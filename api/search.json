[{"id":"c4bbab825e6b5f8c309a31fde6de63ea","title":"netty进阶","content":"MpscQueueMpsc来自JCTools，即JAVA的高并发增强包，主要提供了一些 JDK 缺失的并发数据结构\n\nSpsc 单生产者单消费者\nMpsc 多生产者单消费者\nSpmc 单生产者多消费者\nMpmc 多生产者多消费者\n\nMpsc 的全称是 Multi Producer Single Consumer，多生产者单消费者，多个生产者线程通过CAS无锁操作提升性能，单个消费者不需要加锁；\nMpsc Queue 可以保证多个生产者同时访问队列是线程安全的，而且同一时刻只允许一个消费者从队列中读取数据。\nMpscArrayQueue内部的环形数组容量为 2 的次幂，可以通过位运算快速定位到数组对应下标。\nNetty Reactor 线程中的任务队列 taskQueue 必须满足多个生产者可以同时提交任务，所以 JCTools 提供的 Mpsc Queue 非常适合 Netty Reactor 线程模型\nMpscArrayQueue为例//继承类的所有变量声明\n// ConcurrentCircularArrayQueueL0Pad.java\nlong p01, p02, p03, p04, p05, p06, p07;\nlong p10, p11, p12, p13, p14, p15, p16, p17;\n\n// ConcurrentCircularArrayQueue.java\n// 计算数组下标的掩码\nprotected final long mask;\n// 存放队列数据的数组\nprotected final E[] buffer;\n\n// MpmcArrayQueueL1Pad.java\nlong p00, p01, p02, p03, p04, p05, p06, p07;\nlong p10, p11, p12, p13, p14, p15, p16;\n\n// MpmcArrayQueueProducerIndexField.java\n// 生产者索引\nprivate volatile long producerIndex;\n\n// MpscArrayQueueMidPad.java\nlong p01, p02, p03, p04, p05, p06, p07;\nlong p10, p11, p12, p13, p14, p15, p16, p17;\n\n// MpscArrayQueueProducerLimitField.java\n// 生产者索引的最大值\nprivate volatile long producerLimit;\n\n// MpscArrayQueueL2Pad.java\nlong p00, p01, p02, p03, p04, p05, p06, p07;\nlong p10, p11, p12, p13, p14, p15, p16;\n\n// MpscArrayQueueConsumerIndexField.java\n// 消费者索引\nprotected long consumerIndex;\n\n// MpscArrayQueueL3Pad.java\nlong p01, p02, p03, p04, p05, p06, p07;\nlong p10, p11, p12, p13, p14, p15, p16, p17;\n\n在pad类中填充了大量long的数据，其命名没有什么特殊的含义，只是起到填充的作用，这是为了解决伪共享（false sharing）问题\n伪共享问题\n\n\n\n\n\n\n\n\n你的行为似乎有利于共享，但是却徒增消耗\n为了平衡CPU与内存的速度差异，常常会设立多层缓存机制，一般是三层，CPU 读取数据时，首先会从 L1 查找，如果未命中则继续查找 L2，如果还未能命中则继续查找 L3，最后还没命中的话只能从内存中查找，读取完成后再将数据逐级放入缓存中。\n此外，多线程之间共享一份数据的时候，需要其中一个线程将数据写回主存（总线嗅探机制保证可见性），其他线程访问主存数据。\nCPU 缓存由若干个缓存行（Cache Line） 组成，缓存行是 CPU 缓存可操作的最小单位。\nCache Line 的大小与 CPU 架构有关，在目前主流的 64 位架构下，Cache Line 的大小通常为 64 Byte。\n而 Java 中一个 long 类型是 8 Byte，所以一个 Cache Line 可以存储 8 个 long 类型变量。\nCPU 在加载内存数据时，会将相邻的数据一同读取到 Cache Line 中（一次加载连续的 64 个字节），这样就可以避免 CPU 频繁与内存进行交互了。\n例如：如果访问一个 long 型的单独变量 a，并且还有另外一个 long 型变量 b 紧挨着它，那么当加载 a 时候将免费加载 b\n伪共享就会在此出现：\n\n假设有 A、B、C、D 四个变量，线程1尝试修改变量A，于是将A和B、C、D一起都加载到了core1的一个 Cache Line；\n此时，线程2读取变量B，也将A、C、D加载到了core2的同一 Cache Line；\n线程1 对变量 A 进行修改，修改完成后将变量A值写回主存，然后 CPU1 会通知 CPU2 该缓存行已经失效；\n线程 2 在Core2 中对变量 C 进行修改时，发现 Cache line 已经失效，所以需要重新从主存中读取数据加载到当前 Cache line 中。\n\n当多个线程同时修改互相独立的变量时，如果这些变量共享同一个缓存行，就会出现写竞争，导致频繁从主存加载数据，影响性能。\n\n\n常见的解决思路就是：以空间换时间，让不同线程操作的不相干变量加载到不同缓存行，避免相互影响\npublic class FalseSharingPadding &#123;\n    protected long p1, p2, p3, p4, p5, p6, p7;\n    protected volatile long value = 0L;\n    protected long p9, p10, p11, p12, p13, p14, p15;\n&#125;\n\n变量 value 前后分别填充了 7 个 long 类型的变量。\n这样不论在什么情况下，都可以保证在多线程访问 value 变量时，value 与其他不相关的变量处于不同的 Cache Line\nMPSC方法解析加入元素// MpscArrayQueue.java\n//生产者加入元素\npublic boolean offer(final E e) &#123;\n    if (null == e)\n    &#123;\n        throw new NullPointerException();\n    &#125;\n\n    final long mask = this.mask;\n\n    // 获取生产者索引最大限制\n    long producerLimit = lvProducerLimit();\n    long pIndex;\n    do\n    &#123;\n        // 获取生产者索引\n        pIndex = lvProducerIndex();\n        // 如果生产者索引达到了最大值，防止追尾\n        if (pIndex >= producerLimit)\n        &#123;\n            // 消费者索引，以volatile的形式获取，保证获取的是最新的值\n            final long cIndex = lvConsumerIndex();\n            // 修改为当前消费者的索引加上数组的大小\n            producerLimit = cIndex + mask + 1;\n\t\t\t// 如果依然达到了最大值，则返回false，表示队列满了，再放元素就追尾了\n            if (pIndex >= producerLimit)\n            &#123;\n                return false; // 队列已满\n            &#125;\n            else\n            &#123;\n                soProducerLimit(producerLimit);        // 更新 producerLimit\n            &#125;\n        &#125;\n    &#125; while (!casProducerIndex(pIndex, pIndex + 1));// CAS 更新生产者索引，更新成功则退出，说明当前生产者已经占领索引值\n    // 计算生产者索引在数组中下标\n    final long offset = calcCircularRefElementOffset(pIndex, mask);\n    // 向数组中放入数据\n    soRefElement(buffer, offset, e);\n    return true; \n&#125;\n\n//获取生产者索引最大值和修改生产者索引最大值\n  // 读取producerLimit\nprotected final long lvProducerLimit() &#123;\n        // producerLimit本身就是volatile修饰的\n        return this.producerLimit;\n    &#125;\n    // 保存producerLimit\n    protected final void soProducerLimit(long v) &#123;\n        // 这个方法会加StoreStore屏障\n        // 会把最新值直接更新到主内存中，但其它线程不会立即可见\n        // 其它线程需要使用volatile语义才能读取到最新值\n        // 这相当于是一种延时更新的方法，比volatile语义的性能要高一些\n        UnsafeAccess.UNSAFE.putOrderedLong(this, P_LIMIT_OFFSET, v);\n    &#125;\n&#125;\n\n//获取生产者索引，更新生产者索引\n // 读取producerIndex\n    protected final long lvProducerIndex() &#123;\n        // producerIndex本身就用volatile修饰了\n        return this.producerIndex;\n    &#125;\n \n    // CAS更新producerIndex\n    protected final boolean casProducerIndex(long expect, long newValue) &#123;\n        // CAS更新\n        return UnsafeAccess.UNSAFE.compareAndSwapLong(this, P_INDEX_OFFSET, expect, newValue);\n    &#125;\n\n// 读取consumerIndex\n  protected final long lvConsumerIndex() &#123;\n      // 以volatile的形式加载consumerIndex\n      // 此时会从内存读取最新的值\n      return UnsafeAccess.UNSAFE.getLongVolatile(this, C_INDEX_OFFSET);\n  &#125;\n\n// 修改数组对应偏移量的值\n    public static &lt;E> void soElement(E[] buffer, long offset, E e) &#123;\n        // 比使用下标更新数组元素有两个优势\n        // 1. 使用Unsafe操作内存更新更快\n        // 2. 使用putOrderedObject会直接更新到主内存，而使用下标不会立马更新到主内存\n        UnsafeAccess.UNSAFE.putOrderedObject(buffer, offset, e);\n    &#125;\n\n\n\n初始时，两个线程拿到的 pIndex 都等于producerIndex为0，小于 producerLimit ；\n接着，两个线程都会尝试 CAS 更新 producerIndex + 1 ，必然只有一个线程能更新成功，另一个失败；\n假设 Thread1 CAS 操作成功，那么它拿到的 pIndex 为0，Thread2 失败后就会重新更新 producerIndex ，然后更新成功，拿到 pIndex 为1；\n最后，根据 pIndex 进行位运算，得到数组对应的下标，然后通过 UNSAFE.putOrderedObject() 方法将数据写入到数组中。\n\n获取元素//无CAS\npublic E poll() &#123;\n        // 读取consumerIndex的值\n        long cIndex = this.lpConsumerIndex();\n        // 计算在数组中的偏移量\n        long offset = this.calcElementOffset(cIndex);\n        // 获取存储元素的数组\n        E[] buffer = this.buffer;\n        // 取元素，通过StoreStore写入队列，通过LoadLoad取出来的元素是最新值\n        E e = UnsafeRefArrayAccess.lvElement(buffer, offset);\n        if (null == e) &#123;\n            // 元素入队是先更新了producerIndex的值，再把更新元素到数组中\n            // 如果在两者之间，进行了消费，则此处是无法获取到元素的\n            // 所以需要进入下面的判断\n            // 判断consumerIndex是否等于producerIndex\n            // 只有两者不相等，才可以再消费元素\n            if (cIndex == this.lvProducerIndex()) &#123;\n                return null;\n            &#125;\n            // 使用死循环来取元素，直到取到为止\n            do &#123;\n                e = UnsafeRefArrayAccess.lvElement(buffer, offset);\n            &#125; while(e == null);\n        &#125;\n        // 更新取出的位置元素为null\n        UnsafeRefArrayAccess.spElement(buffer, offset, (Object)null);\n        // 修改consumerIndex的索引为新值，使用StoreStore屏障，直接更新到主内存\n        this.soConsumerIndex(cIndex + 1L);\n        // 返回出队的元素\n        return e;\n    &#125;\n\n\n因为只有一个消费者线程，所以整个 poll() 的过程没有 CAS 操作。\npoll() 方法核心思路是获取消费者索引 consumerIndex，然后根据 consumerIndex 计算得出数组对应的偏移量，然后将数组对应位置的元素取出并返回，最后将 consumerIndex 移动到环形数组下一个位置。\nprotected final long lpConsumerIndex() &#123;\n       // 直接返回消费者索引\n       return this.consumerIndex;\n   &#125;\n   // 保存消费者索引值\n   protected void soConsumerIndex(long l) &#123;\n       // 这个方法会加StoreStore屏障\n       // 会把最新值直接更新到主内存中，但其它线程不会立即可见\n       // 其它线程需要使用volatile语义才能读取到最新值\n       // 这相当于是一种延时更新的方法，比volatile语义的性能要高一些\n       UnsafeAccess.UNSAFE.putOrderedLong(this, C_INDEX_OFFSET, l);\n   &#125;\n\n\npublic static &lt;E> void spElement(E[] buffer, long offset, E e) &#123;\n        // 更新buffer在offset处的元素值\n        UnsafeAccess.UNSAFE.putObject(buffer, offset, e);\n    &#125;\n \n    public static &lt;E> E lvElement(E[] buffer, long offset) &#123;\n        // 获取buffer在offset处的元素值\n        return UnsafeAccess.UNSAFE.getObjectVolatile(buffer, offset);\n    &#125;\n\n//计算偏移量\npublic static long calcElementOffset(long index, long mask) &#123;\n        // REF_ARRAY_BASE，基础地址，数组在内存中的地址\n        // REF_ELEMENT_SHIFT，可以简单地看作一个元素占用多少字节\n        // 64位系统中一个引用对象占用64位，也就是8字节，但是压缩模式下占用4字节\n        // index &amp; mask 计算数组下标\n        // 比如数组大小为4，mask就为3时，4&amp;3=100&amp;011=0\n        return REF_ARRAY_BASE + ((index &amp; mask) &lt;&lt; REF_ELEMENT_SHIFT);\n    &#125;\n\n\nUnsafe 方法\n**putOrderedXxx()**，使用 StoreStore 屏障，会把最新值更新到主内存，但不会立即失效其它缓存行中的数据，是一种延时更新机制；\n**putXxxVolatile()**，使用 StoreLoad 屏障，会把最新值更新到主内存，同时会把其它缓存行的数据失效，或者说会刷新其它缓存行的数据；\n**putXxx(obj, offset)**，不使用任何屏障，更新对象对应偏移量的值；\n**getXxxVolatile()**，使用 LoadLoad 屏障，会从主内存获取最新值；\n**getXxx(obj, offset)**，不使用任何屏障，读取对象对应偏移量的值；\n\n\n\n总结：\nMPSC实现高并发和高性能使用了哪些方法？\nLazySet 延迟更新机制：在更新producerLimit，消费者索引，和环形数组元素时使用StoreStore屏障，虽然写操作结果有纳秒级的延迟，但是由于没有立刻读取的操作，所以没有问题，且提升了性能\n使用偏移量来更新数组元素，比下标性能更好\n使用UNSAFE方法来直接操作内存\n使用long型变量填充来避免伪共享问题\n\n","slug":"netty进阶","date":"2022-11-24T08:04:09.000Z","categories_index":"","tags_index":"netty","author_index":"Samuel"},{"id":"50b4378888e6118830afe84cb7b95b4c","title":"下一个更大元素","content":"556.下一个更大元素 III给你一个正整数 n ，请你找出符合条件的最小整数，其由重新排列 n 中存在的每位数字组成，并且其值大于 n 。如果不存在这样的正整数，则返回 -1 。\n注意 ，返回的整数应当是一个 32 位整数 ，如果存在满足题意的答案，但不是 32 位整数 ，同样返回 -1 。\n输入：n = 12;\n输出：21;\n输入：n = 123;\n输出：132;\n\n思路：从后向前搜索，第一次发现左侧元素小于右侧元素时，交换，并对交换后的元素之后的元素进行反转\n\nclass Solution &#123;\n    public int nextGreaterElement(int n) &#123;\n        char[] nums = Integer.toString(n).toCharArray();\n        for(int i = nums.length-2;i>=0;i--)&#123;\n            for(int j=nums.length-1;j>i;j--)&#123;\n                if(nums[j]>nums[i]) &#123;\n            \t//先交换\n                swap(nums,i,j);\n                //再反转\n                reverse(nums,i+1,nums.length-1);\n                long res = Long.parseLong(new String(nums));\n                return res>Integer.MAX_VALUE?-1:(int)res;\n                &#125;\n            &#125;\n        &#125;\n        return -1;\n    &#125;\n    void reverse(char[] nums,int start,int end)&#123;\n        int left = start;\n        int right = end;\n        while(left&lt;=right)&#123;\n            swap(nums,left++,right--);\n        &#125;\n    &#125;\n    void swap(char[] nums,int i,int j)&#123;\n        char c = nums[i];\n        nums[i]=nums[j];\n        nums[j]=c;\n    &#125;\n&#125;\n\n算法技巧，字符串与数字的转换\n//将整数转换为数组\nchar[] nums = Integer.toString(n).toCharArray();\n//将数组转换为字符串\nString s = new String(nums);\n//将数组转换为整数\nint n = Integer.parseInt(new String(nums));\n//将ArrayList转换为字符串\nArrayList&lt;> list = new ArrayList&lt;>();\nObject[] o = list.toArray();//toArray只会返回一个Object数组\nchar[] c = new char[o.length];\nfor (int i = 0; i &lt; o.length; i++) &#123;\n\tc[i] = o[i].toString().charAt(0);\n&#125;\nString s = new String(c);\n\n","slug":"下一个更大元素","date":"2022-11-24T05:39:19.000Z","categories_index":"","tags_index":"LeetCode初见","author_index":"Samuel"},{"id":"9b0aac9dc0e1ef2dfbe55000223e9c86","title":"Java新特性","content":"j记录一些与我能看懂的新特性\nJDK9 String 底层存储结构发生变化使用字节数组\nJDK10局部变量的类型推断 var关键字\n&#x2F;&#x2F;var 没有改变Java的本质，var只是一种简便的写法，\n&#x2F;&#x2F;就是说在定义局部变量时，任意什么类型都可以用var定义变量的类型会根据所赋的值来判断\nvar list &#x3D; new ArrayList&lt;String&gt;();\nlist.add(&quot;hello，world！&quot;);\nSystem.out.println(list);\n\n引入List.copyOf() 来生成不可改变的List\nJDK11引入ZGC\nJDK14移除CMS\nJDK15弃用偏向锁\n正式使用ZGC\nJDK19虚拟线程\n","slug":"Java新特性","date":"2022-11-22T04:48:11.000Z","categories_index":"","tags_index":"Java额外知识补充","author_index":"Samuel"},{"id":"6ba55d3e12601017e69aa7613dde8806","title":"周赛笔记11/13/2022","content":"6234.最小公倍数为 K 的子数组数目给你一个整数数组 nums 和一个整数 k ，请你统计并返回 nums 的 子数组 中满足 元素最小公倍数为 k 的子数组数目。\n子数组 是数组中一个连续非空的元素序列。数组的最小公倍数 是可被所有数组元素整除的最小正整数。\n示例 1 ：\n输入：nums &#x3D; [3,6,2,7,1], k &#x3D; 6\n输出：4\n解释：以 6 为最小公倍数的子数组是：\n- [3,6]\n- [3,6,2]\n- [6,2]\n- [6]\n\n//两个for循环扫描\nclass Solution &#123;\n    public int subarrayLCM(int[] nums, int k) &#123;\n        int ans =0;\n        int n=nums.length;\n        for(int i=0;i&lt;n;i++)&#123;\n            if(nums[i]==k) ans++;\n            int temp=nums[i];\n            for(int j=i+1;j&lt;n;j++)&#123;\n                //最小公倍数的传递性，a,b,c的最小公倍数为：a,b的最小公倍数k与c的最小公倍数\n                temp=minMul(temp,nums[j]);\n                if(temp==k) ans++;\n            &#125;\n        &#125;\n        return ans;\n    &#125;\n    //可以记住这个算法\n    //利用最大公约数求最小公倍数\n    int minMul(int a, int b)&#123;\n        int sum = a*b;\n        return sum/gcd(a,b);\n    &#125;\n    //辗转相除法求最大公约数\n    int gcd(int a,int b)&#123;\n        return (b==0)?a:gcd(b,a%b);\n    &#125;\n&#125;\n\n6235.逐层排序二叉树所需的最少操作数目给你一个 值互不相同 的二叉树的根节点 root 。\n在一步操作中，你可以选择 同一层 上任意两个节点，交换这两个节点的值。\n返回每一层按 严格递增顺序 排序所需的最少操作数目。\n节点的 层数 是该节点和根节点之间的路径的边数。\n\n输入：root &#x3D; [1,4,3,7,6,8,5,null,null,null,null,9,null,10]\n输出：3\n解释：\n- 交换 4 和 3 。第 2 层变为 [3,4] 。\n- 交换 7 和 5 。第 3 层变为 [5,6,8,7] 。\n- 交换 8 和 7 。第 3 层变为 [5,6,7,8] 。\n共计用了 3 步操作，所以返回 3 。\n可以证明 3 是需要的最少操作数目。\n\n//复习二叉树的层序遍历\nclass Solution &#123;\n    //层序遍历，生成每层的数组记录，对数组记录进行操作，记录操作次数\n    public int minimumOperations(TreeNode root) &#123;\n        if(root==null) return 0;\n        int res = 0;\n        Deque&lt;TreeNode> q = new ArrayDeque&lt;>();\n        q.add(root);\n        while(q.peek()!=null)&#123;\n            int n = q.size();\n            int[] record = new int[n];\n            for(int i=0;n>0;n--)&#123;\n                TreeNode node = q.poll();\n                record[i++] = node.val;\n                if(node.left != null) q.add(node.left);\n                if(node.right !=null)q.add(node.right);\n            &#125;\n            res+=count(record);\n        &#125;\n    return res;\n    &#125;\n    //记录将数组变为有序的最小交换次数\n    int count(int[] record)&#123;\n        //比较与排序过的数组的索引差异，不断交换，直到相同\n        HashMap&lt;Integer,Integer> map = new HashMap();\n        int[] sorted = record.clone();\n        Arrays.sort(sorted);\n        int count=0;\n        for(int i=0;i&lt;record.length;i++) map.put(sorted[i],i);\n        for(int i=0;i&lt;record.length;i++)&#123;\n            while(true)&#123;\n                int index = map.get(record[i]);\n                if(index!=i)&#123;\n                    count++;\n                    swap(record,index,i);\n                &#125;\n                else break;\n            &#125;\n        &#125;\n        return count;\n    &#125;\n    void swap(int[] nums, int i,int j)&#123;\n        int temp = nums[i];\n        nums[i]=nums[j];\n        nums[j]=temp;\n    &#125;\n&#125;\n\n","slug":"周赛笔记11-13-2022","date":"2022-11-13T08:22:18.000Z","categories_index":"","tags_index":"LeetCode初见","author_index":"Samuel"},{"id":"2e8864ab557e295b3f55e14c06a19e33","title":"Java基础知识汇总","content":"Object类中有哪些方法\nequals()：未被重写前，由&#x3D;&#x3D;来实现，比较引用数据类型的引用地址是否相同\nHashCode()：本地方法，未被重写前返回对象在堆上的唯一地址值，可以看作是对象的身份ID\nclone()：实现了cloneable接口才可以调用该方法，实现对象的浅复制\ngetClass()：final修饰，获取运行时的类型\ntoString()：若参数为变量，则返回对应变量的string对象，若参数为一个对象，则返回堆内存对象的地址\nfinalize()：在GC准备释放对象所占用的内存空间之前，它将首先调用finalize()方法，finalize()方法中一般用于释放非Java 资源（如打开的文件资源、数据库连接等）,或是调用native方法时分配的内存(比如C语言的malloc()）。\nwait()：使线程阻塞等待\nnotify()：唤醒等待的线程\nnofityAll()：唤醒在该对象上等待的所有线程\n\nJAVA的八大数据类型可以分为四个大类：整型，字符型，浮点型，布尔型\n\nboolean：JVM中并没有提供boolean专用的字节码指令，在编译后会以int型来表示，4字节。boolean[]会以byte数组来表示，1字节\nchar：可以赋值单字符以及整型数值，表示数字的取值范围为0~65536，2字节\nbyte：范围为-128 - 128，1字节\nshort：范围为：-32768-32768，2字节\nint：范围为：-2,147,483,648-2,147,483,647，4字节\nlong：范围为；-2^63-2^63-1，8字节\nfloat：单精度浮点数，4字节\ndouble：双精度浮点数，8字节\n\n接口和抽象类有哪些区别相同点：\n\n不能被实例化\n可以将抽象类和接口类型作为引用类型\n一个类如果继承了某个抽象类或者实现了某个接口都需要对其中的抽象方法全部实现\n\n不同点：\n\n抽象类中可以定义构造器，可以有抽象方法和具体方法，抽象类中可以定义成员变量，一个类只能继承一个抽象类，抽象类中可以包含静态方法，抽象类中的成员可以由private,protected,public修饰\n接口中的成员全部都是由public修饰，不能定义构造器，只能有抽象方法，不能有静态方法，一个类可以实现多个接口\n\n除了语法上的异同之外，两者还有语义上的不同。抽象类适合描述某一更具体的概念，比如狗是一种动物，而不能说狗实现了动物的接口。接口则用于描述多个事物的共同特征，比如鸟实现了flyable接口，这个flyable就是一种行为特征，当然也可以描述其他的特征。\nString,StringBuilder,StringBuffer的区别\nString的底层是一个由final修饰的char型数组，String是静态只读的，当改变变量的值时，其实只是改变了引用对象的指向，指向了新创建的字符串，而原字符串仍存在于字符串常量池。\nStringBuffer（JDK1.0引入）：引用对象指向一个空间，包含一个可自行扩容的char型数组和字符串长度计数变量Count，StringBuffer的所有方法均被synchronized修饰。扩容时会开辟一块新的空间用于创建更大的数组，并将原数据复制过去，并改变引用对象的指向。\nStringBuilder(JDK1.5引入)：取消了synchronized方法修饰，所以效率更高，但是线程不安全。\n\nObject o = new Object()在内存中占用多少个字节？一个对象在内存中的存储布局：markword：8字节，锁信息+HashCode+GC信息；classPointer:4字节；对齐：保证大小能被8整除；数据段：即对象内声明的变量\n所以一个空对象最小为16字节\n对象如何定位？HotSpot虚拟机默认使用直接定位：指针直接指向堆内存内的对象，对象内的classPointer指向方法区内的class。优点：直接访问快；缺点：GC时，若需要移动对象，则指针也需要改变\n句柄方式（间接方式）：指针指向另一个结构体，该结构体内有两个指针，分别指向堆内存和方法区。优点：对象小，GC时无需改动指针。缺点：比直接访问更慢\n对象的创建过程new指令：申请内存空间，为成员变量设立默认值\ninvokespecial汇编码：调用构造方法，为成员变量设定初始值\nastore汇编码：建立引用，让指针指向堆\n面向对象有哪些特征面向对象是一种编程思想，即万物皆可归类抽象，万物皆可对象；有三大特征\n\n封装：类与外界的封装关系，即隐藏类内部的实现机制，对外部而言，它的内部细节是隐藏的，只暴露了自身的访问方法。使用者按照既定的方式来调用方法，不必关心方法的内部实现，便于使用，增强了代码的可维护性。\n继承：类与类的关系，即从已有的类中派生出新的类，即子类与父类，也可以称作超类和基类。从多个类中抽象出一个基类，使其具备多个类的共同特性，使用extends关键字继承某个类后，就具备了父类的属性，并扩展新的属性。在父类中使用private关键字来限制不会被继承。\n多态：多个类的关系，必备的三个要素：继承，重写，父类引用指向子类对象\n\nArrayList与LinkedList的区别\nArrayList是基于索引的数据接口，底层是数组，可以在常数级的复杂度对元素进行随机访问。而LinkedList是基于Node对象列表的形式存储数据，底层是一个双向链表，查找元素是O（n）。因此LinkedList的插入，添加，删除操作，总体上会更快，因为不是数组，不需要移动元素，重新计算索引和大小，但是LinkedList更占内存，因为每一个node都会封装前驱指针和后继指针。\n如果你需要经常随机访问数据，更加推荐使用ArrayList；如果需要经常插入删除元素，推荐使用LinkedList。\n多提一嘴：其实总体上ArrayList性能其实更加优越一些。第一，LinkedList的每一个node都有指针，更占内存，第二：虽然LinkedList的头插效率很高，但是尾插效率却不见得十分高效，因为数组的尾插无需进行拷贝和移位，而链表则需要创建node对象。并且有人测试过，在数据量较大时，链表的中间插入仍会比ArrayList耗时更多。Joshua Bloch自己都不用LinkedList，以俺还是无脑选择ArrayList~\n\n多线程环境下，操作long和double类型为什么不安全？JAVA内存模型要求，变量的读取和写入必须是原子操作，但对于非volatile类型的long和double变量，JVM允许将64位的读操作或写操作分解成两个32位的操作。当读取一个非volatile类型的long时，如果读操作和写操作在不同的线程中执行，那么很可能读取到某个值的高32位和另一个值的低32位。就是说，在多线程环境下，使用共享且可变的long和double变量是不安全的，必须用关键字volatile声明或者用锁保护起来。但是如果在64bit的操作环境下，读写就可以是原子操作。\n什么是线程安全？当多个线程访问某个类时，这个类始终能表现出正确的行为，那么就称这个类是线程安全的。具体说，就是当多个线程访问某个类时，不管运行时环境采用何种调度方式将这些线程交替进行，并且在主调代码中不需要任何额外的同步或协同，这个类都能表现出正确的行为，那么就称这个类时线程安全的。\nInt和Integer的区别\nInteger是int的包装类，int则是java的一种基本的数据类型；\nInteger变量必须实例化之后才能使用，而int变量不需要实例化；\nInteger实际是对象的引用，当new一个Integer时，实际上生成一个指针指向对象，而int则直接存储数值\nInteger的默认值是null，而int的默认值是0。\n\nint a = 1;//直接存储值\nInteger b = 1;//无new创建Integer对象时，这种操作等于：Integer.valueOf(1);\nInteger c = new Integer(1);//指向堆内存中的对象\n\n包装类的缓存机制\n若使用valueOf方法，则会调用缓存IntegerCache，这是一个静态内部类，会直接缓存-127到128的Integer对象。\n因此，在valueOf方法中，如果值在-127-128之间，都会直接返回缓存中的该对象而不会重新生成对象。\n如果超过这个范围就会直接在堆上创建一个新的对象\npublic static Integer valueOf(int i) &#123;\n     if (i &gt;&#x3D; IntegerCache.low &amp;&amp; i &lt;&#x3D; IntegerCache.high)\n         return IntegerCache.cache[i + (-IntegerCache.low)];\n     return new Integer(i);&#x2F;&#x2F;超过范围\n &#125;\n\nByte，Short，Long的缓存范围都是-128-127，Character的缓存范围是0-127，除了Integer，其他的缓存范围都是固定的\n","slug":"JAVA基础知识汇总","date":"2022-11-13T07:48:43.000Z","categories_index":"","tags_index":"Java基础知识","author_index":"Samuel"},{"id":"2a1374b017f253762c103f23513f4420","title":"NIO select poll和epoll","content":"套接字编程Socket，表示进程间网络通信的特殊文件类型。本质是内核借助缓冲区形成的伪文件。Linux将套接字封装成文件的目的是为了统一接口，使得读写套接字和读写文件的操作一致。\n在TCP&#x2F;IP协议中，“IP地址+TCP或UDP端口号”唯一标识网络通讯中的一个进程。\n“IP地址+端口号”就对应一个socket。欲建立连接的两个进程各自有一个socket来标识，那么这两个socket组成的socket pair就唯一标识一个连接。因此可以用Socket来描述网络连接的一对一关系。\n\n一个文件描述符指向一个套接字\n一个套接字内部由内核借助两个缓冲区实现，一个写缓冲、读缓冲。\n在通信过程中， 套接字一定是成对出现的。一端的发送缓冲区对应对端的接收缓冲区\n\n\nsocket()创建一个socket\nbind()为socket绑定ip+port\nlisten()设置监听上限，即同时跟服务器建立socket连接的数量\naccept()：阻塞监听客户端连接，创建一个新的socket用来与客户端通信\nconnect()：客户端使用现有的socket与服务器建立连接，如果不使用bind绑定客户端地址结构，采用“隐式绑定”，系统自动分配ip+port\n\n网络IO同步：同步就是一个任务的完成需要依赖另外一个任务时，只有等待被依赖的任务完成后，依赖的任务才能算完成，这是一种可靠的任务序列。也就是说，调用会等待返回结果计算完成才能继续执行。BIO,NIO,select,poll,epoll都是同步的，只不过会有阻塞，非阻塞的区别。\n异步：异步是不需要等待被依赖的任务完成，只是通知被依赖的任务要完成什么工作，依赖的任务也立即执行，只要自己完成了整个任务就算完成了。也就是说，其实异步调用会直接返回，但是这个结果不是计算的结果，当结果计算出来之后，才通知被调用的程序。\n阻塞：阻塞调用是指调用结果返回之前，当前线程会被挂起，一直处于等待消息通知，不能够执行其他业务。\n非阻塞：不管可不可以读写，它都会立即返回，返回成功说明读写操作完成了，返回失败会设置相应errno状态码，根据这个errno可以进一步执行其他处理。它不会像阻塞IO那样，卡在那里不动。\nBIO即阻塞IO，一个socket对应一个线程，若无数据发送则会一直阻塞等待，造成资源浪费\n特别是在JAVA环境下，线程的创建，切换，代价高昂\n结构简单，适合规模小，低并发的情况\n\n特点：面向流的，阻塞的java1.4以前的io模型，一连接对一个线程，原始的IO是面向流的，不存在缓存的概念。\nJava IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。\n此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区\nJava IO的各种流是阻塞的，这意味着当一个线程调用read或 write方法时，该线程被阻塞，直到有一些数据被读取，或数据完全写入，该线程在此期间不能再干任何事情了。\nNIO非阻塞IO，指使用一个线程不断轮询来管理所有套接字，即一个while死循环来不断遍历，一旦发现有数据便进行处理。\n做到了单线程也能管理所有套接字。这是非阻塞的，就算没有数据也不会停下来，而是返回无数据的标识，然后再进行下一次的轮询。\nNIO是面向缓冲区的，每个连接都有一个缓冲区来暂存数据，由管道来进行双向传输\n\nselector实现循环监听通道信号的组件\n一个selector 对应一个线程， 多个channel以事件的方式注册于selector，代表一个进程便可以处理多个连接\nselector 会在各个通道上切换，只有在连接&#x2F;通道真正有读写事件发生时，才会进行读写，就大大地减少了系统开销，并且不必为每个连接都创建一个线程，不用去维护多个线程，避免了多线程之间的上下文切换导致的开销\nchannelNIO的通道类似于流，但有些区别如下：\n\n通道可以同时进行读写，而流只能读或者只能写\n通道可以实现异步读写数据\n通道可以从缓冲读数据，也可以写数据到缓冲\n\nchannel 是双向的, 可以返回底层操作系统的情况, 比如Linux ，底层的操作系统通道就是双向的\nbufferBuffer 就是一个内存块 ，底层是有一个数组\nchannel 提供从文件、网络读取数据的渠道，但是读取或写入的数据都必须经由 Buffer\n数据的读取写入是通过Buffer, 这个和BIO不同 , BIO 中要么是输入流，或者是输出流，不能双向\n但是NIO的Buffer 是可以读也可以写, 需要 flip 方法切换\n特点：面向块，非阻塞NIO是面向缓冲区的。数据被读取到缓冲区，需要时可在缓冲区中前后移动，这就增加了处理过程中的灵活性。\nJava NIO的非阻塞模式，使一个线程从某通道发送请求读取数据，如果目前没有数据可用时，就什么都不会获取，而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此，一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。\nNIO是可以做到用一个线程来处理多个操作的。selector会不断循环监听channel，如果通道中没有数据即没有请求时它可以去处理别的通道或者做其他的事情，如果通道中有数据它就会选择这个通道然后进行处理，实现了一个线程处理多个连接。\nselectNIO是一种十分创新的思想，但是也有许多问题，比如忙循环。\n若一直在用户空间进行轮询，则会资源浪费，复杂度至少为O(n)\n而select就是将所有的fd收集并交给内核，进行一次系统调用，复杂度降为O(1)\n\n内核会返回一个整数，若小于零，代表没有任何数据或请求到达，若大于零，代表可以进行处理。若等于零，代表等待超时。\n每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大\n同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大\nfd_set的大小是有限制的，即单个进程能维护的套接字的大小有限，32位为1024，64位机默认是2048。可以修改。\nwhile (1) &#123;\n      read_fd_set &#x3D; all_fd_set;\n      printf(&quot;阻塞中... lastfd&#x3D;%d\\n&quot;, lastfd);\n    \t&#x2F;&#x2F;获取标志位\n      int nready &#x3D; select(lastfd+1, &amp;read_fd_set, NULL, NULL, NULL);\n      switch (nready) &#123;\n          case 0 :\n              printf(&quot;select time out ......\\n&quot;);\n              break;\n          case -1 :\n              perror(&quot;select error \\n&quot;);\n              break;\n          default:\n              &#x2F;&#x2F; 监听到新的客户端连接\n              if (FD_ISSET(lfd, &amp;read_fd_set)) &#123;\n                  struct sockaddr_in client_addr; \n                  socklen_t cliaddr_len &#x3D; sizeof(client_addr);\n                  char cli_ip[INET_ADDRSTRLEN] &#x3D; &quot;&quot;;  \n                  &#x2F;&#x2F; 肯定有连接不会阻塞\n                  int clientfd &#x3D; accept(lfd, (struct sockaddr*)&amp;client_addr, &amp;cliaddr_len);\n                  inet_ntop(AF_INET, &amp;client_addr.sin_addr, cli_ip, INET_ADDRSTRLEN);\n                  printf(&quot;----------------------------------------------\\n&quot;);\n                  printf(&quot;client ip&#x3D;%s,port&#x3D;%d\\n&quot;, cli_ip, ntohs(client_addr.sin_port));\n                  &#x2F;&#x2F; 将clientfd加入读集合\n                  FD_SET(clientfd, &amp;all_fd_set);  \n                  lastfd &#x3D; clientfd;\n                  if(0 &#x3D;&#x3D; --nready) &#123;\n                      continue;\n                  &#125;\n              &#125;\n              int i;\n              &#x2F;&#x2F;遍历所有的fdset来处理事件\n              for (i &#x3D; lfd + 1;i &lt;&#x3D; lastfd; i++) &#123;\n                  &#x2F;&#x2F; 处理读事件\n                  if (FD_ISSET(i, &amp;read_fd_set)) &#123;\n                      char recv_buf[512] &#x3D; &quot;&quot;;\n                      int rs &#x3D; read(i, recv_buf, sizeof(recv_buf));\n                      if (rs &#x3D;&#x3D; 0 ) &#123;\n                          close(i);\n                          FD_CLR(i, &amp;all_fd_set);\n                      &#125; else &#123;\n                          printf(&quot;%s\\n&quot;,recv_buf);\n                          &#x2F;&#x2F; 给每一个服务端写数据\n                          int j;\n                          for (j &#x3D; lfd + 1;j &lt;&#x3D; lastfd; j++) &#123;\n                              if (j !&#x3D; i) &#123;\n                                  write(j, recv_buf, strlen(recv_buf));\n                              &#125;\n                          &#125;\n                      &#125;\n                  &#125;\n              &#125;\n      &#125;\n      \n  &#125;\n\n\n\n\npollpoll的实现和select很相似，不同的是用于管理文件描述符的集合由数组变为了链表，所以没有最大连接数的限制。存在和select同样的问题\nepoll 与前面所有的轮询机制不同，epoll使用的是事件驱动，即当发生事件时，每个fd上有注册有回调函数，当网卡接收到数据时会回调该函数，同时将该fd的引用放入rdlist就绪列表中。\n当调用epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可。\n如果rdlist不为空，则把发生的事件复制到用户态，同时将事件数量返回给用户。\n避免了遍历所有的fd，只检查发生事件的fd\n&#x2F;&#x2F; 数据结构\n&#x2F;&#x2F; 每一个epoll对象都有一个独立的eventpoll结构体\n&#x2F;&#x2F; 用于存放通过epoll_ctl方法向epoll对象中添加进来的事件\nstruct eventpoll &#123;\n    &#x2F;*红黑树的根节点，这颗树中存储着所有添加到epoll中的需要监控的事件*&#x2F;\n    struct rb_root  rbr;\n    &#x2F;*双链表中则存放着将要通过epoll_wait返回给用户的满足条件的事件*&#x2F;\n    struct list_head rdlist;\n&#125;;\n\n执行流程\n\n调用epoll_create()创建一个ep对象，在内核空间中开辟了一块空间存储eventpoll，返回一个文件句柄，即红黑树的根节点\n调用epoll_ctl()向红黑树中添加、删除、修改fd\n调用epoll_wait()等待，当有事件发生时网卡驱动会调用fd上注册的函数并将该fd添加到rdlist中，解除阻塞。由于fd的引用在红黑树上，所以查找速度很快。\n\n\n总结：\n\nEPOLL支持的最大文件描述符上限是整个系统最大可打开的文件数目, 1G内存理论上最大创建10万个文件描述符\n每个文件描述符上都有一个callback函数，当socket有事件发生时会回调这个函数将该fd的引用添加到就绪列表中，select和poll并不会明确指出是哪些文件描述符就绪，而epoll会。造成的区别就是，系统调用返回后，调用select和poll的程序需要遍历监听的整个文件描述符找到是谁处于就绪，而epoll则直接处理即可\nselect、poll采用轮询的方式来检查文件描述符是否处于就绪态，而epoll采用回调机制。造成的结果就是，随着fd的增加，select和poll的效率会线性降低，而epoll不会受到太大影响，除非活跃的socket很多\n\n//开辟内核空间，返回文件描述符\nint epfd = epoll_create(1);\nevent.data.fd = lfd;\nevent.events = EPOLLIN;\nepoll_ctl(epfd, EPOLL_CTL_ADD, lfd, &amp;event);\nwhile (1) &#123;\n        printf(\"阻塞中....\\n\");\n    \t//从事件集中获取文件描述符\n        int nready = epoll_wait(epfd, events, 20, -1);\n        int i;\n        for (i = 0; i &lt; nready; ++i) &#123;\n            // 监听到新的客户端连接\n            if (events[i].data.fd == lfd) &#123;\n                struct sockaddr_in client_addr; \n                socklen_t cliaddr_len = sizeof(client_addr);\n                char cli_ip[INET_ADDRSTRLEN] = \"\";  \n                // 肯定有连接不会阻塞\n                int clientfd = accept(lfd, (struct sockaddr*)&amp;client_addr, &amp;cliaddr_len);\n                inet_ntop(AF_INET, &amp;client_addr.sin_addr, cli_ip, INET_ADDRSTRLEN);\n                event.data.fd = clientfd;\n                event.events = EPOLLIN | EPOLLET;\n                epoll_ctl(epfd, EPOLL_CTL_ADD, clientfd, &amp;event);\n                \n                printf(\"----------------------------------------------\\n\");\n                printf(\"client ip=%s,port=%d\\n\", cli_ip, ntohs(client_addr.sin_port));\n            &#125; else &#123;\n                char recv_buf[512] = \"\";\n                int rs = read(events[i].data.fd, recv_buf, sizeof(recv_buf));\n                if (rs &lt; 0) &#123;\n                    close(events[i].data.fd);\n                    epoll_ctl(epfd, EPOLL_CTL_DEL, events[i].data.fd, &amp;event);\n                    continue;\n                &#125;\n                printf(\"%s\\n\",recv_buf);\n            &#125;\n        &#125;      \n    &#125;\n\nC10K问题服务器如何支持10k个并发连接？\n为每个连接分配一个独立的线程&#x2F;进程这一思路最为直接。但是，由于申请进程&#x2F;线程会占用相当可观的系统资源，同时对于多进程&#x2F;线程的管理会对系统造成压力，因此，这种方案不具备良好的可扩展性。这一思路在服务器资源还没有富裕到足够程度的时候，是不可行的。即便资源足够富裕，效率也不够高。\n总之，此思路技术实现会使得资源占用过多，可扩展性差，在实际应用中已被抛弃。\nIO多路复用\n循环逐个处理各个连接，每个连接对应一个 socket。当所有 socket 都有数据的时候，这种方法是可行的。但是，当应用读取某个 socket 的文件数据不 ready 的时候，整个应用会阻塞在这里，等待该文件句柄ready，即使别的文件句柄 ready，也无法往下处理。任一文件句柄的不成功会阻塞住整个应用。\n使用select方法解决上面阻塞的问题。在读取文件句柄之前，先查下它的状态，如果ready 了，就进行处理；如果不 ready， 就不进行处理；于是，有了 select 方案。用一个 fd_set 结构体来告诉内核同时监控多个文件句柄，当其中有文件句柄的状态发生指定变化（例如某句柄由不可用变为可用）或超时，则调用返回。同时，在使用上，因为只有一个字段记录关注和发生事件，所以每次调用之前，要重新初始化fd_set结构体。并且因为监听的是所有fd，所以当fd过多时，检查状态就会很慢\npoll 和select原理基本相同，不过消除了文件句柄上限。使用不同字段分别标注“关注事件和发生事件”，来避免重复初始化。\n使用epoll，“poll逐个排查所有文件句柄状态”效率不高。如果在调用返回的时候，只给应用提供发生了状态变化（很可能是数据 ready）的文件句柄，进行排查的效率就高很多。epoll 采用了这种设计，适用于大规模的应用场景。实验表明：当文件句柄数目超过10之后，epoll 性能将优于 select 和 poll；当文件句柄数目达到 10K 的时候，epoll 已经超过 select 和 poll 两个数量级。\n\nC10M：服务器如何支持10M个并发连接？内核是问题所在，要高效地去除阻塞，让CPU更多地处理核心任务。不要让内核执行所有繁重的任务。将数据包处理、内存管理、处理器调度等任务从内核转移到应用程序，由应用程序高效地完成。让Linux只处理控制层，数据层完全交给应用程序来处理。\n当连接很多时，首先需要大量的进程&#x2F;线程。同时，系统中的应用进程&#x2F;线程可能大量地都处于 ready 状态，需要系统不断地进行快速切换，系统的上下文的切换是有代价的。\n所以我们面临的瓶颈有两个：一个是进程&#x2F;线程作为处理单元，还是太厚重了；另一个是系统调度的代价太高了。\n如果有一种更轻量级的进程&#x2F;线程作为处理单元，而且它们的调度可以做到很快，也许就能解决问题，这就是协程\n协程协程在实现上都是试图用一组少量的线程来实现多个任务，一旦某个任务阻塞，则可能用同一线程继续运行其他任务，避免大量上下文的切换。每个协程所独占的系统资源往往只有栈部分。各个协程之间的切换，往往是用户通过代码来显式指定的（跟各种callback 类似），不需要内核参与，可以很方便实地现异步。\n这个技术本质上是异步非阻塞技术，它是将事件回调进行了包装，让程序员看不到里面的事件循环。程序员就像写阻塞代码一样简单。\n比如调用 client-&gt;recv() 等待接收数据时，就像阻塞代码一样写。实际上是，底层库在执行recv时悄悄保存了一个状态，比如代码行数、局部变量的值。然后，就跳回到EventLoop中了。什么时候真的数据到来时，它再把刚才保存的代码行数、局部变量值取出来，又开始继续执行。\n这就是协程的本质。协程是异步非阻塞的另外一种展现形式。Golang、Erlang、Lua协程都是这个模型。\n","slug":"NIO-select-poll和epoll","date":"2022-11-02T05:45:40.000Z","categories_index":"","tags_index":"网络编程基础知识","author_index":"Samuel"},{"id":"52c15247d71045907737fa627f8aa035","title":"洪水淹没算法","content":"695. 岛屿的最大面积\n输入：grid &#x3D; [[0,0,1,0,0,0,0,1,0,0,0,0,0],[0,0,0,0,0,0,0,1,1,1,0,0,0],[0,1,1,0,1,0,0,0,0,0,0,0,0],[0,1,0,0,1,1,0,0,1,0,1,0,0],[0,1,0,0,1,1,0,0,1,1,1,0,0],[0,0,0,0,0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,0,1,1,1,0,0,0],[0,0,0,0,0,0,0,1,1,0,0,0,0]]\n输出：6\n解释：答案不应该是 11 ，因为岛屿只能包含水平或垂直这四个方向上的 1 。\n\nclass Solution &#123;\n    public int maxAreaOfIsland(int[][] grid) &#123;\n        int res =0;\n        int m=grid.length;\n        int n=grid[0].length;\n        for(int i=0;i&lt;m;i++)&#123;\n            for(int j=0;j&lt;n;j++)&#123;\n                if(grid[i][j]==1)&#123;\n                    res=Math.max(res,FloodFill(grid,i,j));\n                &#125;\n            &#125;\n        &#125;\n        return res;\n    &#125;\n    //淹没与i,j相邻的陆地并记录下面积\n    int FloodFill(int[][] grid,int i, int j)&#123;\n        if(!isValid(i,j,grid)) return 0;\n        if(grid[i][j]==0) return 0;\n        grid[i][j]=0;\n        return FloodFill(grid,i+1,j)\n        +FloodFill(grid,i,j+1)\n        +FloodFill(grid,i-1,j)\n        +FloodFill(grid,i,j-1) +1;\n\n    &#125;\n    boolean isValid(int i,int j,int[][] grid)&#123;\n        if(i>=0 &amp;&amp; j>=0 &amp;&amp; i&lt;grid.length &amp;&amp; j&lt;grid[0].length)&#123;\n            return true;\n        &#125;\n        return false;\n    &#125;\n&#125;\n\n200. 岛屿数量给你一个由 ‘1’（陆地）和 ‘0’（水）组成的的二维网格，请你计算网格中岛屿的数量。\n岛屿总是被水包围，并且每座岛屿只能由水平方向和或竖直方向上相邻的陆地连接形成。\n此外，你可以假设该网格的四条边均被水包围。\n输入：grid &#x3D; [\n  [&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;0&quot;],\n  [&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;1&quot;,&quot;0&quot;],\n  [&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;],\n  [&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;]\n]\n输出：1\n\nclass Solution &#123;\n    //二维数组的递归遍历和floodfill算法\n    public int numIslands(char[][] grid) &#123;\n        int res =0;\n        int m = grid.length;\n        int n = grid[0].length;\n        for(int i=0;i&lt;m;i++)&#123;\n            for(int j=0;j&lt;n;j++)&#123;\n                if(grid[i][j] == '1')&#123;\n                    res++;\n                    FloodFill(grid,i,j);\n                &#125;\n            &#125;\n        &#125;\n        return res;\n    &#125;\n    //洪水填充算法，将1周围的所有1都改变为0，最终使得图中的1的数目便是岛屿的数目\n    void FloodFill(char[][] grid, int i, int j)&#123;\n        if(!isValid(i,j,grid)) return;\n        if(grid[i][j] == '0') return;\n        grid[i][j] = '0';\n        FloodFill(grid,i+1,j);\n        FloodFill(grid,i,j+1);\n        FloodFill(grid,i-1,j);\n        FloodFill(grid,i,j-1);\n    &#125;\n    boolean isValid(int i,int j,char[][] grid)&#123;\n        if(i>=0 &amp;&amp; j>=0 &amp;&amp; i&lt;grid.length &amp;&amp; j&lt;grid[0].length)&#123;\n            return true;\n        &#125;\n        return false;\n    &#125;\n&#125;\n\n","slug":"洪水淹没算法","date":"2022-10-31T06:51:29.000Z","categories_index":"","tags_index":"LeetCode初见","author_index":"Samuel"},{"id":"293c17b4d2a4292133cc4d1ffd7f8725","title":"计算机网络","content":"计算机网络的分层模型OSI七层模型\n应用层：计算机上的网络应用，传输应用报文，如HTTP，SMTP\n表示层：用于处理交换信息的表示格式（处理语法和处理语义），格式变换，数据加密解密，数据压缩等功能\n会话层：向表示层建立连接，并传输有序的数据，也就是建立同步SYN\n运输层：负责两个进程的通信，即端到端，如TCP UDP\n网络层：讲分组从源端传到目的端，注重传输过程中的路径选择，如IP\n链路层：讲网络层的数据包封装成帧，如CSMA\n物理层：以比特流的方式传输\n\n上面4层是端到端的，也就是关注的是数据从源主机交付到目的主机，而不管每步是怎么传输的\n下面3层是点到点的，关注数据在传输过程中下一步是怎么走的，也就是路由是如何转发的\nTCP&#x2F;IP四层模型\n应用层（应用层+表示层+会话层）\n运输层\n网络层\n网络接口层（物理层+链路层）\n\n五层参考模型\n应用层\n运输层 \n网络层\n链路层\n物理层\n\n运输层协议UDP特点\n\n无连接状态：UDP无需任何准备就可以传输数据，也没有引入建立连接的时延。并且UDP也不维护连接状态\n精确控制发送数据的时机：应用程序将数据传给UDP，UDP可以立即将数据封装为UDP报文并传递给网络层，而TCP引入了拥塞机制来控制发送方的频率。\n\n报文结构：\nUDP首部仅四个部分\n\n源端口号：2字节\n目的端口号：2字节\n长度：2字节\n校验和：2字节\n\nUDP的校验和：应用数据的所有16比特字之和的反码\nTCP特点\n\n保证发送有效，有序的字节流，是面向流的协议，基于TCP:HTTP\n首部20字节\n\nTCP首部的标志字段\n\nURG&#x3D;1 表明紧急指针字段有效，表示有紧急数据，应该尽快传输\nACK&#x3D;1 表明确认字段有效\nPSH&#x3D;1 表示接收方此时应该尽快交付缓冲区的数据\nRST&#x3D;1 表示TCP连接出现严重错误，必须释放连接，再重新建立连接\nSYN&#x3D;1 表示这是一个连接请求或者连接接受报文\nFIN&#x3D;1 表示此段数据的发送端已经发送完毕最后一个数据段，并要求释放连接\n\nTCP的连接管理三次握手：\n\n开始处于CLOSED，客户机向服务器发送TCP SYN报文段，使用seq指定初始序号，这个请求报文是没有数据的，客户机进入SYN_SENT\n服务器收到客户机的SYN报文段，使用带ACK的SYN报文段来回复，为该连接分配缓冲区和相关变量，使用seq指定相关序号\n客户机接到服务器的SYN报文段，客户机为连接分配缓冲，使用ACK报文段回复（SYN&#x3D;0），可能会有数据，客户机进入ESTABLISHED\n\nSYN ：Synchronize Sequence Numbers 即握手信号\n为什么需要三次：第二步服务器向客户机提供了自己的初始序号，因此再需要一次握手来确认此序号\n四次挥手：\n\n客户机发送TCP FIN报文段到服务器，进入FIN_WAIT_1\n服务器收到FIN，回复ACK，进入FIN_WAIT_2\n服务器发送FIN报文给客户机，此时连接半关闭，\n客户机接收FIN，回复ACK报文，进入TIME_WAIT，时间结束后，释放资源，服务器收到后连接关闭\n\nTCP的有限状态机\n\n\nCLOSED 没有任何连接状态\nLISTEN 侦听状态，等待来自远方TCP端口的连接请求 \nSYN-SENT 在发送连接请求后，等待对方确认 \nSYN-RECEIVED 在收到和发送一个连接请求后，等待对方确认 \nESTABLISHED 代表传输连接建立，双方进入数据传送状态 \nFIN-WAIT-1 主动关闭,主机已发送关闭连接请求，等待对方确认 \nFIN-WAIT-2 主动关闭,主机已收到对方关闭传输连接确认，等待对方发送关闭传输连接请求 \nTIME-WAIT 完成双向传输连接关闭，等待所有分组消失 \nCLOSE-WAIT 被动关闭,收到对方发来的关闭连接请求，并已确认 \nLAST-ACK 被动关闭,等待最后一个关闭传输连接确认，并等待所有分组消失\nCLOSING 如果通信双方同时发送FIN数据包，则同时进行关闭操作，则双方将同时进入TCP_CLOSING状态。 \t具体的，本地发送一个FIN数据包以结束本地数据包发送，如果在等待应答期间，接收到远端发送的FIN数据包，则本地将状态设置为TCP_CLOSING状态。 \t在接收到应答后，再继续装入到TCP_CLOSE_WAIT状态。\n\nTCP的拥塞控制\n当cwnd &lt; ssthresh时，慢启动，指数增长\n当cwnd &gt; ssthresh时，拥塞避免，线性增长\n出现三个冗余确认，快速恢复，ssthresh &#x3D; cwnd&#x2F;2 ; cwnd &#x3D; ssthresh+3*MSS；此后每收到一个冗余ACK就增加一个MSS，直到收到正确的ACK，cwnd&#x3D;ssthresh,进入慢增长\n出现timeout，ssthresh &#x3D; cwnd&#x2F;2 ; cwnd &#x3D; 1MSS\n\nTCP可靠传输机制的保证：\n检验和：用于检验一个分组中的比特错误\n\n定时器：用于超时检验，发生超时事件时重传\n\n序号：为一系列分组编号，可以检测出丢失分组以及冗余分组\n\nACK：用于告诉发送方分组被正确接收\n\nNAK：用于告诉发送方分组未被正确接收\n\n窗口：发送方被限制发送的序号范围\n\n\nGBN 回退N步 go-back-N将序号队列分为四部分\n\n已被确认\n窗口内：已发送，未被确认\n窗口内：可用，未发送\n不可用\n\n若窗口内某一序号n的ACK timeout，则需要重传n之后的所有分组\n当接收到正确序号的ACK时，窗口便前移一个序号\n0123 +rcv ack0 &#x3D;&gt; 1234\n1234 +rcv ack1 &#x3D;&gt; 2345\nack2 timeout &#x3D;&gt;re_send (2345)\n接受方无buffer，失序分组会被丢弃，所以需要重发来重新确认顺序\n选择性重传SR selective repeat接收方添加buffer，按序提交给上层\n发送方只重发没有确认的分组\n为每一个分组都添加timer，缓冲区的存在可以暂存失序但正确的分组\n待重传分组到达并恢复顺序后，再统一交付给上层\nTCP和UDP的区别\n通信即时性：UDP协议的双方随时都可以进行通信，而TCP协议的双方必须经过三次握手后才能通信，并且要经过四次挥手才能断开连接\n对象不同：UDP是面向报文的，接收来自应用层的数据直接加上首部就发送。而TCP是将应用层的数据看作字节流，为其设立缓存，将数据进行打包并发送\n通信数量不同：UDP支持单播，多播，广播；TCP只支持单播\n数据的安全性不同：网络层以上提供的都是不可靠的传输协议，UDP也是。而TCP保证了可靠传输，解决了丢失，乱序等问题\n报文大小不同：UDP首部结构简单，8字节；而TCP报文首部有20字节，最大可达60字节。\n\n如何使UDP可靠运输层不能改变，网络层及下层都无法保证可靠，所以需要从应用层来保证可靠\n核心出发点：在应用层模仿TCP的可靠性传输\n如：\n\n添加添加seq&#x2F;ack机制，确保数据发送到对端\n添加发送和接收缓冲区，主要是用户超时重传\n添加超时重传机制\n\n送端发送数据时，生成一个随机seq&#x3D;x，然后每一片按照数据大小分配seq。数据到达接收端后接收端放入缓存，并发送一个ack&#x3D;x的包，表示对方已经收到了数据。发送端收到了ack包后，删除缓冲区对应的数据。时间到后，定时任务检查是否需要重传数据。\n只不过都是由应用层的软件来实现的，比如使用UDP数据包+序列号，UDP数据包+时间戳等方法，在服务器端进行应答确认机制。\n比如RUDP或者RTP都是基于UDP实现的可靠传输协议。\nQUIC协议HTTP3弃用TCP后，使用了基于UDP的QUIC协议，使用UDP实现了TCP+TLS的特性，且仅需一次握手即可建立可靠连接（0-RTT 握手）\n如何实现可靠传输\n\n包号PKN+确认应答SACK来保证确认接收和数据有序性\n滑动窗口：应用层实现\n拥塞控制：应用层实现\n\n如何避免对头阻塞\n\n弃用TCP\n使用二进制帧格式的数据结构，面向流的传输，给每个请求流都分配一个独立的滑动窗口\n\n\n为什么QQ使用的是UDP协议登陆和保持连接状态采用TCP，和好友之间发送消息采用UDP，内网传文件采用了P2P\n\n当时没有epoll这种可以支持成千上万tcp并发连接的技术，所以使用了应用层封装后的UDP来解决大并发的问题。后面也懒得修改\n国内网络环境水平参差复杂，特别是在千禧年，带宽窄且抖动厉害，此时TCP的等待握手反而会成为劣势，占用宝贵的时间资源和性能资源\nUDP的特性，即时封装即时发送，所以在在应用层的控制下，可以更快地探测和重传。\n\nQQ如何实现可靠：使用上层协议来实现可靠，如果客户端使用UDP协议发出消息后，服务器收到该包，需要使用UDP协议发回一个应答包。如此来保证消息可以无遗漏传输\nHTTP协议超文本传输协议，基于TCP实现\n特点\n可靠\n简单快速：客户向服务器请求服务时，只需传输方法和路径\n灵活：支持任意类型的数据\n无状态，无持久化\n\n请求指令\nGET：从服务器获取一个资源\nPUT：将来自客户端的资源存储到服务器中\nPOST：将客户端数据发送到服务器应用程序中去\nDELETE：从服务器中删除资源\nHEAD：仅发送HTTP首部\n\nGET和POST的区别：\n\nget通过URL传输数据，比如以字段&#x3D;value的形式，以？和&amp;连接。传输少量数据，URL是可见的，可能会泄漏信息。\nPOST可以传输大量数据，且支持标准字符集，可以正确传输中文字符\n前者着重于获取资源，后者着重于发送数据\n\n状态码响应报文都会携带一个状态码来告知请求报文的状态\n\n200：正确返回\n302：重定向\n404：没找到\n\n报文请求报文\n起始行：请求指令，URL，HTTP版本号\n首部：描述浏览器可以接受的字符集，编码方式，期望的语言\n主体：可能会有，也可能没有\n\n响应报文\n起始行：版本号，状态码\n首部：返回的数据类型，长度等信息\n主体：二进制流\n\nCookie身份标识：向服务器表明自己的身份\nCookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。\nCookie存储的数据量有限，且都是保存在客户端浏览器中，大小一般不超过4kb\n\n在服务器发送响应后，会顺带将Set-Cookie也发送给客户端。\n当客户端保存后，之后给服务器发送请求时，都会在请求中包含Cookie的头部\n应用：判断用户是否已经登录网站，购物车\nSession当用户登录时，发送用户名和密码后，服务端查询数据库是否存在该用户，如果有的话，会自动生成一个sessionid，用于记录登录的时间、状态、属于哪个用户，过期时间等信息，并将这些信息保存在服务端\n同时，将这些信息通过cookie的形式将这些数据返回给客户端\n当用户再次登录该服务器，访问其他接口的时候，会自动带上sessionid，服务器接收到请求后会自动查询有没有存储这个sessionid的信息\n\nCookie和Session的区别：\n\nSession因为存储在服务器上，所以安全性比Cookie更高。\nCookie中只能存储ASCII字符串，如果是略微复杂的信息如java 对象，unicode字符串，比较艰难，需要进行编码，而session可以存取任意类型的数据，包括java对象\n隐私策略不同：cookie对客户端可见，客户端的程序是可以窥探到cookie的。而session对客户端是不可见的。\ncookie的过期时间可以设置得很长，而session因为存储在服务器上，出于性能的考虑，不能将存活时间设置得太长\n当并发量高的时候，session的资源消耗会很高，而cookie就不会给服务器造成太大压力\n\n存在的问题\n\n存储在服务器，消耗大量的存储资源\n查询速度会成为瓶颈，导致响应速度慢\n在跨端、跨服务器时，需要session同步\n通过架设数据库集群redis，会导致维护成本高，配置复杂\n\nToken服务器不存储用户数据，而是直接通过加密的方式把用户数据通过令牌的方式返回给客户端，该令牌将会由服务器自己设置。\n每次用户访问时，都会携带这个令牌，用来证明自己的身份，从而得到自己的状态和数据。\n服务器不需要存储用户资源导致资源占用过多的问题，也不需要每次查询从而加快了响应速度，而且传递的方式也由双方协定，不管是否跨域，都可以正常传递。\n\n但是，这种token容易被伪造，因为只要任何人拿到了这种令牌都可以称自己是合法的用户\n从而获取一些私密的信息，此时如果服务器能拥有某种方式使得能证明该用户是合法的就显得极为重要\nsign:由服务端进行设置，且只有服务器知道签名和密钥。\n当用户登录时，服务器提取将用户信息（payload）和header组成新的数据，然后再加上sign进行加密得到一个token。\n当用户发起请求后，由服务器对sign进行解密，然后再结合自己设置的sign进行对比，如果一致，就证明该token合法，如果不一致，该token就是非法的\nJWT是token的一个实现形式，全称为JSON Web Token，本质是一个字符串，他将用户的信息保存到一个json字符串中，然后进行编码后得到一个JWT token，并且这个JWT token带有签名信息，接收后可以校验是否被篡改\nJWT的优势：\n\n数据量小，传输速度快\n以JSON加密保存，跨语言\n不依赖于cookie和session，适合于分布式微服务\n\nJWT的结构header头部是一个描述JWT元数据的JSON对象\n&#123;\n  &quot;alg&quot;: &quot;HS256&quot;,&#x2F;&#x2F;签名使用的算法\n  &quot;typ&quot;: &quot;JWT&quot;&#x2F;&#x2F;令牌名称\n&#125;\n\nPayload有效载荷，提供七个可选字段：\niss：发行人 exp：到期时间 sub：主题 aud：用户 nbf：在此之前不可用 iat：发布时间 jti：JWT ID用于标识该JWT\n&#123;\n  &quot;sub&quot;: &quot;1234567890&quot;,\n  &quot;name&quot;: &quot;Helen&quot;,\n  &quot;admin&quot;: true\n&#125;\n\nSignature签名哈希部分是对上面两部分数据签名，需要使用base64编码后的header和payload数据，通过指定的算法生成哈希，以确保数据不会被篡改。\n首先，需要指定一个密钥（secret）。该密钥仅仅为保存在服务器中，并且不能向用户公开。\n然后，使用header中指定的签名算法（默认情况下为HMAC SHA256）根据以下公式生成签名\nHMACSHA256(base64UrlEncode(header)+\".\"+base64UrlEncode(payload),secret);\n\n在计算出签名哈希后，JWT头，有效载荷和签名哈希的三个部分组合成一个字符串，每个部分用.分隔，就构成整个JWT对象\n\n注意JWT每部分的作用，在服务端接收到客户端发送过来的JWT token之后：\nheader和payload可以直接利用base64解码出原文，从header中获取哈希签名的算法，从payload中获取有效数据signature由于使用了不可逆的加密算法，无法解码出原文，它的作用是校验token有没有被篡改。\n服务端获取header中的加密算法之后，利用该算法加上secretKey对header、payload进行加密，比对加密后的数据和客户端发送过来的签名是否一致，注意secretKey只能保存在服务端。\n对于不同的加密算法secretKey含义有所不同，一般对于MD5类型的摘要加密算法，secretKey实际上代表的是盐值\nHTTP1.0和HTTP1.1的区别长连接​       HTTP1.1支持长连接和请求的流水线处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启长连接keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。\n节约带宽​       HTTP1.0中存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能。HTTP1.1支持只发送header信息（不带任何body信息），如果服务器认为客户端有权限请求服务器，则返回100，客户端接收到100才开始把请求body发送到服务器；如果返回401，客户端就可以不用发送请求body了节约了带宽。\nHOST域​       在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名，HTTP1.0没有host域。随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都支持host域，且请求消息中如果没有host域会报告一个错误（400 Bad Request）。\n缓存处理​       在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。\n错误通知的管理​       在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。\nHTTP1.1和HTTP2.0的区别多路复用​\tHTTP2引入了帧和流的概念，将数据分成一个个的二进制形式的帧。帧上面除了 HTTP 数据，还包含数据长度、流标识符、帧类型等信息。而流就是一个建立连接后的双向的虚拟字节流，流具有并行性，即二进制帧都是并行传输的，无需按序等待。HTTP&#x2F;2 会将所有 HTTP 请求打散成帧，在一个 TCP 连接上做并发请求，充分利用 TCP 带宽。避免了队头阻塞。\n头部数据压缩​       在HTTP1.1中，HTTP请求和响应都是由状态行、请求&#x2F;响应头部、消息主体三部分组成。一般而言，消息主体都会经过gzip压缩，或者本身传输的就是压缩过后的二进制文件，但状态行和头部却没有经过任何压缩，直接以纯文本传输。随着Web功能越来越复杂，每个页面产生的请求数也越来越多，导致消耗在头部的流量越来越大，HTTP2.0对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快。\n服务器推送​       服务端推送是一种在客户端请求之前发送数据的机制。网页使用了许多资源：HTML、样式表、脚本、图片等等。在HTTP1.1中这些资源每一个都必须明确地请求。这是一个很慢的过程。为了改善延迟，HTTP2.0引入了server push，它允许服务端推送资源给浏览器，免得客户端再次创建连接发送请求到服务器端获取。这样客户端可以直接从本地加载这些资源，不用再通过网络。\nHTTPSHTTP+SSL，是可加密的，身份认证的网络协议，更加安全\nSSL&#x2F;TLSHTTP的缺点：报文都是明文的，始终可见，安全性低\n对称加密：双方使用同一种方式来加密和解密，如果加密的规则被破解，那么就不存在密文了\n非对称加密：公钥加密后，必须由私钥解密；反之必须由公钥解密。\nSSL证书：由CA颁发，拥有SSL证书的服务器就可以向客户端提供公钥，支持HTTPS连接\n计算机输入URL后会发生什么应用层客户端发起请求后，浏览器解析域名。首先浏览器会查看本地磁盘的host文件（已被舍弃），是否有对应的IP地址，如果有就直接使用\n如果没有，就会发送一个DNS请求给本地的DNS服务器，本地DNS服务器会查询缓存记录，如果缓存存在，就直接返回结果。如果没有，使用迭代查询，本地DNS服务器逐个请求：根服务器-&gt;顶级域名服务器-&gt;权威域名服务器，最后获得IP地址，存入缓存。获取IP地址后，向目的地址主机的80端口发送请求报文。\n运输层TCP的三次握手，运输层接收应用层的数据并封装为TCP报文，交给网络层\n网络层若该主机为第一次接入该家庭网络或者其他私网，那么在发送TCP报文前还需要借助基于UDP的DHCP协议来获取源IP地址。\nDHCP使用以0.0.0.0为源地址，255.255.255.255为广播地址，向67端口发送发现报文。DHCP服务器接收到后便会向客户端做出响应，最终客户端会收到DHCP ACK报文，其中包含IP地址以及租用期。\n其中对于家庭网络或者其他私网，为了与广域网中的其他子网进行数据传输，还需要借助NAT协议，即网络地址转换，对外：将子网内的IP地址统一转换为在广域网内通信的IP地址；对内：借助NAT转换表将分组转发给内部主机。\n网络层接收TCP报文，将其封装为IP数据报，以IPV4协议为例，IPV4数据报包含了32位的目的和源地址，header总大小为20字节，如果数据报大于了链路层所能承载的最大单元MTU，就要进行数据报分片。\n主机通过ICMP协议获取网络层的传输状态，若目的网络不可达，路由器便会向客户端发送类型为3的ICMP报文来指示错误，其中ICMP报文封装在IP数据报中。\n网络层使用路由器来实现分组交换：每个路由器内部都会动态维护一张转发表，遵循最长前缀匹配原则来找到输出链路，其中转发路径由路由选择算法来实现。\n若使用的是IPV6协议，网络层的整个运输链路只要存在使用IPV4的节点，就需要进行处理，比如将IPV6封装在IPV4数据报内，进行兼容传输。\n网络层关注的是主机到主机或者主机到路由器，链路传输的管理就交给链路层。\n链路层IP数据报被包装为链路层帧，帧使用CRC即循环冗余检测来进行差错检测，使用多路访问协议来避免出现帧碰撞。\nCRC的原理：多项式编码，双方协商好一个多项式，在数据的二进制编码后加上r个零，并使用异或除法除以该多项式，将获得的余数加在数据后，检测时使用这个多项式异或除，若余数为0，则证明无差错。\n多路访问协议：信道划分+随机接入，ALOHA，CSMA\n其中链路层的数据传输依靠MAC地址，MAC地址是扁平化的，即一个网卡就对应一个MAC地址，不会改变，也不会动态分配分层，类似于一个人的DNA。IP地址与MAC地址的转换依靠地址解析协议ARP，MAC地址与IP地址的映射存储于ARP表中，当无法查询到映射时，便会使用MAC广播地址发送查询分组。比如若该主机第一次接入该网络，则需要使用广播帧来获取网关路由器的MAC地址\n链路层的以太网帧转发依赖于链路层交换机：同样具有转发表，交换机具有自学习的特性，若长时间未收到以表内某个地址作为源地址的帧，就会删除该表项，保证转发表内存放的都是高频率使用的表项。\n最终经过DHCP获取IP地址-&gt;ARP查询广播获取网关地址-&gt;DNS服务器获取目的IP地址-&gt;运输层包装TCP报文-&gt;路由选择-&gt;TCP三次握手建立可靠连接后\n应用便可以向该域名发送HTTP GET报文，最终获取到HTTP响应，应用抽取HTML文件，显示到浏览器上。\n","slug":"计算机网络","date":"2022-10-31T06:51:13.000Z","categories_index":"","tags_index":"计算机基础知识","author_index":"Samuel"},{"id":"a7e90bf30b292f0f6e0827bd156cab5e","title":"HashMap","content":"HashCodeHashCode()，在未被重写前，即object类中，是一个Native方法，默认返回JVM生成的随机数，是一个独特值，可以看作是对象的身份ID\n而在String类中，HashCode被重写\npublic int hashCode() &#123;\n       int h = hash;\n       if (h == 0 &amp;&amp; value.length > 0) &#123;\n           char val[] = value;\n\n           for (int i = 0; i &lt; value.length; i++) &#123;\n               h = 31 * h + val[i];\n           &#125;\n           hash = h;\n       &#125;\n       return h;\n   &#125;\n\n为什么使用31作为乘数？？？\n\n31是一个不大不小的奇质数，如果选择偶数计算，会导致乘积运算时的数据溢出。如果选择一个很小的数，那么hashcode会分布在一个很小的范围内，容易造成哈希值的冲突；如果选择一个很大的数，那么可能会超出整型变量的范围。\n在二进制中31等于2&lt;&lt;5-1，那么31*i即为（i&lt;&lt;5）-i，这种乘积运算可以直接通过位移来提升性能，JVM也支持这种优化方式\n不止31，33，37，39，41也可以作为乘数，当我们使用超过50,000个 单词来计算hashcode，这5个乘数都得到的哈希值冲突都小于7，31最小。同时hash的目的就是让数据尽可能分散排布，而以31作为乘数得到的结果分布最为均匀。\n\nHashMap如何计算索引值第一步：计算hashstatic final int hash(Object key) &#123;\n    int h;\n    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n&#125;\n//将key的hashCode值 与 key的hashCode值的高16位(无符号右移)，进行^异或运算，得到一个hash值\n\n原理：引入扰动函数\n扰动函数就是为了增大随机性，减少碰撞，在引入扰动函数后散列表的数据分布更加均匀\n第二步：计算索引//n为数组长度从\nindex = hash &amp; (n-1);\n\n一般的散列算法是以取余%来计算散列值的，但是CPU在做 &#x2F;除 或 %取余运算时，效率是很低的。\n所以使用位运算与，可以实现相同的结果，而且效率更高。\nHashMap的容量HashMap的初始化容量通常设置为2的幂次方大小，未指定大小时默认初始化为16，\n这与hash &amp; (n-1)密切相关，2次幂大小的数与运算与取余运算的效果相同\n要减一，即n-1，我们才能获得一个01111这样的值（在和hash进行与运算的时候才可以获得范围合法的索引）\n若指定一个奇数作为capacity，就会调用tableSizeFor()\n若传入17，向正方向寻找一个最接近17的2的幂次方，即为32\n通过位移运算+或运算将17的每一位都改为1，然后再加1，最后就可以得到32\n扩容//负载因子\nstatic final float DEFAULT_LOAD_FACTOR = 0.75f;\n\n负载因子就是一个阈值，当数据量超过这个阈值后，便要进行扩容\n因为hashcode的特性，一个散列表地址可能对应多个元素，所以即使元素数量大于散列表地址数量，也可能出现无法把散列表占满的情况，在这种情况下，某些位置会出现碰撞，这降低了HashMap的性能\n所以当散列表的位置使用到一定程度时，就需要进行扩容，默认0.75，也就是当使用3&#x2F;4后，就进行扩容\n为什么扩容时会直接乘以2：\n\n以2倍扩容的方式扩容，元素在新表中的位置要么不动，要么原脚标位+扩容长度（二的幂次方偏移量），这样会使扩容的效率大大提高（JDK1.8后扩容不用重新rehash）\n可以使元素均匀的散布hashmap中，减少hash碰撞\n\n转换红黑树的条件\n链表长度大于8\nEntry数组大于64\n\nHashCode()和equals()的关系，如何使用？\nequals()来自Object()类，默认使用&#x3D;&#x3D;来比较地址值，判断引用指向是否是一个对象。通过重写该方法来定义新的规则，比如String类中的equals方法就是逐个比较字符串的字符\nHashCode()来自Object()类，这是一个本地方法，在没有被重写时默认返回对象在堆内存上的独特值，可以认为是对象在堆内存中的身份证号，具有唯一性。重写HashCode后，可以返回计算而出的哈希值，即散列算法，用于确定元素的桶位置，例如HashMap\n如何使用：查找一个元素，当调用散列算法后，快速定位到相应位置，若该桶内有元素，则调用equals()，由于哈希碰撞的存在，HashCode()相等时，不一定就是相应的元素，所以必须调用equals()来判断是否为要查找的元素\n\n&#x3D;&#x3D;和equals的区别&#x3D;&#x3D;：若比较的是基本数据类型，则比较的是数值是否相等；如果比较的是引用数据类型，则比较的是地址值\nequals()：用来比较引用指向的对象地址是否相等。不可用于基本数据类型的比较。\n在Object类中，equals就是由&#x3D;&#x3D;来实现的，可以认为equals在被重写前，两者作用是相等的\n为何重写equals后一定要重写hashcode?根据hashcode的规则，两个对象相等其哈希值一定相等\n所以当重写equals后比如在String类中，两个字面量相同的字符串对象equals后一定返回true\n但是如果不重写hashcode，默认返回JVM生成的独特值，此时两个对象的hashcode可能不会相等，与上文说的规则相矛盾。所以必须重写hashcode来符合这个规则\nHashMap为什么是线程不安全的\nJDK1.7可能造成死循环：由于resize时的数据迁移采用头插法（当时的人觉得比较高效），而头插法会导致链表顺序颠倒（因为先插入的元素在后面），当线程A未完成transfer操作时被挂起，而线程B成功完成了transfer操作，线程A再次获取时间片后继续执行transfer，由于头插法导致链表顺序颠倒，便有可能导致生成环形链表。\nJDK1.8可能造成数据丢失：假设两个线程A、B都在进行put操作，并且hash函数计算出的插入下标是相同的，当线程A执行过程中由于时间片耗尽导致被挂起，而线程B得到时间片后在该下标处插入了元素，完成了正常的插入，然后线程A获得时间片，由于之前已经进行了hash碰撞的判断，所有此时不会再进行判断，而是直接进行插入，这就导致了线程B插入的数据被线程A覆盖了，从而线程不安全。\n\nHashMap如何保证线程安全\nCollections.synchronizedMap()方法传入HashMap的引用变量，返回一个新的Map，这个新的Map就是线程安全的，返回的并不是HashMap，而是map的一种实现。该方法封装了所有不安全的HashMap方法，使用了synchronized方法来进行互斥，和HashTable差不多，该方法使用代理模式new了一个新的类，这个类实现了Map接口。该方法的优点：实现简单；缺点：加锁的粒度较大，性能比较差。被synchronizedMap()包裹的map是可以传入null 键的。而concurrentHashmap不可以。\n使用ConcurrentHashMap，使用了新的锁机制，把hashmap拆分成了多个独立的块，这样在高并发的情况下减少了锁冲突的可能。使用的是NonfairSync，这个特性调用CAS指令来保证原子性和互斥性。如果多个线程恰好操作到同一个segment，只有一个线程得到运行。优点：互斥的代码段小，性能更好，发生锁碰撞的几率低。缺点：代码繁琐。\n\nConcurrenHashMap和HashTableHashTable它的每一个方法都是使用了synchronized同步锁机制，将整个入口锁起来，在多线程的情况下，他整个数组结构的入口就只能一条线程执行完成之后其他线程才能进入，无论下标是否相同，是否存在hash碰撞。\n而ConcurrenHashMap由JDK1.5引入，降低了锁粒度且保证了线程安全\nHashEntry内的成员变量value等都是volatile类型的，这样就保证别的线程对value值的修改，get方法可以马上看到\n在JDK1.7之前，在初始化ConcurrentHashMap的时候，会初始化一个Segment数组,容量为16，Segment内部有一个table数组，存储entry数组+链表的结构\n每个Segment都继承了ReentrantLock类，也就是说每个Segment类本身就是一个锁，使用了分段锁的机制，降低了锁粒度。\n在查找时，定位segment和定位table后，依次扫描这个table元素下的的链表，要么找到元素，要么返回null。\n在JDK1.8之后，引入红黑树且取消了segment设计。使用synchronize关键字，为每一个node对象加同步锁，将锁的粒度将到最低。\nTreeMap和HashMap为什么HashMap是无序的？\n在对HashMap元素进行遍历的时候，是以数组下标为顺序，若该slot下存在链表和红黑树，则向下遍历，直到遍历完该slot下的所有元素。\n众所周知，出现哈希冲突而存放在链表中的元素是不会按照顺序排放的，所以HashMap无序。\n而TreeMap 的底层数据结构是一棵红黑树，红黑树上的元素都是有顺序的\nTreeMap如何实现排序？\n当使用无参构造时TreeMap treeMap = new TreeMap();，默认是升序的\n但是TreeMap的构造方法可以传入一个Comparator对象，重写其中的Compare方法就可以定于以何种规则排序key\n//按照key字母顺序排序\nTreeMap&lt;String,Integer> treeMap = new TreeMap&lt;String,Integer>(new Comparator() &#123;\n            public int compare(Object o1, Object o2) &#123;\n                return ((String)o1).compareTo((String)o2);\n            &#125;\n&#125;);\n//Compare方法的原理：返回-1，无需交换元素，返回1，交换元素\n\nHashMap：适用于Map插入，删除，定位元素；\nTreeMap：适用于按自然顺序或自定义顺序遍历键（key）,性能不如HashMap\nLinkedHashMap和HashMap\n简单的说，LinkedHashMap其实就是在HashMap的基础上再维护了一个双向链表，来保持顺序性\n这个顺序默认是插入顺序，可以将其看作是实现hashmap查找效率的链表\n可以通过设置accessOrder设置为访问顺序\naccessOrder默认为false，当设置为true时，会在每次get或put后将元素移动至双向链表尾部（LRU）\n//使用linkedHashMap模拟实现LRU\nclass LRUCache &#123;\n    int cap;\n    LinkedHashMap&lt;Integer,Integer> cache = new LinkedHashMap&lt;>();\n    public LRUCache(int capacity) &#123;\n        this.cap = capacity;\n    &#125;\n    //加入链表尾部\n    void makeRecently(int key)&#123;\n        int val = cache.get(key);\n        cache.remove(key);\n        cache.put(key,val);\n    &#125;\n    public int get(int key) &#123;\n        if(!cache.containsKey(key)) return -1;\n        makeRecently(key);\n        return cache.get(key);\n    &#125;\n    \n    public void put(int key, int value) &#123;\n        if(cache.containsKey(key))&#123;\n            cache.put(key,value);\n            makeRecently(key);\n            return;\n        &#125;\n        if(cache.size() >= this.cap)&#123;\n            //找到链表头部的key,就是最久未使用的key,调用一次next()就是第一个元素\n            int toBeRemoved = cache.keySet().iterator().next();\n            cache.remove(toBeRemoved);\n        &#125;\n        cache.put(key,value);\n    &#125;\n&#125;\n\n","slug":"HashMap","date":"2022-10-30T14:05:57.000Z","categories_index":"","tags_index":"Java基础知识","author_index":"Samuel"},{"id":"6841591cdd97dd7e1d719dfd22576c72","title":"买股票问题","content":"121. 买卖股票的最佳时机你只能选择某一天买入这只股票，并选择在未来的某一个不同的日子卖出该股票。设计一个算法来计算你所能获取的最大利润。\n输入：[7,1,5,3,6,4]\n输出：5\n解释：在第 2 天（股票价格 &#x3D; 1）的时候买入，在第 5 天（股票价格 &#x3D; 6）的时候卖出，最大利润 &#x3D; 6-1 &#x3D; 5 。\n     注意利润不能是 7-1 &#x3D; 6, 因为卖出价格需要大于买入价格；同时，你不能在买入前卖出股票。\n\nclass Solution &#123;\n    public int maxProfit(int[] prices) &#123;\n        int n = prices.length;\n        //dp数组，dp[i][j],今天是第i天，交易状态为j，利润为dp[i][j];\n        int[][] dp =new int[n][2];\n        for(int i =0;i&lt;n;i++)&#123;\n            //base case\n            if(i==0)&#123;\n                dp[i][0] =0;\n                dp[i][1] = -prices[i];\n                continue;\n            &#125;\n            //0代表已卖出，手中无股票；1代表未卖出，手中持有股票\n            dp[i][0] = Math.max(dp[i-1][0],dp[i-1][1]+prices[i]);\n            dp[i][1] = Math.max(dp[i-1][1],-prices[i]);\n        &#125;\n        return dp[n-1][0];\n    &#125;\n&#125;\n\n122. 买卖股票的最佳时机 II输入：prices &#x3D; [7,1,5,3,6,4]\n输出：7\n解释：在第 2 天（股票价格 &#x3D; 1）的时候买入，在第 3 天（股票价格 &#x3D; 5）的时候卖出, 这笔交易所能获得利润 &#x3D; 5 - 1 &#x3D; 4 。\n     随后，在第 4 天（股票价格 &#x3D; 3）的时候买入，在第 5 天（股票价格 &#x3D; 6）的时候卖出, 这笔交易所能获得利润 &#x3D; 6 - 3 &#x3D; 3 。\n     总利润为 4 + 3 &#x3D; 7 。\n\nclass Solution &#123;\n    //特殊之处：可以进行无数次买卖，所以在进行一次买入时可能总利润已经为正数\n    //而只能进行一次买卖的情况下，在买入前的总利润只能为零\n    public int maxProfit(int[] prices) &#123;\n        int n = prices.length;\n        int[][] dp = new int[n][2];\n        for(int i=0;i&lt;n;i++)&#123;\n            if(i==0)&#123;\n                dp[i][0] = 0;\n                dp[i][1] = -prices[i];\n                continue;\n            &#125;\n            dp[i][0] = Math.max(dp[i-1][0],dp[i-1][1]+prices[i]);\n            //区别在这里\n            dp[i][1] = Math.max(dp[i-1][1],dp[i-1][0]-prices[i]);\n        &#125;\n        return dp[n-1][0];\n    &#125;\n&#125;\n\n123. 买卖股票的最佳时机 III最多进行两笔交易\n输入：prices &#x3D; [3,3,5,0,0,3,1,4]\n输出：6\n解释：在第 4 天（股票价格 &#x3D; 0）的时候买入，在第 6 天（股票价格 &#x3D; 3）的时候卖出，这笔交易所能获得利润 &#x3D; 3-0 &#x3D; 3 。\n     随后，在第 7 天（股票价格 &#x3D; 1）的时候买入，在第 8 天 （股票价格 &#x3D; 4）的时候卖出，这笔交易所能获得利润 &#x3D; 4-1 &#x3D; 3 。\n\nclass Solution &#123;\n    //因为限制了买卖次数，所以需要一个三维的dp数组来进行穷举和状态转移\n    //k代表到第i天内，可以最多进行k次交易\n    public int maxProfit(int[] prices) &#123;\n        int n = prices.length;\n        int max_k = 2;\n        int[][][] dp = new int[n][max_k+1][2];\n        for(int i=0;i&lt;n;i++)&#123;\n            for(int k=max_k;k>0;k--)&#123;\n                if(i==0)&#123;\n                    dp[i][k][0] = 0;\n                    dp[i][k][1] = -prices[i];\n                    continue;\n                &#125;\n                dp[i][k][0] = Math.max(dp[i-1][k][0], dp[i-1][k][1] + prices[i]);\n                //在买入的时候进行k的状态转移，因为一次买入就代表一次交易的开始\n                dp[i][k][1] = Math.max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i]);\n            &#125;\n        &#125;\n        return dp[n-1][max_k][0];\n    &#125;\n&#125;\n\n188. 买卖股票的最佳时机 IV自定义k的情况\n输入：k &#x3D; 2, prices &#x3D; [2,4,1]\n输出：2\n解释：在第 1 天 (股票价格 &#x3D; 2) 的时候买入，在第 2 天 (股票价格 &#x3D; 4) 的时候卖出，这笔交易所能获得利润 &#x3D; 4-2 &#x3D; 2 。\n\nclass Solution &#123;\n    //需要对k进行判断，若k大于某个值便按照无限次来计算，避免了超时的情况\n    public int maxProfit(int k, int[] prices) &#123;\n        int n =prices.length;\n        if(n==0) return 0;\n        if(k>n/2) return ifKequalsInfinite(prices);\n        int[][][] dp = new int[n][k+1][2];\n        for(int i=0;i&lt;n;i++)&#123;\n            //当k=0时，取一些永远不可能的特殊值\n            dp[i][0][0] = 0;\n            dp[i][0][1] = -666;\n        &#125;\n        for(int i=0;i&lt;n;i++)&#123;\n            for(int j=k;j>0;j--)&#123;\n                if(i==0)&#123;\n                    dp[i][j][0] = 0;\n                    dp[i][j][1] = -prices[i];\n                    continue;\n                &#125;\n                dp[i][j][0] = Math.max(dp[i-1][j][0],dp[i-1][j][1]+prices[i]);\n                //如果要保证今天可以进行一次交易，那么到昨天的总交易次数最大只能为j-1，留下一次给今天\n                dp[i][j][1] = Math.max(dp[i-1][j][1],dp[i-1][j-1][0]-prices[i]);\n            &#125;\n        &#125;\n        return dp[n-1][k][0];\n    &#125;\n    //当k足够大时，看作无限大\n    int ifKequalsInfinite(int[] prices)&#123;\n         int n = prices.length;\n        int[][] dp = new int[n][2];\n        for (int i = 0; i &lt; n; i++) &#123;\n            if (i - 1 == -1) &#123;\n            // base case\n            dp[i][0] = 0;\n            dp[i][1] = -prices[i];\n            continue;\n        &#125;\n        dp[i][0] = Math.max(dp[i-1][0], dp[i-1][1] + prices[i]);\n        dp[i][1] = Math.max(dp[i-1][1], dp[i-1][0] - prices[i]);\n    &#125;\n    return dp[n - 1][0];\n    &#125;\n&#125;\n\n","slug":"买股票问题","date":"2022-10-30T13:19:55.000Z","categories_index":"","tags_index":"LeetCode初见","author_index":"Samuel"},{"id":"946249c65165e1a3d66f50e0cb6e89e7","title":"Spring","content":"bean的生命周期Bean的创建分为三个基本步骤\n\n实例化：可以理解为new一个对象，AbstractAutowireCapableBeanFactory中的createBeanInstance方法\n属性注入：可以理解为setter方法完成属性注入，AbstractAutowireCapableBeanFactory的populateBean方法\n初始化：按照Spring的规则配置一些初始化的方法，例如实现AOP代理，注解。AbstractAutowireCapableBeanFactory的initializeBean方法\n\n而Bean的完整生命周期就是在上面三个步骤中穿插执行BeanPostProcessor后置处理器的过程\n\n普通Java对象可以理解为它是用Class对象作为「模板」进而创建出具体的实例，而Spring所管理的Bean不同的是，除了Class对象之外，还会使用BeanDefinition的实例来描述对象的信息，比如说，我们可以在Spring所管理的Bean有一系列的描述：@Scope、@Lazy等等。可以理解为：Class只描述了类的信息，而BeanDefinition描述了对象的信息。\n​\tSpring在启动的时候需要「扫描」在XML/注解/JavaConfig 中需要被Spring管理的Bean信息，随后，会将这些信息封装成BeanDefinition，最后会把这些信息放到一个beanDefinitionMap中，key是beanName，value则是BeanDefinition对象，目前真实对象还没实例化，接着会遍历这个beanDefinitionMap，执行BeanFactoryPostProcessor这个Bean工厂后置处理器\n​\t比如说，我们平时定义的占位符信息，就是通过BeanFactoryPostProcessor的子类PropertyPlaceholderConfigurer进行注入进去，我们也可以自定义BeanFactoryPostProcessor来对我们定义好的Bean元数据进行获取或者修改\n​\tBeanFactoryPostProcessor后置处理器执行完了以后，就到了实例化对象，在Spring里边是通过反射来实现的，一般情况下会通过反射选择合适的构造器来把对象实例化\n//反射创建\nConstructor ctor = Class.getDeclareConstructor();\nObject obj = ctor.newInstance();\n\n​\t实例化只是把对象给创建出来，而对象具体的属性是还没注入的，比如我的对象是UserService，而UserService对象依赖着SendService对象，这时候的SendService还是null的，使用populateBean()进行属性注入，这里便会牵扯出循环依赖的问题\n​\t属性注入后会判断该Bean是否实现了Aware相关的接口，如果存在则填充相关的资源，invokeAwareMethod()，进行BeanName，BeanFactory，BeanClassLoader属性设置\n​\tAware相关的接口处理完之后，就会到BeanPostProcessor后置处理器，BeanPostProcessor后置处理器有两个方法，一个是before，一个是after\n​\tBeanPostProcessor相关子类的before方法执行完，则执行init相关的方法，比如说@PostConstruct、实现了InitializingBean接口、定义的init-method方法\n​\tinit方法执行完之后，就会执行BeanPostProcessor的after方法，AOP就在此实现（关键子类AnnotationAwareAspectJAutoProxyCreator），基本重要的流程已经走完了，我们就可以获取到对象去使用了\n\n对IOC的理解控制反转：一种编程思想，即讲对象交给spring容器来帮我们进行管理。\nDI：依赖注入，把对应的值注入到具体的对象中，即@Autowired或者populateBean\n容器：存放对象，使用Map结构来存储，在spring中一般存在三级缓存，singletonObject存放完整的Bean对象，bean的整个生命周期，从创建到销毁都是由容器来管理。\nAOP是如何实现的AOP是IOC的一个扩展功能，现有IOC，再有AOP，AOP是IOC整个流程的一个扩展点\n\nadvice:切面的工作被描述为通知\nJoinpoint：动态代理所代理实现类中的各个方法称为连接点\nPointcut：代理类中真正增强的方法\nAspect：将通知用到切入点的过程叫切面\n\n在bean的创建过程中有一个步骤可以对bean进行扩展实现，beanPostProcessor后置处理，而AOP就是其中一个扩展\n\n代理对象的创建（advice，切面，切点）\n通过JDK或者CGLIB的方式来生成代理对象\n在执行方法调用的时候，会调用到生成的字节码文件中，会调用DynamicAdvisoredInterceptor类中的intercept方法，从此方法开始执行\n根据之前定义好的通知生成拦截器\n按照拦截器链中以此获取每一个通知，开始进行执行\n\n循环依赖和三级缓存所谓的循环依赖，就是两个或则两个以上的bean互相依赖对方，最终形成闭环\n比如“A对象依赖B对象，而B对象也依赖A对象”，或者“A对象依赖B对象，B对象依赖C对象，C对象依赖A对象”\npublic class A &#123;\n    private B b;\n&#125;\npublic class B &#123;\n    private A a;\n&#125;\n\n在常规情况下，会出现以下情况\n\n通过构建函数创建A对象（A对象是半成品，还没注入属性和调用init方法）。\nA对象需要注入B对象，发现对象池里还没有B对象（对象在创建并且注入属性和初始化完成之后，会放入对象缓存里）。\n通过构建函数创建B对象（B对象是半成品，还没注入属性和调用init方法）。\nB对象需要注入A对象，发现对象池里还没有A对象。\n创建A对象，循环以上步骤。\n\n解决循环依赖的最核心思想：提前曝光\n将半成品A提前放入缓存池，从而可以让B对象成功完成属性注入和初始化，成品B可以让半成品A完成初始化，从而打破了循环依赖\n\n通过构建函数创建A对象（A对象是半成品，还没注入属性和调用init方法）。\nA对象需要注入B对象，发现缓存里还没有B对象，将半成品对象A放入半成品缓存。\n通过构建函数创建B对象（B对象是半成品，还没注入属性和调用init方法）。\nB对象需要注入A对象，从半成品缓存里取到半成品对象A。\nB对象继续注入其他属性和初始化，之后将完成品B对象放入完成品缓存。\nA对象继续注入属性，从完成品缓存中取到完成品B对象并注入。\nA对象继续注入其他属性和初始化，之后将完成品A对象放入完成品缓存。\n\n三级缓存//一级缓存：存放成品bean\nprivate final Map&lt;String, Object> singletonObjects = new ConcurrentHashMap&lt;>(256);\n\n//二级缓存，存放半成品bean，提前曝光的核心\nprivate final Map&lt;String, Object> earlySingletonObjects = new HashMap&lt;>(16);\n\n//三级缓存，存放bean工厂对象，用来生成半成品bean并存入二级缓存中\nprivate final Map&lt;String, ObjectFactory&lt;?>> singletonFactories = new HashMap&lt;>(16);\n\n直接看流程图：\n\n问：这里的第三级缓存有什么用？\n如果我们不考虑AOP的情况下，第三级缓存真没什么用，它直接将实例化阶段创建的对象给返回了。\n如果我们考虑上了AOP，那么流程图会变成：\n\n我们对A进行了AOP代理的话，那么此时getEarlyBeanReference将返回一个代理后的对象，而不是实例化阶段创建的对象，这样就意味着B中注入的A将是一个代理对象而不是A的实例化阶段创建后的对象。\n问：初始化的时候是对A对象本身进行初始化，而容器中以及注入到B中的都是代理对象，这样不会有问题吗？\n不会，这是因为不管是cglib代理还是jdk动态代理生成的代理类，内部都持有一个目标类的引用，当调用代理对象的方法时，实际会去调用目标对象的方法，A完成初始化相当于代理对象自身也完成了初始化。\n问：三级缓存为啥要存一个工厂，而不是直接存一个引用进去呢？\n工厂的目的在于只有真正发生循环依赖的时候，才会去生成代理对象。如果未发生循环依赖，那么就只有一个工厂放那儿，但是不会去通过这个工厂去真正创建对象。\n问：为什么要使用第三级缓存呢，不管有没有循环依赖，我们都提前创建好代理对象，并将代理对象放入缓存，出现循环依赖时，其他对象直接就可以取到代理对象并注入。这样就只会使用两级缓存，不是更方便嘛？\n如果要使用二级缓存解决循环依赖，意味着Bean在构造完后就需要创建代理对象，这样违背了Spring设计原则！！\nSpring结合AOP跟Bean的生命周期，是在Bean创建完全之后通过AnnotationAwareAspectJAutoProxyCreator这个后置处理器来完成的，在这个后置处理的postProcessAfterInitialization方法中对初始化后的Bean完成AOP代理。如果出现了循环依赖，那没有办法，只有给Bean先创建代理，但是没有出现循环依赖的情况下，设计之初就是让Bean在生命周期的最后一步完成代理而不是在实例化后就立马完成代理。\n使用二级缓存：\n\n使用三级缓存：\n\n总结：Spring如何解决循环依赖？\n答：Spring通过三级缓存解决了循环依赖，其中一级缓存为单例池（singletonObjects，一个并发HashMap）,二级缓存为早期曝光对象earlySingletonObjects，三级缓存为早期曝光对象工厂（singletonFactories），二三级缓存均为普通的HashMap。\n当A、B两个类发生循环引用时，在A完成实例化后，就使用实例化后的对象去创建一个对象工厂，并添加到三级缓存中，如果A被AOP代理，那么通过这个工厂获取到的就是A代理后的对象，如果A没有被AOP代理，那么这个工厂获取到的就是A实例化的对象。\n当A进行属性注入时，会去创建B，同时B又依赖了A，所以创建B的同时又会去调用getBean(a)来获取需要的依赖，此时的getBean(a)会从缓存中获取，第一步，先获取到三级缓存中的工厂；第二步，调用对象工工厂的getObject方法来获取到对应的对象，得到这个对象后将其注入到B中。紧接着B会走完它的生命周期流程，包括初始化、后置处理器等。\n当B创建完后，会将B再注入到A中，此时A再完成它的整个生命周期。至此，循环依赖结束！\nJDK和CGLIB动态代理的区别JDK代理使用的是反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。\nCGLIB代理使用字节码处理框架ASM，对代理对象类的class文件加载进来，通过修改字节码生成子类。\nJDK创建代理对象效率较高，执行效率较低，JDK动态代理机制是委托机制，只能对实现接口的类生成代理，通过反射动态实现接口类。\nCGLIB创建代理对象效率较低，执行效率高，CGLIB则使用的继承机制，针对类实现代理，被代理类和代理类是继承关系，所以代理类是可以赋值给被代理类的，因为是继承机制，不能代理final修饰的类。\n如果目标对象实现了接口，默认情况下会采用JDK的动态代理实现AOP，可以强制使用CGLIB实现AOP，如果目标对象没有实现了接口，必须采用CGLIB库，spring会自动在JDK动态代理和CGLIB之间转换。\nJDK动态代理只能为接口创建代理，使用上有局限性。实际的场景中我们的类不一定有接口，此时如果我们想为普通的类也实现代理功能，我们就需要用到CGLIB来实现了。\nJDK代理是不需要依赖第三方的库，只要JDK环境就可以进行代理，需要满足以下要求： 1.实现InvocationHandler接口，重写invoke() 2.使用Proxy.newProxyInstance()产生代理对象 3.被代理的对象必须要实现接口\nCGLIB 必须依赖于CGLIB的类库,需要满足以下要求： 1.实现MethodInterceptor接口，重写intercept() 2.使用Enhancer对象.create()产生代理对象\nCGLIB是一个强大、高性能的字节码生成库，它用于在运行时扩展Java类和实现接口，本质上它是通过动态的生成一个子类去覆盖所要代理的类（非final修饰的类和方法）。\nEnhancer既能够代理普通的class，也能够代理接口。Enhancer创建一个被代理对象的子类并且拦截所有的方法调用（包括从Object中继承的toString和hashCode方法）。Enhancer不能够拦截final方法，例如Object.getClass()方法，这是由于Java final方法语义决定的。基于同样的道理，Enhancer也不能对final类进行代理操作。\n事务Spring将JDBC的事务概念带到了业务层中，同样继承了ACID特性，同样也有四种隔离级别\n只不过开启&#x2F;提交&#x2F;回滚的操作交给Spring来执行，而不用自行编码\n一般只需一个注解@Transactional 修饰方法。那么整个方法的代码块都将以事务的规则执行\n事务传播行为当事务方法被另外一个事务方法调用时，必须指定事务应该如何传播\n例如，方法可能继续在当前事务中执行，也可以开启一个新的事务，在自己的事务中执行。\nREQUIRED如果外部方法开启事务并且是 REQUIRED 的话，所有 REQUIRED 修饰的内部方法和外部方法均属于同一事务 ，只要一个方法回滚，整个事务都需要回滚。如果外部方法没有开启事务的话，REQUIRED 修饰的内部方法会开启自己的事务，且开启的事务相互独立，互不干扰。\nREQUIRES_NEW不管外部方法是否开启事务，REQUIRES_NEW 修饰的内部方法都会开启自己的事务，且开启的事务与外部的事务相互独立，互不干扰。\nNESTED如果当前存在事务，就在当前事务内执行；否则，就执行与 REQUIRED 类似的操作。\nSUPPORTS如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。\nNOT_SUPPORTED以非事务方式运行，如果当前存在事务，则把当前事务挂起。\nMANDATORY如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。\nNEVER以非事务方式运行，如果当前存在事务，则抛出异常。\nSpring事务的实现原理是什么？Spring有两种事务的实现方式，第一是编程式事务，即通过手动编码的方式，创建TransactionTemplate对象进行execute()传入业务代码或者transactionManager对象通过commit()提交业务代码来实现。第二就是声明式事务，即使用注解的形式直接拦截方法，基于AOP。编程式事务的粒度更小，是代码块级别的。而声明式事务的粒度稍大一些是整个方法。\n事务操作是AOP的一个核心体现，当一个方法添加@Transactional后，Spring会基于这个类生成代理对象，当使用这个代理对象的方法时，如果有事务，那么会先关闭连接的autocommit，先执行业务逻辑。若无异常，代理逻辑就会提交。若出现异常，就会进行回滚操作。\n","slug":"Spring","date":"2022-10-26T13:17:18.000Z","categories_index":"","tags_index":"JAVA进阶","author_index":"Samuel"},{"id":"838ae74e3a76757d637de803a615bfd9","title":"MySQL","content":"MySQL关系型数据库，插件式的存储引擎，这种架构可以根据业务的需求和实际需要选择合适的存储引擎。\n\n客户端通过协议与服务器连接，发送查询语句，先检查缓存是否命中，若命中直接返回，否则进行语句解析\n预处理，检查语句是否有语法错误，查询优化（是否会使用索引扫描），生成查询计划，启动查询引擎，开始查询，底层存储引擎调用API获取数据，返回给客户端\nMYSQL默认使用B+树索引\n\n字段选择优先级（由优至劣）\n整型\ntime：定长运算快\nenum：枚举，能约束值，内部由整型存储\nchar：定长，需要考虑字符集\nvarchar：不定长，考虑字符集的转换与排序的校对集，速度慢\ntext：无法使用内存临时表\n\n定长优先。能选整型就不要选字符串，够用就行，不要富余分配空间，尽量避免使用Null\nvarchar最多可以定义65535个字节\n事务的ACID\n原子性：要么全部成功，要么全部失败。由undo_log来保证\n一致性：数据库总是从一个状态转移到另一个状态\n隔离性：最终提交前，其他事务不可见，MVCC\n持久性：事务一旦提交，修改将会永久保存到数据库中，内存+redo_log\n\n范式1NF(第一范式)属性（对应于表中的字段）不能再被分割，也就是这个字段只能是一个值，不能再分为多个其他的字段了。1NF 是所有关系型数据库的最基本要求 ，也就是说关系型数据库中创建的表一定满足第一范式\n\n\n\n\n\n\n\n\n\n如果关系表中的属性不可再细分且属性列不可重复，该关系满足第1范式\n2NF(第二范式)2NF 在 1NF 的基础之上，消除了非主属性对于码的部分函数依赖。如下图所示，展示了第一范式到第二范式的过渡。第二范式在第一范式的基础上增加了一个列，这个列称为主键，非主属性都依赖于主键\n\n\n\n\n\n\n\n\n\n第二范式要求关系表中所有数据都要和关系表的主键有完全函数依赖（即属性不能只和主键有部分依赖关系）\n3NF(第三范式)3NF 在 2NF 的基础之上，消除了非主属性对于码的传递函数依赖 。符合 3NF 要求的数据库设计，基本上解决了数据冗余过大，插入异常，修改异常，删除异常的问题。比如在关系 R(学号 , 姓名, 系名，系主任)中，学号 → 系名，系名 → 系主任，所以存在非主属性系主任对于学号的传递函数依赖，所以该表的设计，不符合 3NF 的要求\n\n\n\n\n\n\n\n\n\n每一个非主属性既不部分依赖于码也不传递依赖于码\n\n1NF：属性不可再分。\n2NF：1NF 的基础之上，消除了非主属性对于码的部分函数依赖。\n3NF：3NF 在 2NF 的基础之上，消除了非主属性对于码的传递函数依赖\n\n四种隔离级别\nread uncommitted：所有事务都可以看见未提交的结果，产生脏读\nread committed：一个事务从开始到提交前，任何数据改变都是不可见的，产生不可重复读问题\nrepeatable read：MySQL默认的隔离级别，解决不可重复读问题，保证同一事物的多个实例在并发读取事务时，会读取到同样的数据行，产生幻读问题（InnoDB的MVCC解决了幻读问题）\nserializable：最高级别的隔离，强制事务排序，不可能相互冲突，其实就是加锁，效率低\n\n存储引擎MyISAM和InnoDB的区别是什么\n\nInnoDB：支持事务，支持外键，聚集索引：文件存储于主键索引的叶子节点上，所以主键索引效率很高，但是辅助索引需要进行回表，并且主键不能过大，因为辅助索引也会存储主键，所以过大的主键会影响索引的大小。最小粒度锁为行锁\nMyISAM：不支持事务，不支持外键，非聚集索引，索引保存的是数据文件的指针，主键索引和辅助索引独立。会创建一个单独的变量保存整个表的行数，读取表行数的速度更快。最小粒度锁为表锁，并发性能不好。\n\n基础架构\nMySQL 主要由下面几部分构成：\n\n连接器： 身份认证和权限相关(登录 MySQL 的时候)。\n查询缓存： 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）\n\n\n\n\n\n\n\n\n\n\n连接建立后，执行查询语句的时候，会先查询缓存，MySQL 会先校验这个 SQL 是否执行过，以 Key-Value 的形式缓存在内存中，Key 是查询预计，Value 是结果集。如果缓存 key 被命中，就会直接返回给客户端，如果没有命中，就会执行后续的操作，完成后也会把结果缓存起来，方便下一次调用。当然在真正执行缓存查询的时候还是会校验用户的权限，是否有该表的查询条件\nMySQL 查询不建议使用缓存，因为查询缓存失效在实际业务场景中可能会非常频繁，假如你对一个表更新的话，这个表上的所有的查询缓存都会被清空。对于不经常更新的数据来说，使用缓存还是可以的。\n\n分析器： 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。\n\n优化器： 按照 MySQL 认为最优的方案去执行。\n\n执行器： 执行语句，然后从存储引擎返回数据。 执行语句之前会先判断是否有权限，如果没有权限的话，就会报错。\n\n日志模块：在server层是binlog归档日志模块\n\n插件式存储引擎 ： 主要负责数据的存储和读取，采用的是插件式架构，支持 InnoDB、MyISAM、Memory 等多种存储引擎\n\n查询语句的执行流程如下：权限校验（如果命中缓存）—&gt;查询缓存—&gt;分析器—&gt;优化器—&gt;权限校验—&gt;执行器—&gt;引擎\n\n更新语句执行流程如下：分析器—-&gt;权限校验—-&gt;执行器—&gt;引擎—redo log(prepare 状态)—&gt;binlog—&gt;redo log(commit状态)\n\n\n索引为什么要有索引\n一般的应用系统读写比例大约在10：1左右，而且数据的插入和更新出现性能问题的几率小于查询。在生产环境中，最容易出现问题的就是查询操作，因此对查询性能的优化就显得十分重要。\n索引的本质就是一个满足某种查找算法的数据结构，常见的有BST，AVL，红黑树，Btree，B+树等等\n这些结构以某种方式指向数据（索引结点指向数据记录物理地址的指针）\n\n索引大大减少了服务器需要扫描的数据量，提高了检索效率\n避免排序，减少CPU消耗\n将随机IO转换为顺序IO\n\n索引也是一张表，保存了主键和索引，指向了实体表，也需要占用内存。索引存储于外存，所以索引的查询也需要磁盘IO开销,访问外存的时间成本大约是内存的十万倍\n虽然提高了查询速度，但是在对实体表进行更新时，索引也需要进行相应的维护更新，而索引的维护也需要开销，降低了更新表的速度\nHASH索引Memory引擎默认Hash索引\n等值查询很快，计算的hash值与对应的行指针一并存入表中，哈希碰撞的元素以链表的形式相连。也不支持排序，以及模糊查询，并且由于散列算法，键值对的存储是无序的，所以不支持范围查询。\nB+树索引InnoDB，MyISAM默认是B+树\n考虑到IO时十分高昂的操作，且数据库动辄百万级数据量，所以当一次IO时，常常以页作为单位来读取数据，当读取一页的数据至内存缓冲区时，实际上才发生了一次IO，所以控制IO的次数对于索引效率的提升，至关重要。\nB+树的特点：\n\n除叶子结点外的子节点：只起到索引的作用，仅存储指针，不存储信息\n所有信息存储于叶子结点，所有叶子结点在底部链接形成一个双向链表（范围查询）\n\n在InnoDB中，叶子节点的容量默认为一页16KB\n叶子节点结构(聚簇索引为例)：页目录（主键）+用户数据区域（单向链表，通过主键排序，在插入数据的时候便会排序）\n非叶子节点结构：页指针+指向的该页的最小主键值\nMYSQL的各种索引\n主键索引：一张表一个主键索引，通常与表一起创建。\n唯一索引：如果能确定某个数据列将只包含彼此各不相同的值，在为这个数据列创建索引的时候就应该用关键字UNIQUE把它定义为一个唯一索引。这么做的好处：一是简化了MySQL对这个索引的管理工作，这个索引也因此而变得更有效率；二是MySQL会在有新记录插入数据表时，如果字段的值已经出现过了，MySQL将拒绝插入那条新记录。也就是说，唯一索引可以保证数据记录的唯一性。事实上，在许多场合，人们创建唯一索引的目的往往不是为了提高访问速度，而只是为了避免数据出现重复。\n普通索引：建立在普通字段上的索引，唯一任务是加快对数据的访问速度。因此，应该只为那些最经常出现在查询条件（WHEREc）或排序条件（ORDERBY）中的数据列创建索引。只要有可能，就应该选择一个数据最整齐、最紧凑的数据列（如一个整数类型的数据列）来创建索引。\n复合索引：字符类型字段的前几个字符建立，可以覆盖多个数据列，遵循最左匹配原则，可能会因为order by失效。\n\n三星索引：衡量一个索引是否达到最佳表现的三个维度\n\n第一星：where后面的等值谓词，可以匹配索引列的顺序：意义在于谓索匹配的越多，索引片越窄，最终扫描的数据行也是越小。把 WHERE 后的等值条件列作为索引最开头的列，如此，必须扫描的索引片宽度就会缩至最短。\n第二星：order by的排序是否和索引的顺序一致：意义在于避免进行额外的排序，增加消耗。将 ORDER BY 列加入到索引中，保持列的顺序\n第三星：select的字段是否都为索引列：意义在于避免每一个索引行查询，都需要去聚簇索引进行一次随机IO查询。将查询语句中剩余的列都加入到索引中。\n\n普通索引和唯一索引有什么区别？\n概念上的不同：普通索引可以重复。而唯一索引和主键一样，不可以重复，但在一张表里面只能有一个主键，不能为空，唯一索引可有多个。唯一索引可有一条记录为null。在学校，一般用学号做主键，身份证号作为唯一索引\n查询实现的不同：若查询语句为\nselect id from T where k&#x3D;4\n\n普通索引：查找到满足条件的第一个记录后，继续查找下个记录，直到碰到第一个不满足k&#x3D;4的记录。\n唯一索引：查到第一个满足条件的，就停止搜索。\n若重复数据很多，普通索引多了一次“查找和判断下一条记录”的操作，可能会多次IO，但是总体性能其实差别不大\n更新性能不同：往表中插入一个新记录，InnoDB会有什么反应？\n若在内存中，普通索引直接插入，而唯一索引会判断一次是否有冲突，再插入。判断的性能消耗可以不计\n若不在内存中，普通索引会将数据记录在change buffer；唯一索引会将数据页读入内存再插入。众所周知数据库的IO成本很高，所以普通索引更新数据的性能是要更优的。\n总结：若更新性能优先级更高，选择普通索引。\n主键索引(聚簇索引)\n二级索引(辅助索引)同样是B+树，以非主键而是以自定义规则的索引，以满足不同的查询需求，属于非聚集索引。\n叶子节点的用户数据区不再存储完整记录，而是存储主键+部分记录。\n所以使用辅助索引有时候需要进行回表，即部分记录无法满足查询需求，需要使用主键来重新到主键索引查找。\n联合索引使用表中的多个字段创建索引，就是 联合索引，也叫 组合索引 或 复合索引\n什么情况下设置了复合索引，但不会使用？\n\n没有符合最左匹配原则\n字段进行了隐私数据类型转化\n引擎估算走辅助索引的时间反而比全表扫描的时间更长\n\n什么是最左匹配原则？\n对于复合索引，若有字段123，若查询时省略字段1，则无法使用索引。\n因为数据库依据联合索引最左的字段来构建 B+ 树，叶子节点的排序是以字段123的顺序进行的，只有先确定了前一个（左侧的值）后，才能确定下一个值。a有序，b才能有序，若a省略，则无法有序查找bc。\n所以，我们在使用联合索引时，可以将区分度高的字段放在最左边，这也可以过滤更多数据\n非聚簇索引的优缺点？\n优点：更新代价比聚集索引要小 。非聚集索引的更新代价就没有聚集索引那么大了，非聚集索引的叶子节点是不存放数据的\n缺点：\n\n跟聚集索引一样，非聚集索引也依赖于有序的数据\n可能会二次查询(回表) :这应该是非聚集索引最大的缺点了。 当查到索引对应的指针或主键后，可能还需要根据指针或主键再到数据文件或表中查询\n\n聚簇索引的优缺点？\n优点：聚集索引的查询速度非常的快，因为整个 B+树本身就是一颗多叉平衡树，叶子节点也都是有序的，定位到索引的节点，就相当于定位到了数据\n缺点：\n\n依赖于有序的数据 ：因为 B+树是多路平衡树，如果索引的数据不是有序的，那么就需要在插入时排序，如果数据是整型还好，否则类似于字符串或 UUID 这种又长又难比较的数据，插入或查找的速度肯定比较慢。\n更新代价大 ： 如果对索引列的数据被修改时，那么对应的索引也将会被修改，而且聚集索引的叶子节点还存放着数据，修改代价肯定是较大的，所以对于主键索引来说，主键一般都是不可被修改的\n\nMYSQL默认使用B+树，为啥要用B+树，不用B树？\n因为两者都是存储于磁盘，而IO是花销很大的操作，InnoDB每次申请磁盘空间时都会申请若干条连续的磁盘块来组成一页，并放入内存，读取索引，放回磁盘，不断重复，直到找到数据。\n所以如果每次申请到的数据都能有助于定位到所需数据，这将会减少IO次数，提高查询效率。\n对于B树，因为B树的每一个结点都会存储键，指针和数据，每个磁盘块的信息存储能力有限，树的高度也会更高，增加了IO次数，所以B树的查询效率波动很大。\n而B+树的非叶子结点只存储键，所以B+树的非叶子结点可以存储更多的信息，降低了树高度，平均一次IO可以获取更多索引，所以B+树更适合外存索引，且查询效率更稳定\n其中在 MySQL 底层对 B+ 树进行进一步优化：\n叶子节之间是双向链表，节点内部是单向链表，且在链表的头结点和尾节点也是循环指向的。（范围查询的关键）\n为什么不用红黑树？\n无论是二叉树还是红黑树，都会因为树的深度过深而导致IO次数变多，效率不高\nInnoDB一颗高度为3的B+树可以存放多少行数据？\nInnoDB的一页大小为16k，若一行数据的大小为1k，那么可以存储16行数据\n若主键ID为bigint型，8字节，指针为6字节，总大小为14字节，那么一页可以存储1170个指针\n所以数据量大约为1170  * 1170 *  16&#x3D; 大约两千万\nMySQL的锁按锁的属性分共享锁：即读锁\n排他锁：即写锁\n按锁的粒度分行级锁：锁住一行或者多行记录\n表级锁：给整个表加锁\n页级锁：介于行级锁和表锁的一种锁，一次锁定相邻的一组记录\n记录锁：行级锁的一种，锁住一条记录，避免数据在查询时被修改的不可重复读问题\n间隙锁：行级锁的一种，只出现在Repeatable read的事务中，解决了幻读的问题\n临键锁：InnoDB的行锁默认算法，就是记录锁和间隙锁的结合版，会锁住查询的记录，同时也会锁住范围内的所有间隙空间\n按锁的状态分意向共享锁\n意向排他锁\nMySQL的主从同步MySQL内建的复制功能是构建大型，高性能应用程序的基础。\n将MySQL的数据分布到多个系统上去，这种分布的机制，是通过将MySQL的某一台主机的数据复制到其它主机（slave）上，并重新执行一遍来实现。\n复制过程中一个服务器充当主服务器，而一个或多个其它服务器充当从服务器。\n主服务器将更新写入二进制日志文件，并维护文件的一个索引以跟踪日志循坏，这些日志可以记录发送到从服务器的更新。\n当一个从服务器连接主服务器时，它通知主服务器从服务器在日志中读取的最后一次成功更新的位置。从服务器接收从那时起发生的任何更新，然后封锁并等待主服务器通知的更新。\nMySQL支持哪些复制\n基于语句的复制：在主服务器上执行的sql语句，在从服务器上执行同样的语句。MySQL默认采用基于语句的复制，效率比较高。一旦发现没法精确复制时，会自动选着基于行的复制。\n基于行的复制：把改变的内容复制过去，而不是把命令在从服务器上执行一遍。从MySQL 5.0开始支持\n混合类型的复制：默认采用基于语句的复制，一旦发现基于语句的无法精确复制时，就会采用基于行的复制\n\n为什么需要主从同步\n若出现锁表不能读的情况，此时可以使用主从复制，让主库负责写，从库负责读，这样就不影响业务的正常运行\n当IO频率越来越大时，业务量越来越大时，单机已无法满足，此时多库的处理可以提高IO的性能\n\n日志（bin log，redo log和undo log）MySQL 日志 主要包括错误日志、查询日志、慢查询日志、事务日志、二进制日志几大类。其中，比较重要的还要属二进制日志 binlog（归档日志）和事务日志 redo log（重做日志）和 undo log（回滚日志）\n\nredo log（重做日志）redo log（重做日志）是InnoDB存储引擎独有的，它让MySQL拥有了崩溃恢复能力\nMySQL 中数据是以页为单位，你查询一条记录，会从硬盘把一页的数据加载出来，加载出来的数据叫数据页，会放入到 Buffer Pool 中。\n后续的查询都是先从 Buffer Pool 中找，没有命中再去硬盘加载，减少硬盘 IO 开销，提升性能。\n更新表数据的时候，也是如此，发现 Buffer Pool 里存在要更新的数据，就直接在 Buffer Pool 里更新。\n然后会把“在某个数据页上做了什么修改”记录到redo log buffer里，接着刷盘到 redo log 文件里\n\n刷盘时机InnoDB 存储引擎为 redo log 的刷盘策略提供了 innodb_flush_log_at_trx_commit 参数，它支持三种策略：\n\n设置为 0 的时候，表示每次事务提交时不进行刷盘操作，依靠刷盘线程进行\n设置为 1 的时候，表示每次事务提交时都将进行刷盘操作（默认值）\n设置为 2 的时候，表示每次事务提交时都只把 redo log buffer 内容写入 page cache\n\ninnodb_flush_log_at_trx_commit 参数默认为 1 ，也就是说当事务提交时会调用 fsync 对 redo log 进行刷盘\n另外，InnoDB 存储引擎有一个后台线程，每隔1 秒，就会把 redo log buffer 中的内容写到文件系统缓存（page cache），然后调用 fsync 刷盘\n也就是说，一个没有提交事务的 redo log 记录，也可能会刷盘\n除了后台线程每秒1次的轮询操作，还有一种情况，当 redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动刷盘\n\n\n为0时，如果MySQL挂了或宕机可能会有1秒数据的丢失\n\n为1时， 只要事务提交成功，redo log记录就一定在硬盘里，不会有任何数据丢失。\n如果事务执行期间MySQL挂了或宕机，这部分日志丢了，但是事务并没有提交，所以日志丢了也不会有损失\n\n为2时， 只要事务提交成功，redo log buffer中的内容只写入文件系统缓存（page cache）。\n如果仅仅只是MySQL挂了不会有任何数据丢失，因为已经写入主机的内存里了，但是宕机可能会有1秒数据的丢失\n\n\n日志文件组硬盘上存储的 redo log 日志文件不只一个，而是以一个日志文件组的形式出现的，每个的redo日志文件大小都是一样的。\n比如可以配置为一组4个文件，每个文件的大小是 1GB，整个 redo log 日志文件组可以记录4G的内容。\n它采用的是环形数组形式，从头开始写，写到末尾又回到头循环写，如下图所示\n\n在个日志文件组中还有两个重要的属性，分别是 write pos、checkpoint\n\nwrite pos 是当前记录的位置，一边写一边后移\n\ncheckpoint 是当前要擦除的位置，也是往后推移\n\n\n\n每次刷盘 redo log 记录到日志文件组中，write pos 位置就会后移更新。\n\n每次 MySQL 加载日志文件组恢复数据时，会清空加载过的 redo log 记录，并把 checkpoint 后移更新。\n\nwrite pos 和 checkpoint 之间的还空着的部分可以用来写入新的 redo log 记录\n\n如果 write pos 追上 checkpoint ，表示日志文件组满了，这时候不能再写入新的 redo log 记录，MySQL 得停下来，清空一些记录，把 checkpoint 推进一下\n\n\n为什么不直接把修改后的数据页直接刷盘？而是要记录redo log?\n实际上，数据页大小是16KB，刷盘比较耗时，可能就修改了数据页里的几 Byte 数据，没有必要将整个数据页落盘。\n而且数据页刷盘是随机写，因为一个数据页对应的位置可能在硬盘文件的随机位置，所以性能很差。\n如果是写 redo log，一行记录可能就占几十 Byte，只包含表空间号、数据页号、磁盘文件偏移量、更新值，再加上是顺序写，所以刷盘速度很快。\n所以用 redo log 形式记录修改内容，性能会远远超过刷数据页的方式，这也让数据库的并发能力更强\nbin log（归档日志）redo log 它是物理日志，记录内容是“在某个数据页上做了什么修改”，属于 InnoDB 存储引擎。\n而 binlog 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID&#x3D;2 这一行的 c 字段加 1”，属于MySQL Server 层。\n不管用什么存储引擎，只要发生了表数据更新，都会产生 binlog 日志\nbin log的作用：主从同步\n可以说MySQL数据库的数据备份、主备、主主、主从都离不开binlog，需要依靠binlog来同步数据，保证数据一致性\n\nbinlog会记录所有涉及更新数据的逻辑操作，并且是顺序写\n记录格式binlog 日志有三种格式，可以通过binlog_format参数指定。\n\nstatement\nrow\nmixed\n\n指定statement，记录的内容是SQL语句原文，比如执行一条update T set update_time=now() where id=1，记录的内容如下\n\n同步数据时，会执行记录的SQL语句，但是有个问题，update_time=now()这里会获取当前系统时间，直接执行会导致与原库的数据不一致。\n为了解决这种问题，我们需要指定为row，记录的内容不再是简单的SQL语句了，还包含操作的具体数据，记录内容如下\n\nrow格式记录的内容看不到详细信息，要通过mysqlbinlog工具解析出来。\nupdate_time=now()变成了具体的时间update_time=1627112756247，条件后面的@1、@2、@3 都是该行数据第 1 个~3 个字段的原始值（假设这张表只有 3 个字段）。\n这样就能保证同步数据的一致性，通常情况下都是指定为row，这样可以为数据库的恢复与同步带来更好的可靠性。\n但是这种格式，需要更大的容量来记录，比较占用空间，恢复与同步时会更消耗IO资源，影响执行速度。\n所以就有了一种折中的方案，指定为mixed，记录的内容是前两者的混合。\nMySQL会判断这条SQL语句是否可能引起数据不一致，如果是，就用row格式，否则就用statement格式\n写入机制binlog的写入时机也非常简单，事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中。\n因为一个事务的binlog不能被拆开，无论这个事务多大，也要确保一次性写入，所以系统会给每个线程分配一个块内存作为binlog cache\n我们可以通过binlog_cache_size参数控制单个线程 bin log cache 大小，如果存储内容超过了这个参数，就要暂存到磁盘（Swap）\n\n\n上图的 write，是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快\n上图的 fsync，才是将数据持久化到磁盘的操作\n\nwrite和fsync的时机，可以由参数sync_binlog控制，默认是0。\n\n为0的时候，表示每次提交事务都只write，由系统自行判断什么时候执行fsync\n\n虽然性能得到提升，但是机器宕机，page cache里面的 binlog 会丢失。\n为了安全起见，可以设置为1，表示每次提交事务都会执行fsync，就如同 redo log 日志刷盘流程 一样\n\n最后还有一种折中方式，可以设置为N(N&gt;1)，表示每次提交事务都write，但累积N个事务后才fsync\n\n\n两阶段提交redo log（重做日志）让InnoDB存储引擎拥有了崩溃恢复能力。\nbinlog（归档日志）保证了MySQL集群架构的数据一致性\n虽然它们都属于持久化的保证，但是侧重点不同。\n在执行更新语句过程，会记录redo log与binlog两块日志，以基本的事务为单位，redo log在事务执行过程中可以不断写入，而binlog只有在提交事务时才写入（刷盘），所以redo log与binlog的写入时机不一样\n\n如果bin log在写入时出了问题，而redo log无问题，则在MySQL恢复数据时主的值为redo中的操作值，而其他如SQL从的值则会跟随binlog恢复而无改变造成数据不一致的问题\n为了解决两份日志之间的逻辑一致问题，InnoDB存储引擎使用两阶段提交方案\n原理很简单，将redo log的写入拆成了两个步骤prepare和commit，这就是两阶段提交\n使用两阶段提交后，写入binlog时发生异常也不会有影响，因为MySQL根据redo log日志恢复数据时，发现redo log还处于prepare阶段，并且没有对应binlog日志，就会回滚该事务\n如果redo log设置commit阶段发生异常，那会不会回滚事务呢？\n\n并不会回滚事务，它会执行上图框住的逻辑，虽然redo log是处于prepare阶段，但是能通过事务id找到对应的binlog日志，所以MySQL认为是完整的，就会提交事务恢复数据\nundo log我们知道如果想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行回滚，在 MySQL 中，恢复机制是通过 回滚日志（undo log） 实现的，所有事务进行的修改都会先记录到这个回滚日志中，然后再执行相关的操作。如果执行过程中遇到异常的话，我们直接利用 回滚日志 中的信息将数据回滚到修改之前的样子即可！并且，回滚日志会先于数据持久化到磁盘上。这样就保证了即使遇到数据库突然宕机等情况，当用户再次启动数据库的时候，数据库还能够通过查询回滚日志来回滚将之前未完成的事务。\n另外，MVCC 的实现依赖于：隐藏字段、Read View、undo log。在内部实现中，InnoDB 通过数据行的 DB_TRX_ID 和 Read View 来判断数据的可见性，如不可见，则通过数据行的 DB_ROLL_PTR 找到 undo log 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 Read View 之前已经提交的修改和该事务本身做的修改\n总结MySQL InnoDB 引擎使用 redo log保证事务的持久性，使用 undo log 来保证事务的原子性。\nMySQL数据库的数据备份、主备、主主、主从都离不开bin log，需要依靠bin log来同步数据，保证数据一致性\nredo log和bin log有什么区别？\n\n层次不同：bin log是在存储引擎的上层产生的，无论是怎么样的存储引擎，对数据库的修改都会产生二进制日志。而redo log是在存储引擎层产生的，innoDB独占，只记录该存储引擎对表的修改，产生时间晚于bin log\n记录内容的不同：MySQL的bin log是逻辑日志，其记录是对应的SQL语句，记录顺序与提交顺序有关，是面向操作者的逻辑顺序。而innoDB存储引擎层面的redo log日志是物理日志，redo log记录的是物理页的修改情况，如空间号、数据页号、磁盘文件偏移量，是面向物理页的顺序。\n记录时机不同：bin log只在每次事务提交的时候一次性写入缓存中的日志文件。而redo log保证在发出事务提交指令时，先向缓存中的redo log写入日志，写入完成后才执行提交动作，两者通过二阶段提交来保证一致性。\n\nMySQL的锁机制记录锁记录锁是封锁这一条记录，阻止其他事务插入，更新，删除这一条记录\nSELECT * FROM &#96;test&#96; WHERE &#96;id&#96;&#x3D;1 FOR UPDATE;\n\n间隙锁间隙锁是封锁索引记录中的间隙，或者第一条索引记录之前或者之后的范围的数据，间隙锁面向的是范围，所以是左开右开区间\n产生条件：RR隔离级别\n对唯一索引进行操作：\n\n对于指定查询某一条记录的加锁语句，如果该记录不存在，会产生记录锁和间隙锁，如果记录存在，则只会产生记录锁，如：WHERE id = 5 FOR UPDATE;\n对于查找某一范围内的查询语句，会产生间隙锁，如：WHERE id BETWEEN 5 AND 7 FOR UPDATE;\n\n对普通索引进行操作：\n\n在普通索引列上，不管是何种查询，只要加锁，都会产生间隙锁，这跟唯一索引不一样；\n在普通索引跟唯一索引中，数据间隙的分析，数据行是优先根据普通索引排序，再根据唯一索引排序。\n\n例如表中有6条记录，其中索引d分别为0，5，10，15，20，25\n执行 select * from t where d=5 for update，就不止是给数据库中已 有的6个记录加上了行锁，还同时加了 7 个间隙锁。、\n比如（0，5）区间内被加上间隙锁，这个区间内无法插入新记录，一定程度上避免了幻读，但是并没有完全解决幻读。\n在RC级别下，间隙锁会失效\n1. \n临键锁间隙锁和行锁合称临键锁（ next-key lock），每个 next-key lock 是前开后闭区间，同样只在RR级别下有效\n\n若对存在的记录加锁，则会锁住前后两个区间的内容\n若对不存在的记录加锁，则会锁住该记录所在区间的内容\n\nMVCCMulti-Version Concurrency Control多版本并发控制，实现对数据库的并发访问，实现读写冲突不加锁，非阻塞并发读。\n数据库的并发有三种场景\n\n读读：不存在任何问题，不需要并发控制\n读写：有线程安全问题，可能会造成脏读，幻读，不可重复读等问题\n写写：有线程安全问题，可能存在更新丢失的问题\n\nMVCC的实现原理就是为事务分配单项增长的时间戳，为每个修改保存一个版本，版本与时间戳相关联，解决了脏读，幻读，不可重复读的问题，但是不能解决更新丢失的问题，可以认为MVCC是行级锁的一个变种，但是它在很多情况下避免了加锁操作，因此开销更低\n当前读也叫锁定读Locking Read，读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁，比如update 、delete 、insert\n快照读也叫普通读Consistent Read，就是单纯的select语句，但不包括for update，就是不加锁的非阻塞读，前提是不使用serializable的隔离级别，实现原理即MVCC\n实现原理隐藏字段每行记录除了自定义的字段外，还有数据库隐式定义的字段\nDB_TRX_ID6字节，最近修改事务的ID，即创建这条记录或者最后一次修改这条记录的事务ID\nDB_ROLL_PTR\n7字节，回滚指针，指向这条记录的上一个版本，用于配合undolog\nDB_ROW_ID\n6字节，隐藏的主键，如果数据表没有主键，innoDB就会自动生成一个row_id\nundo log即回滚日志，即进行插入，更新，删除操作后生成的记录链\n当进行insert时，产生的undo log只在事务回滚的时候需要，可以在事务提交后被丢弃\n当进行update和delete操作时，undo log不仅在事务回滚时需要，在快照读时也需要，所以必须保留，只有在回滚或者快照读不涉及该日志时，undo log才会被purge线程清除（若delete_bit为true，且DB_TRX_ID相对于purge线程的read view可见，那么这条记录就一定可以被清除）\n\n由上图可知，不同事物或者相同事物对同一条记录的修改，就会导致该记录的undolog生成一条记录版本的线性链，链首就是最新的旧记录，链尾就是最早的旧记录\nRead ViewRead View是实现repeatable read的基础，当事务进行快照读的时候会产生一个读视图，用来对当前事务的可见性进行判断，也就是说，事务会将生成的Read View作为条件来判断当前事务能够看见哪个版本的数据，有可能读到最新的数据，也有可能读到undolog里面的某个版本的数据。\nRead View的可见性算法Read View的三个全局属性：\n\ntrx_list：事务列表，即视图生成时刻系统正活跃未提交的事务ID\nup_limit_id：记录事务列表中ID最小的ID\nlow_limit_id：视图生成时刻系统尚未分配的下一个事务（例如事务123正在活跃，事务4已提交，此时下一个事务ID就是5）\n\n具体的算法如下\n\n取出当前最新记录的DB_TRX_ID，即当前事务ID\n比较DB_TRX_ID&lt;up_limit_id，如果小于则说明当前事务能看见DB_TRX_ID所在的记录，如果大于等于就进入下一个判断\n判断DB_TRX_ID&gt;&#x3D;low_limit_id，如果大于等于，代表DB_TRX_ID所在的记录在readView生成后才出现，对于当前事务肯定不可见，如果小于，进入下一个判断\n判断DB_TRX_ID是否在活跃事务列表中，如果在，说明在视图生成时刻，该事务还没有提交，当前事务无法看见。若不在，说明以及提交，修改的结果可以看见（除自己以外的活跃trx_id都不可见）\n\nRC，RR级别下的视图在RR级别下某个事务对记录的第一次快照读会创建一个视图，此后在进行快照读时都会使用同一个视图，所以无论是否有其他事务对记录进行了修改，使用的都是这个视图，修改是不可见的，所以实现了可重复读的级别\n在RC级别下，每次快照读都会生成一个新的视图，所以在RC级别下总是可以看见其他事务的提交\n总结：MVCC其实就是在事务进行并发读写时提供一个快照，事务只能看见符合可见性的版本链内的记录，从而实现了并发读写的隔离性。\nMVCC解决幻读了嘛\n\n\n\n\n\n\n\n\n幻读【前后多次读取，数据总量不一致】\n\n快照读：快照读就是普通的select语句，通过MVCC的方式解决了幻读，MVCC为保证了事务执行过程中看到的数据是一致的，使用ReadView和可见性算法可以实现即使有新记录插入，当前事务也是看不到的。\n当前读：除了select语句外的所有操作都是当前读，当前读使用临键锁来避免幻读，当执行 select … for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞。\n\n但是在RR级别下，仍然有一些情况会出现幻读\n第一种情况：同一事务，使用update导致快照读生成的ReadView被更改\n若在事务开始执行之前，表中是没有id&#x3D;5的这条记录的，所以查询不到\n然后事务 B 插入一条 id &#x3D; 5 的记录，并且提交了事务\n此时，事务 A 更新 id &#x3D; 5 这条记录，事务 A 看不到 id &#x3D; 5 这条记录，但是他去更新了这条记录，然后再次查询 id &#x3D; 5 的记录，事务 A 就能看到事务 B 插入的纪录了，幻读就是发生在这种违和的场景。\n\n\n总结：\n\n在可重复读隔离级别下，事务 A 第一次执行普通的 select 语句时生成了一个 ReadView，之后事务 B 向表中新插入了一条 id &#x3D; 5 的记录并提交。\n接着，事务 A 对 id &#x3D; 5 这条记录进行了更新操作，在这个时刻，这条新记录的DB_TRX_ID的值就变成了事务 A 的事务 id。\n之后事务 A  再使用普通 select 语句去查询这条记录时就可以看到这条记录了，于是就发生了幻读。\n\n因为这种特殊现象的存在，所以我们认为 MySQL Innodb 中的 MVCC 并不能完全避免幻读现象。\n第二种情况：同一事务，先快照读，再当前读导致幻读\nT1 时刻：事务 A 先执行快照读语句：select * from t_test where id &gt; 100 得到了 3 条记录。\nT2 时刻：事务 B 往插入一个 id&#x3D; 200 的记录并提交；\nT3 时刻：事务 A 再执行当前读语句select * from t_test where id &gt; 100 for update 就会得到 4 条记录，此时也发生了幻读现象。\n\n要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select … for update 这类当前读的语句，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。\n总结：MVCC只能很大程度上避免幻读，但是个别情况下，仍然会发生幻读\nMySQL调优代码优化：\n\n少使用select*，指定具体字段\n尽量少使用order by排序，而使用联合索引\n减少使用Null，有多个null的可以加默认值\nwhere后少使用函数运算\n避免超过五个以上的表连接\n\nSQL：\n\n对于高频筛选字段可以适当建立索引\n一个表的索引不超过五个\n联合索引，遵守最左匹配原则\n\n如果MySQL出现慢查询，问题在哪？\n\n索引失效或者无索引\n强制查询不存在的字段，此时MySQL会查询整张表\n两张表字符集不一样或者编码不一样，但是需要联表查询\n多线程查询操作，若线程A查询了很大的一块数据，此时server正在返回A的查询结果并占用了所有的IO，线程B的查询性能就会受限\n\n如何解决呢？\n\n一次查询数量过于庞大，拆成多次查询、拼装\n分离冷热数据，将大字段或者是查询频率少的数据分出一张新表\nIN子查询影响查询性能，用JOIN方式代替\n用了反向查询（比如NOT IN）或者IN语句参数集太多，可能会导致全表扫描，这种情况尽量拆分语句\n\n","slug":"mySQL","date":"2022-10-25T14:02:31.000Z","categories_index":"","tags_index":"数据库基础","author_index":"Samuel"},{"id":"cd132b199d60085bc82ceffbffeca6fd","title":"netty项目记录","content":"如何编写并启动一个服务端？\npublic void run() throws Exception&#123;\n        //指定bossGroup，也就是负责处理连接请求的线程\n        EventLoopGroup bossGroup = new NioEventLoopGroup(1);\n        //指定workerGroup，也就是负责处理IO请求的线程\n        EventLoopGroup workerGroup = new NioEventLoopGroup();  //8个\n        try &#123;\n            //创建启动类\n            ServerBootstrap bootstrap = new ServerBootstrap();\n            //链式编程为启动类加入线程，channel,handler\n            bootstrap.group(bossGroup, workerGroup)\n                    .channel(NioServerSocketChannel.class)\n                    .handler(new LoggingHandler(LogLevel.INFO))\n                //为管道加入handler或者自定义的handler，netty扩展性的体现\n                    .childHandler(new ChannelInitializer&lt;SocketChannel>() &#123;\n                        @Override\n                        protected void initChannel(SocketChannel socketChannel) throws Exception &#123;\n                            //获取到pipeline\n                            ChannelPipeline pipeline = socketChannel.pipeline();\n                            //因为是基于http协议，使用http的编码和解码器\n                            pipeline.addLast(new HttpServerCodec());\n                            //是以块方式写，添加 ChunkedWriteHandler 处理器\n                            pipeline.addLast(new ChunkedWriteHandler());\n                            /*\n                            说明：\n                            1. http 数据在传输过程中是分段，HttpObjectAggregator，就是可以将多个报文段聚合\n                            2. 这就是为什么，当浏览器发送大量数据时，就会发出多次http请求。\n                             */\n                            pipeline.addLast(new HttpObjectAggregator(8192));\n                            /*\n                             * 说明：\n                             *  1.对应websocket ，它的数据是以帧（frame）形式传播\n                             *  2. 可以看到WebSocketFrame ，下面有六个子类\n                             *  3. 浏览器请求时，ws://localhost:7000/hello 表示请求的uri\n                             *  4. WebSocketServerProtocolHandler 核心功能是将 http协议升级为 ws 协议，保持长连接\n                             *  5. 是通过一个状态码 101\n                             */\n                            pipeline.addLast(new WebSocketServerProtocolHandler(contentPath));\n                            //自定义的handler，处理业务逻辑\n                            pipeline.addLast(new WebSocketServerHandler());\n                        &#125;\n                    &#125;);\n            System.out.println(\"netty 服务器启动\");\n            ChannelFuture channelFuture = bootstrap.bind(port).sync();\n            //监听关闭\n            channelFuture.channel().closeFuture().sync();\n        &#125;finally &#123;\n            //关闭\n            bossGroup.shutdownGracefully();\n            workerGroup.shutdownGracefully();\n        &#125;\n    &#125;\n&#125;\n\n\n//自定义的handler\npublic class WebSocketServerHandler extends SimpleChannelInboundHandler&lt;TextWebSocketFrame> &#123;\n    //定义一个channel组，管理所有的channel\n    //GlobalEventExecutor.INSTANCE 是全局的事件执行器，是一个单例\n    private static ChannelGroup channelGroup = new DefaultChannelGroup(GlobalEventExecutor.INSTANCE);\n    SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n    @Override\n    //收到消息后触发的方法\n    protected void channelRead0(ChannelHandlerContext ctx, TextWebSocketFrame msg) throws Exception &#123;\n        System.out.println(\"服务器端收到消息\");\n        //获取到当前的channel\n        Channel channel = ctx.channel();\n        //这时我们遍历channelGroup，根据不同的情况，回送不同的消息\n        channelGroup.forEach(ch -> &#123;\n            if(channel != ch)&#123; //不是当前的channel，转发消息\n                //将信息刷回客户端\n                ch.writeAndFlush(new TextWebSocketFrame(msg.text()));\n            &#125;\n        &#125; );\n        //回复消息\n        //ctx.channel().writeAndFlush(new TextWebSocketFrame(\"服务器事件\" + LocalDateTime.now() + \"  \" + msg.text()));\n    &#125;\n    //当web客户端连接后，触发方法\n    @Override\n    public void handlerAdded(ChannelHandlerContext ctx) throws Exception &#123;\n        //id表示唯一的值，LongText 是唯一的 ShortText 不是唯一\n        //System.out.println(\"handlerAdded 被调用\" + ctx.channel().id().asLongText());\n        //System.out.println(\"handlerAdded 被调用\" + ctx.channel().id().asShortText());\n        Channel channel = ctx.channel();\n        //将该客户加入聊天的信息推送给其他在线的客户端\n        //该方法会将 channelGroup 中所有的channel 遍历，并发送消息，我们不需要自己遍历\n        //channelGroup.writeAndFlush(new TextWebSocketFrame(\"[客户端]\" + channel.remoteAddress() + \"加入聊天\"\n//                      + sdf.format(new Date()) + \"\\n\"));\n        channelGroup.add(channel);\n    &#125;\n    @Override\n    public void handlerRemoved(ChannelHandlerContext ctx) throws Exception &#123;\n        System.out.println(\"handlerRemoved 被调用\" + ctx.channel().id().asLongText());\n    &#125;\n    @Override\n    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123;\n        System.out.println(\"异常发生\" + cause.getMessage());\n        ctx.close();\n    &#125;\n&#125;\n\n","slug":"netty项目记录——react线程模型简述","date":"2022-10-22T09:16:43.000Z","categories_index":"","tags_index":"netty","author_index":"Samuel"},{"id":"f81fcbbeae7dcf45a5335b1888cb075e","title":"netty基础","content":"为什么我们不用Java NIO？原生的Java NIO编程，对编程能力要求比较高，需要处理连接异常、网络闪断、拆包粘包、网络拥塞、长短连接等各种各样的网络通讯细节问题，这是一件非常困难且耗时的事情。并且，原生Java NIO还有一个臭名昭著的Epoll Bug，它会导致Selector空轮询，最终导致CPU 100%。官方声称在JDK 1.6版本的update 18修复了该问题，但是直到JDK1.7版本该问题仍旧存在，只不过该Bug发生概率降低了一些而已，它并没有被根本解决。\nNetty和Tomcat有什么区别？Netty是一个基于NIO的异步网络通信框架，性能高，封装了原生NIO，降低了编码复杂度。\nTomcat是一个Web服务器，是一个Servlet容器，内部只运行Servlet程序并处理HTTP请求。\nNetty封装的是IO模型，用于处理网络数据的传输，不关心具体的协议，其定制性更高\nreactor线程模型reactor就是IO多路复用（NIO）+线程池的结合优化版\nreactor线程模型：主要有四个角色\n\nReactor：把IO事件分配给对应的handler处理，就是IO多路复用的select实现，即轮询监听\nAcceptor：处理客户端连接事件，创建Handler对象\nHandler：将自身与事件绑定，执行非阻塞读、写任务，负责channel的读入，业务处理完成后，负责将结果写出channel\nworker：用来处理handler传来的业务的线程\n\n其中1，2，3存放于主线程中，也称为bossGroup\n4存放于从线程，也就是线程池中，也称为workerGroup\n单reactor-多线程\n主从reactor-多线程这种模型下是把Reactor线程拆分了mainReactor和subReactor两个部分\nmainReactor只处理连接事件，读写事件交给subReactor来处理。业务逻辑还是由线程池来处理\n\nNetty的线程模型是怎么样的Netty同时支持Reactor单线程模型，多线程模型，主从多线程模型，用户可以配置参数在这三种模型之间切换\n服务端启动时，通常会创建两个NioEventLoopGroup实例，对应两个独立的Reactor线程池，bossGroup负责处理客户端的连接请求，workerGroup负责处理IO相关的操作，执行任务等。用户可以根据ServerBootstrap启动类选择参数配置线程模型。\nNetty为什么高性能？\nNIO模型，用最少的资源完成最多的任务\n内存零拷贝，减少不必要的拷贝造成资源浪费，实现更高效率的传输\n串行化处理读写：消息的处理尽可能在同一个线程内完成，避免切换线程的花销，避免多线程竞争和同步锁。调整NIO线程池的线程参数，可以同时启动多个串行化的线程，相比于多线程竞争机制性能更优。\n支持protobuf：protobuf (protocol buffer) 是谷歌内部的混合语言数据标准。通过将结构化的数据进行序列化(串行化)，用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。是一个高性能的编解码框架，序列化数据后数据更小，传输速度更快，安全性也更高，netty可以直接在handler内添加protobuf编码解码器。\n内存池设计，申请的内存可以重用\n\n粘包现象：发送abc和def，结果接收到abcdef\n原因：\n\n应用层：接收方的bytebuf设置太大（默认1024）\nTCP滑动窗口足够大，且接收方处理不及时\nTCP的Nagle算法：为了减少广域网的小分组数目，从而减小网络拥塞的出现，会造成粘包。\n\nnetty的解决方案：\n\n短连接，发完一次消息后便断开连接。下一次发消息的时候再次建立连接，重置了缓冲区\n设置合理的缓冲区\n\n半包现象：发送abcdef接收到abc和def\n原因：\n\n应用层：bytebuf过小\nTCP滑动窗口过小\n链路层：MSS限制\n\nnetty解决方案\nFixedLengthFrameDecoder定长帧解码器：固定收到的帧的大小，若收到半包，则延迟交付，直到收到其他消息满足大小，再交付\nLineBasedFrameDecoder行帧解码器：根据特定字符来区分完整的信息，避免半包\nLengthFiledBasedFrameDecoder ：指定内容长度，偏移量，从第几个字节开始读，跳过几个字节再读，从而精准读取内容避免半包\n零拷贝零拷贝（zero-copy），是指在计算机执行IO操作时，CPU 不需要先将数据从一个内存区域复制到另一个内存区域。具体来讲，就是数据从网络设备到用户程序空间传递的过程中，减少数据拷贝次数，减少系统调用，实现 CPU 的零参与，彻底消除 CPU 在这方面的负载。\n传统的Linux I&#x2F;O模式\nshell read(file_fd, tmp_buf, len); write(socket_fd, tmp_buf, len);\n\n用户进程通过read函数向内核（kernel）发起系统调用，CPU 将用户进程从用户态切换到内核态；\nCPU 利用 DMA 控制器将数据从主存或硬盘拷贝到内核空间（kernel space）的读缓冲区（read buffer）；\nCPU 将读缓冲区中的数据拷贝到用户空间（user space）的用户缓冲区（user buffer）；\nCPU 将用户进程从内核态切换回用户态，read调用执行返回；\n用户进程通过write函数向内核发起系统调用，CPU 将用户进程从用户态切换到内核态；\nCPU 将用户缓冲区中的数据拷贝到内核空间的网络缓冲区（socket buffer）;\nCPU 利用 DMA 控制器将数据从网络缓冲区拷贝到网卡，进行数据传输；\nCPU 将用户进程从内核态切换回用户态，write调用执行返回。\n\n数据必须经过用户缓冲区才能到达Socket缓冲区，虽然加入了DMA来处理内核与硬件的数据传输，但是仍然效率不高\n由mmap实现用户态直接I&#x2F;Otmp_buf = mmap(file_fd, len);write(socket_fd, tmp_buf, len);\n使用 mmap 的目的是将内核中读缓冲区（read buffer）的地址与用户空间的缓冲区（user buffer）进行映射，从而实现内核缓冲区与应用程序内存的共享，省去了将数据从内核读缓冲区（read buffer）拷贝到用户缓冲区（user buffer）的过程，CPU直接将内核缓冲区中的数据拷贝到Socket缓冲区，节省了一次CPU拷贝。\n\n当mmap一个文件时，如果这个文件被另一个进程所截获，那么write系统调用会因为访问非法地址被SIGBUS信号终止，SIGBUS默认会杀死进程并产生一个 coredump，服务器可能因此被终止。\nSendfile实现内核内的数据传输sendfile(socket_fd, file_fd, len);\n通过 Sendfile 系统调用，数据可以直接在内核空间内部进行 I&#x2F;O 传输，省去了数据在用户空间和内核空间之间的来回拷贝。\n\n基于 Sendfile 系统调用的零拷贝方式，整个拷贝过程会发生2次上下文切换，1 次CPU拷贝和2次DMA拷贝。\nSendfile 存在的问题是：用户程序不能在中途对数据进行修改，而只是单纯地完成了一次数据传输过程，它只适用于将数据从文件拷贝到 Socket 套接字上的传输过程。\nSendfile+DMA gather copy实现硬件级的直接拷贝Linux内核2.4版本，对 Sendfile 系统调用进行了修改，为DMA拷贝引入了gather操作：它将内核空间的读缓冲区中对应的数据描述信息（内存地址、地址偏移量）记录到相应的网络缓冲区（ socket buffer）中，由 DMA 根据内存地址、地址偏移量将数据批量地从读缓冲区拷贝到网卡设备中。\n\nDMA gather copy需要硬件的支持，Sendfile 拷贝方式不再从内核缓冲区的数据拷贝到 Socket 缓冲区，取而代之是仅仅拷贝缓冲区文件描述符和数据长度。\n这样 DMA 引擎直接利用 gather 操作将页缓存中数据打包发送到网络中即可，本质是和虚拟内存映射类似的思路\n整个拷贝过程会发生2次上下文切换、0次CPU拷贝以及2次 DMA拷贝。\nSplice实现管道传输Linux内核2.6.17版本，引入了 Splice 系统调用。Splice 系统调用可以在内核空间的读缓冲区和网络缓冲区之间建立管道（pipeline），从而避免了两者之间的 CPU 拷贝操作。\nSplice 系统调用不仅不需要硬件支持，还实现了两个文件描述符之间的数据零拷贝。\n整个拷贝过程会发生2次上下文切换，0次CPU拷贝以及2次DMA拷贝\n\n\n\n消息队列\n零拷贝方式\n优点\n缺点\n\n\n\nRocketMQ\nmmap + write\n适用于小块文件传输，频繁调用时，效率很高\n不能很好的利用DMA方式，会比sendfile多消耗CPU，内存安全性控制复杂，需要避免JVM Crash问题\n\n\nKafka\nsendfile\n可以利用DMA方式，消耗CPU较少，大块文件传输效率高，无内存安全性问题\n小块文件效率低于mmap方式，只能是BIO方式传输，不能使用NIO方式\n\n\n无论是传统 I&#x2F;O 拷贝方式还是引入零拷贝的方式，2次DMA拷贝都是少不了的，因为两次 DMA 都是依赖硬件完成的\nnetty的零拷贝Netty 中也使用了零拷贝技术，但是和操作系统层面上的零拷贝不太一样, Netty 零拷贝是相对于堆内存与堆外内存而言的，它的更多的是偏向于数据操作优化这样的概念。\n\nNetty接收和发送ByteBuffer采用DirectBuffer，使用堆外直接内存进行Socket读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的JVM的堆内存进行socker读写，那么JVM将会将堆内存拷贝一份到直接内存中，然后在写入socket中。相比堆外直接内存，消息在发送过程中多了一次缓存区的拷贝\nNetty提供CompositeByteBuf组合缓冲区类，可以将多个 ByteBuf合并为一个逻辑上的ByteBufer，避免了各个ByteBufer之间的拷贝，将几个小buffer合并成一个大buffer的繁琐操作。\nNetty提供了ByteBuf的浅层复制操作(slice、 duplicate)，可以将ByteBuf分解为多个共享同一个存储区域的 ByteBuf，避免内存的拷贝\nNetty进行文件传输时，可以调用FileRegion包装的 **transferTo()**方法直接将文件缓冲区的数据发送到目标通道，避免普通的循环读取文件数据和写入通道所导致的内存拷贝问题。\n在将一个byte数组转换为一个ByteBuf对象的场景下，Netty 提供了一系列的包装类，避免了转换过程中的内存拷贝。\n\n","slug":"netty基础知识","date":"2022-10-22T08:35:26.000Z","categories_index":"","tags_index":"netty","author_index":"Samuel"},{"id":"27f3741f94599209904dbbf8d63cd0fd","title":"进程，线程和协程详解","content":"进程\n\n\n\n\n\n\n\n\nan instance of a computer program that is being executed\n进程是程序的一次执行，是一个程序及其数据，运行环境，在处理机上运行时所发生的活动。\n与程序不同的是，进程具有动态性和生命周期，是系统进行资源分配和调度的独立单位。\n进程的结构：\n\n控制块\n数据段\n程序段\n\n线程的Linux实现而在windows中，线程被抽象为一种比进程更轻量级的可以独立处理事件的单元，支持真线程的系统一定要有线程控制块：TCB，操作系统既要进行进程管理，又要进行线程管理，设计层面是比较复杂的。windows上一定会有相关线程操作的系统调用接口。\n而在Linux中却不一样，从内核的角度来看，并没有线程这个概念，Linux把所有的线程都当作进程来处理，内核也并没有定义独特的调度算法和数据结构来实现线程，线程就是一个与父进程共享资源的进程而已，Linux在创建线程时，会直接创建进程并分配task_struct，同时指定共享资源，所以对于内核来说，它就是进程，线程在Linux中是一个实现进程共享资源的机制。\n在 Linux 中每一个进程都由 task_struct 数据结构来定义。task_struct 就是我们通常所说的 PCB，当我们调用 fork()  时，系统会为我们产生一个 task_struct 结构。然后从父进程，那里继承一些数据，并将PCB插入任务队列中，以待进行进程管理。\n对于线程来说，需要在clone()中指定共享资源\nclone(CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND,0);\n//VM：共享地址空间\n//FS：共享文件系统信息\n//FILES:共享打开的文件\n//SIGHAND：共享阻断信号\n\n而一个普通的fork()就是\nclone(SIGCHLD,0);\n\n内核线程内核需要经常在后台处理操作，这些任务可以交给内核线程来处理。内核线程就是独立运行在内核空间的标准进程。\n内核线程没有独立的地址空间。其指向地址空间的mm指针设置为null，只存在于内核空间\ntask_struct结构中的mm指针：指向进程所拥有的内存描述符\n多线程的优点：并发性提高，占用资源比进程更少。\n多线程缺点：存在大量临界资源，势必会造成各种互斥。编程难度提高，线程的调度和同步需要更多额外的开销。\n线程的通信方式管道：分为匿名管道和命名管道，实质是一个缓冲区，管道的作用正如其名，需要通信的两个进程在管道的两端，进程利用管道传递信息。管道对于管道两端的进程而言，就是一个文件，但是这个文件比较特殊，它不属于文件系统并且只存在于内存中。\n信号signal：信号是软件层次上对中断机制的一种模拟，是一种异步通信方式，进程不必通过任何操作来等待信号的到达。信号可以在用户空间进程和内核之间直接交互，内核可以利用信号来通知用户空间的进程发生了哪些系统事件。\n信号量Semaphore：信号量实质上就是一个标识可用资源数量的计数器，它的值总是非负整数。而只有0和1两种取值的信号量叫做二进制信号量（或二值信号量），可用用来标识某个资源是否可用。\n共享内存:使得多个进程可以可以直接读写同一块内存空间，是针对其他通信机制运行效率较低而设计的。为了在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率\n消息队列:消息队列是消息的链表，具有特定的格式,存放在内存中并由消息队列标识符标识，并且允许一个或多个进程向它写入与读取消息\n套接字:不同客户端的进程间的通信方式\n用户空间和内核空间操作系统为了支持多个应用同时运行，需要保证不同进程之间相对独立，一个进程的崩溃不会影响其他进程，恶意进程不能读取其他进程的数据。于是内存空间被划分为两部分，内核空间和用户空间，内核空间的代码和数据拥有更高的权限，而用户空间的代码不能访问高级别的空间，因此保护了操作系统自身的内存数据。\n用户态：指进程运行在用户地址空间中的状态，被执行的代码要受到 CPU 的很多检查。进程只能访问地址空间中规定的页面的虚拟地址。\n内核态：指进程运行在内核地址空间中的状态，此时 CPU 可以执行任何指令。运行的代码也不受任何的限制，可以自由地访问任何有效地址，也可以直接进行端口的访问。所有系统资源的管理都是在内核态去做的，比如创建一个线程需要分配资源，就需要进入内核态，来完成。\n什么是进程上下文在Linux中，用户程序装入系统形成一个进程的实质是系统为用户程序提供一个完整的运行环境\n进程的运行环境是由它的程序代码和程序运行所需要的数据结构以及硬件环境组成的，进程的运行环境主要包括：\n\n进程空间中的代码和数据、各种数据结构、进程堆栈和共享内存区等。\n环境变量：提供进程运行所需的环境信息。\n系统数据：进程空间中的对进程进行管理和控制所需的信息，包括进程任务结构体以及内核堆栈等。\n进程访问设备或者文件时的权限。\n各种硬件寄存器。\n地址转换信息。\n\n从以上组成情况可以看到，进程的运行环境是动态变化的，尤其是硬件寄存器的值以及进程控制信息是随着进程的运行而不断变化的。在Linux中把系统提供给进程的的处于动态变化的运行环境总和称为进程上下文。\n系统中的每一个进程都有自己的上下文。一个正在使用处理器运行的进程称为当前进程(current)。当前进程因时间片用完或者因等待某个事件而阻塞时，进程调度需要把处理器的使用权从当前进程交给另一个进程，这个过程叫做进程切换。\n此时，被调用进程成为当前进程。在进程切换时系统要把当前进程的上下文保存在指定的内存区域（该进程的任务状态段TSS中），然后把下一个使用处理器运行的进程的上下文设置成当前进程的上下文。\n当一个进程经过调度再次使用CPU运行时，系统要恢复该进程保存的上下文。所以，进程的切换也就是上下文切换。\n在系统内核为用户进程服务时，通常是进程通过系统调用执行内核代码，此时内核为用户进程服务，可以说内核在代替当前进程执行某种服务。所以可以认为，内核态就是内核运行在进程上下文中的状态。\n中断上下文：硬件通过触发信号，导致内核调用中断处理程序，进入内核空间。这个过程中，硬件的一些变量和参数也要传递给内核，内核通过这些参数进行中断处理。所谓的“中断上下文”，其实也可以看作就是硬件传递过来的这些参数和内核需要保存的一些其他环境（主要是当前被打断执行的进程环境）\n如何从用户态进入内核态：中断中断是CPU的一个功能：CPU停下工作后，保留现场，自动的转去执行相应的处理程序，CPU的控制权发生改变，处理完该事件后再返回断点继续执行。避免了CPU的轮询检查，而是转换为事件驱动，向CPU发送中断事件，强制让CPU来执行中断处理程序。发生中断，CPU会立即进入内核态，针对不同的中断信号，采取不同的处理方式。**中断是CPU从用户态进入核心态的唯一途径(如系统调用)**。\n硬中断硬中断时由外部事件引起的，具有随机性和突发性，比如键盘，鼠标的输入，磁盘的读写，缺页。硬中断的中断号是由中断控制器提供的，硬中断是可以屏蔽掉的。\n流程如下\n\n外设 将中断请求发送给中断控制器；\n中断控制器 根据中断优先级，有序地将中断号传递给 CPU；\nCPU 终止执行当前程序流，将 CPU 所有寄存器的数值保存到栈中；\nCPU 根据中断号，从中断向量表中查找中断处理程序的入口地址，执行中断处理程序；\nCPU 恢复寄存器中的数值，返回原程序流停止位置继续执行。\n\n软中断（被动）CPU的内部事件或者程序引起的中断，如程序故障，电压故障。\n软中断（主动）也称作系统调用，用户进程主动要求进入内核态。用户进程通过系统调用申请操作系统提供服务。\n 系统调用使用的是一个特别的中断实现的。具体是:调用 int $0x80的汇编指令，将产生向量为0x80的编程异常（软中断）\n软中断模拟了硬中断的处理过程：\n\n无\n无\nCPU 终止执行当前程序流，将 CPU 所有寄存器的数值保存到栈中；\nCPU 根据中断向量，从中断向量表中查找中断处理程序的入口地址，执行中断处理程序；\nCPU 恢复寄存器中的数值，返回原程序流停止位置继续执行。\n\n一个程序开多少线程合适CPU密集型一个完整的请求，IO操作可以在很短的时间内完成，CPU的运算时间占大部分，线程等待时间接近0\n\n单核CPU：一个CPU对应一个线程，且IO时间短，所以不适合使用多线程。若使用多线程，会造成线程竞争，造成不必要的浪费\n多核：如果是多核CPU，就可以最大化利用CPU的核心数，使用并发编程来提高效率。理论上的线程数量就等于CPU的核数，但是一般会设置为核数+1，这个额外的线程可以保证线程因为缺页中断或者其他原因暂停而不会导致CPU中断工作\n\nIO密集型一个完整请求，除了CPU的运算操作，还有许多IO操作要做，也就是说，IO操作占很大一部分，等待时间较长。\n理论最佳线程数：CPU核心数 * （1&#x2F;CPU利用率），CPU利用率&#x3D;1+（IO耗时&#x2F;CPU耗时）\n如果几乎全是IO耗时，那么就可以说是2N，但是一般也有一个backup，也就是2N+1\n线程的生命周期创建当使用new关键字创建了一个线程之后，该线程就处于一个新建状态，此时它和其他java对象一样，仅仅被分配了内存，并初始化了成员变量值。没有线程的动态特征，也不会执行线程的执行体\n就绪当调用start方法后，该线程处于就绪状态。JVM会为其创建虚拟机栈和PC，处于这个状态表示线程可以运行了，等待被调度执行\n运行在就绪状态下，若被OS调度，就会进入运行状态。当时间片用完或者调用线程让步时，回到就绪状态\n阻塞\n等待阻塞：线程执行wait方法，JVM会将其放入等待池中，此时线程会释放持有的锁\n同步阻塞：即被synchronized修饰的代码块被其他线程拿到，本线程获取同步锁失败，就会被JVM放入锁池中\n其他阻塞：线程执行sleep或者join方法，或者发出了IO请求。当sleep超时，join等待线程终止或者等待超时，IO完毕，线程就会重新转入就绪状态\n\nsleep：线程睡眠，使线程转入阻塞状态一定时间\nwait：线程等待，使线程放入等待池，指导其他线程调用notify或者notifyall方法来唤醒，此时线程会尝试获取锁，若成功，转为就绪状态，若失败，则进入锁池等待锁的释放。\nyield：线程让步，暂停当前正在执行的线程对象，回到就绪状态，把执行机会让给优先级相同或者更高的线程\njoin：线程加入，等待其他线程终止，在当前进程中调用另一个指定进程的join方法，则当前进程转入阻塞状态，直到另一个进程运行结束，当前进程再由阻塞转为就绪状态\nnotify：线程唤醒，唤醒被wait阻塞的进程\n死亡\nrun方法执行完成，线程正常结束\n抛出异常\n直接调用stop方法来结束（容易造成死锁）\n\n\nCoroutine协程JVM的1:1模型即JVM层面创建一个线程，就会向OS申请一个线程\n优点：简单，省事\n缺点：重量级大，需要在JVM和OS两个层面都创建等待队列，依赖于OS的线程调度器，对线程的操作如上下文切换，阻塞，唤醒等都需要等待OS的反馈，效率偏低。\n\nJDK19的虚拟线程，尝试协程的实现\n协程的C++实现解析协程是一个函数的泛化，它允许函数被挂起，稍后再恢复\n普通函数\n\n\n\n\n\n\n\n\n一个普通函数可以被认为有两个操作：调用和返回\n调用Call当调用一个函数时，调用操作会创建一个栈帧，挂起调用函数的执行，并将执行转交到被调用函数的开始位置\n这个“挂起”步骤通常包括将当前保存在CPU寄存器中的任何值保存到内存中，以便在函数恢复执行时，这些值可以在需要时恢复。根据函数的调用约定，调用方和被调用方可以协调谁保存这些寄存器值，但您仍然可以将它们视为调用操作的一部分。\n返回Return返回操作将返回值传递给调用方，并销毁函数的栈帧，然后在调用函数的位置恢复调用方的执行。恢复就是回到调用那个时刻的位置，比如设置寄存器重新指向调用者的栈帧。\n协程与普通函数\n\n\n\n\n\n\n\n\n而协程泛化了函数的操作且增加了三个额外的操作：挂起，恢复，销毁\n协程的栈帧协程可以在不销毁栈帧的情况下被挂起，这相当于打破了一个函数调用在虚拟机栈内的运作规则（压入-执行-返回-弹出-销毁）\n这意味着我们需要一个额外的数据结构来保存协程的状态，即堆内存上的协程帧\n协程帧：用于保存操作数，挂起时的恢复点地址，相当于是保存了自身状态的快照\n挂起：Suspend挂起操作在函数的当前点挂起协程的执行，并在不破坏栈帧帧的情况下将执行权转交给调用方或恢复调用方。\nC++ Coroutines TS中，这些挂起点是通过co_await或co_yield关键字来标识的，在挂起协程执行之后，挂起点上的任何对象都仍然是可用的。\n记住，协程的切换不会破坏栈帧，这是协程实现回调的核心\n当挂起时会发生以下操作：\n\n确保将寄存器中保存的任何值写入协程帧\n将恢复点的地址写入协程帧，以指示在哪个位置挂起，恢复操作就可以知道在哪里恢复协程的执行\n\n恢复：Resume就像普通函数调用一样，这个对resume()的调用将分配一个新的栈帧，并在将执行转交到该函数之前将调用者的返回地址存储在栈帧中。\n但是，它不是将执行转移到函数的开始，而是将执行转移到上次挂起的函数的点。\n调用：Call协程所做的第一件事是在堆中分配一个协程帧，并将参数从栈帧复制&#x2F;移动到协程帧，以便参数的生命周期超过第一个挂起点\n销毁：Destroy销毁操作销毁协程帧，而不恢复协程的执行\n总结\n\n\n\n\n\n\n\n\n协程常常被认为是轻量级的线程，实际上协程不是进程也不是线程，而是一个特殊的函数，这个函数可以在某个地方挂起，并且可以重新在挂起处外继续运行。所以说，协程与进程、线程相比并不是一个维度的概念。\n协程不是被操作系统内核所管理的，而是完全由程序所控制，也就是在用户态执行。这样带来的好处是性能大幅度的提升，因为不会像线程切换那样消耗资源。协程的调度也是通过在用户态里创建一个调度器来模拟内核的调度。\n一个线程也可以包含多个协程。一个线程内可以有多个这样的特殊函数在运行，但是有一点必须明确的是，多个线程或者多个进程可以并行，但是一个线程内的多个协程绝对是串行的，因为它仍然是一个函数。\n线程切换过程是由“用户态到内核态到用户态”， 而协程的切换过程只有用户态，即没有陷入内核态，因此切换效率高。\n协程本质上是异步非阻塞技术，它是将事件回调进行了包装，让程序员看不到里面的事件循环。\n","slug":"进程，线程，协程","date":"2022-10-20T08:53:01.000Z","categories_index":"","tags_index":"Java基础知识","author_index":"Samuel"},{"id":"696c711dc425c21ecfe6691bc40887b7","title":"JUC","content":"JAVA创建线程的四种方式继承Thread类\n定义thread类的子类，并重写run方法，该方法的方法体就是线程需要完成的任务，run方法也称为线程执行体。\n创建Thread类的实例，也就是创建了线程对象\n启动线程，即调用线程的start方法\n\n实现Runnable接口\n定义Runnable接口的实现类，重写run方法，run方法同样是线程执行体\n创建实现类的实例，并用这个实例作为Thread类的target来创建Thread对象，这个Thread对象便是线程对象\n启动线程，调用start方法\n\n使用Callable和future创建future接口是jdk1.5引入的，可以用来接收callable接口里call方法的返回值\n有一个实现类futureTask，实现了future和runnable接口，因此可以作为thread类的target\n\n创建callable接口的实现类，并实现call方法，然后创建该实现类的实例\n使用futureTask类来包装callable对象\n使用futureTask对象作为thread对象的target创建并启动线程\n使用futureTask对象的get方法来获取子线程执行结束后的返回值\n\ncall方法比run方法更加强大：可以有返回值，可以抛出异常\n使用executor框架JDK1.5引入的executor框架最大的优点就是把任务的提交和执行解耦\n开发者只需描述好要只需的任务，然后提交即可\n\n创建一个ExecutorService,ExecutorService executorService = Executors.newFixedThreadPool(5);\n若有返回值，将写好的runnable实例或者callable实例作为target submit即可，返回值是一个future对象，所以可以使用get方法获取返回值.\n若无返回值，直接使用execute方法即可ExecutorService.execute(Runnable command);\n\nexecutor框架的内部使用了线程池的机制，可以作为一个工厂类来创建线程池\n\n\n从上图可以看出，应用程序通过Executor框架控制上层的调度；而下层的调度由操作系统内核控制，下层的调度不受应用程序的控制。\n线程池一种多线程的处理形式，处理过程中可以将任务添加到队列中，然后在创建线程后自动启动这些任务。\n线程池的优势\n线程和任务分离，线程可被重用，提升复用性\n控制线程并发数量，统一管理，降低服务器压力\n提升系统响应速度，因为线程池内的线程可以被复用，且线程池内有核心线程待命，所以就减少了创建线程和销毁线程的时间。\n\n为什么要使用线程池JAVA线程的创建十分昂贵，需要JVM和OS配合完成大量的工作\n\n必须为线程堆栈分配和初始化大量的内存块，其中至少包含1MB的栈内存\nJVM的线程模型为1:1模型，即JVM的线程和OS的线程是1:1对应的，需要进行系统调用，以便在OS中创建和注册本地线程\n\nJava的高并发应用频繁创建和销毁线程的操作是十分低效的，且不符合编程规范的，所以需要使用线程池来独立负责线程的创建维护和分配，以提升性能，减少资源消耗。\n应用场景：网购商品秒杀，云盘文件上传，旅行系统购票等等\n解析//构造方法:\npublic ThreadPoolExecutor(int corePoolSize, //核心线程数量\n                              int maximumPoolSize,//     最大线程数\n                              long keepAliveTime, //       最大空闲时间\n                              TimeUnit unit,         //        时间单位\n                              BlockingQueue&lt;Runnable> workQueue,   //   任务队列\n                              ThreadFactory threadFactory,    // 线程工厂\n                              RejectedExecutionHandler handler  //  饱和处理机制\n\t) \n\n参数解释：\n\ncorePoolSize : 指空闲也不允许被销毁的线程，随时待命存放于线程池中\nmaximumPoolSize：指最大线程数，当任务队列满时，需要创建临时进程处理无法进入任务队列的任务。当临时进程空闲时，会被销毁\nkeepAliveTime&amp;TimeUnit：最大空闲时间和时间单位，当临时进程空闲时间超过最大空闲时间后，便会被销毁\nBlockingQueue：阻塞队列，当核心线程均不空闲时，任务进入队列等待。队列可以用多种数据结构实现，永远推荐使用有界队列，即由数组实现的队列，并设立合理的长度。避免造成等待任务过多消耗系统资源。\nThreadFactory ：线程工厂，手动命名创建线程的工厂，方便抛出错误后定位相应线程池\nRejectedExecutionHandler：拒绝策略，当任务队列满且所有线程均不空闲时，启用饱和处理机制\n\n线程池的阻塞队列\n\nArrayBlockingQueue：底层采用数组实现的有界队列，初始化需要指定队列的容量。ArrayBlockingQueue 是如何保证线程安全的呢？它内部是使用了一个重入锁 ReentrantLock，并搭配 notEmpty、notFull 两个条件变量 Condition 来控制并发访问。从队列读取数据时，如果队列为空，那么会阻塞等待，直到队列有数据了才会被唤醒。如果队列已经满了，也同样会进入阻塞状态，直到队列有空闲才会被唤醒。\nLinkedBlockingQueue：底层采用的数据结构是链表，队列的长度可以是有界或者无界的，初始化不需要指定队列长度，默认是 Integer.MAX_VALUE。LinkedBlockingQueue 内部使用了 takeLock、putLock两个重入锁 ReentrantLock，以及 notEmpty、notFull 两个条件变量 Condition 来控制并发访问。采用**读锁和写锁(锁分离)**的好处是可以避免读写时相互竞争锁的现象，所以相比于 ArrayBlockingQueue，LinkedBlockingQueue 的性能要更好。\nSynchronousQueue：又称无缓冲队列。比较特别的是 SynchronizedQueue 内部不会存储元素。与 ArrayBlockingQueue、LinkedBlockingQueue 不同，SynchronizedQueue 直接使用 CAS 操作控制线程的安全访问。其中 put 和 take 操作都是阻塞的，每一个 put 操作都必须阻塞等待一个 take 操作，反之亦然。所以 SynchronizedQueue 可以理解为生产者和消费者配对的场景，双方必须互相等待，直至配对成功。在 JDK 的线程池 Executors.newCachedThreadPool 中就存在 SynchronousQueue 的运用，对于新提交的任务，如果有空闲线程，将重复利用空闲线程处理任务，否则将新建线程进行处理。\nPriorityBlockingQueue：底层最小堆实现的优先级队列，队列中的元素按照优先级进行排列，每次出队都是返回优先级最高的元素。PriorityBlockingQueue 内部是使用了一个 ReentrantLock 以及一个条件变量 Condition notEmpty 来控制并发访问，不需要 notFull 是因为 PriorityBlockingQueue 是无界队列，所以每次 put 都不会发生阻塞。PriorityBlockingQueue 底层的最小堆是采用数组实现的，当元素个数大于等于最大容量时会触发扩容，在扩容时会先释放锁，保证其他元素可以正常出队，然后使用 CAS 操作确保只有一个线程可以执行扩容逻辑。\n\n如何确定核心线程数，最大线程数，任务队列长度核心线程数：IO密集型：CPU数*2；CPU密集型：CPU数+1\n最大线程数：(每秒产生的最大任务数-任务队列长度)*单个任务执行时间\n任务队列长度：核心线程数&#x2F;单个任务执行时间*2\n饱和处理机制有哪些\nAbortPolicy：丢弃任务并抛出异常\nDiscardPolicy：丢弃任务不抛出异常\nDiscardOldestPolicy：丢弃最前面的任务，然后重新提交被拒绝的任务\nCallerRunsPolicy：直接调用线程处理该任务\n\nCASCAS全称为compare and swap，即比较和交换\n这是JDK提供的原子性操作。语义上是两步操作，但是CPU一条指令即可以完成\n汇编指令：lock cmpxchg  \n原子性保证lock：当执行cmpxchg时，其他CPU不允许打断这个操作，lock是硬件级的实现：锁定北桥信号\n//unsafe包中的CAS操作，硬件级的原子操作\n//更新变量值为x，如果当前值为expected\n//o：对象 offset：偏移量 expected：期望值 x：新值\npublic final native boolean compareAndSwapObject(Object o, long offset, Object expected, Object x);\npublic final native boolean compareAndSwapInt(Object o, long offset, int expected, int x);\npublic final native boolean compareAndSwapLong(Object o, long offset, long expected, long x);\n\n如果对象中的变量值为expect，则使用新的值update替换expect\n替换成功，返回true；替换失败，即变量值不为expect，返回false；\n特点：非阻塞，即允许多个线程对共享资源进行修改，但是同一时刻只有一个线程可以进行写操作，其他线程并不是被阻塞，而是在不停重试拿到锁。\n在JAVA中若一个线程没有拿到锁被阻塞，就会造成线程的上下文切换，大量线程的重新调度会造成性能的浪费。\nvolatile只能保证有序性和可见性，不能保证原子性。CAS就保证了原子性。\nCAS和volatile两者可以实现无锁并发\n所以自旋锁便是通过CAS来实现的，在获取锁的时候使用while循环不断进行CAS操作，类似于不断旋转，直到操作成功返回true，在释放锁的时候使用CAS将锁的状态从1变成0。\n\n\nABA问题：假如线程1使用CAS修改初始值为A的变量X&#x3D;A，那么线程1首先会获取当前变量X的值（A），然后使用CAS操作尝试修改X的值为B，如果使用CAS修改成功了，那么程序运行一定是正常的吗？\n有可能在线程1获取到变量X的值A后，在执行CAS之前，线程2使用了CAS修改了变量X值为B，然后又使用了CAS操作使得变量X值为A，虽然线程A执行了CAS操作时X&#x3D;A，但是这个A已经不是线程1获取到的A了。这就是ABA问题，ABA问题的产生是因为变量的状态值产生了环形转换，就是变量值可以从A到B，也可以B到A，如果变量的值只能朝着一个方向转换，例如A到B，B到C，不构成环路，就不会存在这个问题。\n如何解决ABA问题引入原子类：\nAtomicStampedReference 是通过版本号（时间戳）来解决 ABA 问题的，也可以使用版本号（verison）来解决 ABA，即乐观锁每次在执行数据的修改操作时，都带上一个版本号，一旦版本号和数据的版本号一致就可以执行修改操作并对版本号执行 +1 操作，否则执行失败。\nAtomicMarkableReference 则是将一个 boolean 值作是否有更改的标记，本质就是它的版本号只有两个，true 和 false，修改的时候在两个版本号之间来回切换，虽然这样做并不能解决 ABA 的问题，但是会降低 ABA 问题发生的几率。\nThreadLocal即线程本地变量，使公共变量可以在多个线程内进行隔离访问\nstatic ThreadLocal&lt;Object&gt; TL = new ThreadLocal&lt;&gt;();\n若线程1对TL设置内容Value1，此时线程2是无法通过get方法拿到Value1的\n常用方法及实现原理set (T value)：设置线程本地变量的内容\npublic void set(T value) &#123;\n    // 获取当前线程\n    Thread t = Thread.currentThread();\n    // 获取当前线程的threadLocals字段\n    ThreadLocalMap map = getMap(t);\n    // 判断线程的threadLocals是否初始化了\n    if (map != null) &#123;\n        //this就是公共变量TL\n        map.set(this, value);\n    &#125; else &#123;\n        // 没有则创建一个ThreadLocalMap对象进行初始化\n        createMap(t, value);\n    &#125;\n&#125;\n\n每一个thread对象里都会自带一个threadLocals对象，而这个对象就是ThreadLocalMap的实例\nThreadLocalMap就是一个存储Entry即键值对的数组，初始化时threadLocals会设置为null\nThreadLocal.ThreadLocalMap threadLocals = null\n\n所以set方法并不是往tl对象里面装内容，而是以tl的引用为K，value为V，生成Entry装入该线程的map中\nThreadLocalMapThreadLocalMap实现了map接口，但是和hashmap不同，它没有链表或者红黑树，它就是一个散列数组\n当发生哈希碰撞的时候，ThreadLocalMap会以线性探测的方式：即指针向后不断移动直到找到null或者相同的key为止，这种方式来存储元素。\nThreadLocalMap的hash值计算：使用斐波那契数的倍数 和(len -1) 按位与：int i = key.threadLocalHashCode &amp; (len - 1);\nThreadLocalMap的扩容：当元素数大于len*2&#x2F;3时，便会启动扩容，同样是2倍扩容\n过期数据的清理：\n\n探测式清理：从开始位置向后遍历，清除过期元素，将遍历到的过期数据的 Entry 设置为 null ，沿途碰到的未过期的数据则将其 rehash 后重新在 table 中定位，如果定位到的位置有数据则往后遍历找到第一个 Entry=null 的位置存入。接着继续往后检查过期数据，直到遇到空的桶才终止探测。\n启发式清理：从参数i开始向后遍历lg2n个位置，遍历中遇到位置上 key=null 时，从此处同步调用探测时清理方法。\n\nget()：获取线程本地变量的内容\npublic T get() &#123;\n    Thread t = Thread.currentThread();\n    ThreadLocalMap map = getMap(t);\n    if (map != null) &#123;\n        // 获取ThreadLocal对应保留在Map中的Entry对象\n        ThreadLocalMap.Entry e = map.getEntry(this);\n        if (e != null) &#123;\n            @SuppressWarnings(\"unchecked\")\n            // 获取ThreadLocal对象对应的值\n            T result = (T)e.value;\n            return result;\n        &#125;\n    &#125;\n    // map还没有初始化时创建map对象，并设置null，同时返回null\n    return setInitialValue();\n&#125;\n\n\nEntry继承了弱引用类，说明这里的每一个Entry都是一个弱引用，弱引用的使用可以避免内存泄漏\n\n\nThreadLocal对象的作用：\n\n引用作为key来进行查找entry的值\n维护map，ThreadLocalMap的设置删除都是由ThreadLocal来进行的\n\n在ThreadLocalMap的set&#x2F;getEntry中，会对key进行判断，如果key为null，那么value也会被设置为null，这样即使在忘记调用了remove方法，当ThreadLocal被销毁时，对应value的内容也会被清空，避免了内存泄漏。\n为什么ThreadLocal包装的变量可以实现线程隔离？thread对象内不方便手动添加成员变量，所以就使用ThreadLocal来实现成员变量的效果。ThreadLocal对象本身不存储值，而是作为一个key来查找不同线程中的map的value，不同线程以ThreadLocal的弱引用作为key的Entry里的Value肯定都是不同的，每一个线程内的map都保存了一份副本各玩儿各的，所以就实现了线程隔离。\nThreadLocal的应用场景\nSpring的@Transaction事务声明的注解中就使用ThreadLocal保存了当前的Connection对象，避免在本次调用的不同方法中使用不同的Connection对象。\n依赖于ThreadLocal本身的特性，对于需要进行线程隔离的变量可以使用ThreadLocal进行封装\n\nSynchronized同步锁，保证在同一时刻，被修饰的代码块或方法只有一个线程执行，以达到并发安全的效果\n同步锁是解决并发问题最简单的一种方法，直接给代码块加上此关键字即可\n在JDK1.5之前，Synchronized是一个重量级锁，在以后的版本经过改进后成重量级减小\nsynchronized的作用主要有三个：\n\n原子性：确保线程互斥地访问同步代码；\n可见性：保证共享变量的修改能够及时可见，其实是通过Java内存模型中的“对一个变量unlock操作之前，必须要同步到主内存中；如果对一个变量进行lock操作，则将会清空工作内存中此变量的值，在执行引擎使用此变量前，需要重新从主内存中load操作或assign操作初始化变量值” 来保证的；\n有序性：有效解决重排序问题，即 “一个unlock操作先行发生(happen-before)于后面对同一个锁的lock操作”；\n\n底层实现：对象在JVM的内存布局为：对象头+实例数据+对齐填充\n对象头（12字节）其中有4字节的class pointer和8字节的MarkWord\n后者是实现锁的关键，MarkWord被设计成一个非固定的数据，它会根据对象的状态复用自身的空间，即会随着程序的运行发生变化。MarkWord的最后三字节分别为：1bit记录是否为偏向锁；2bit记录锁标志位。当锁标志位变为00时为轻量级锁，01代表未锁定或者可加偏向锁，10时为重量级锁。\nMonitor对象如果使用Synchronize修饰了一个对象，则MarkWord就会指向一个唯一的Monitor对象，并将标志位改为10，由操作系统提供\nMonitor中有三个变量，分别是Owner、EntryList和WaitSet\nOwner：当线程抢占到锁后，Owner就会指向该线程\nEntryList：当其他线程以自旋形式抢占Owner超过阈值后，便会进入阻塞状态，放入EntryList，等待被唤醒\n具体步骤\nthread0执行synchronize代码的时候，synchronized(obj)的obj对象的markword中ptr_to_heavyweight_monitor（指向monitor的指针）会指向一个monitor对象，执行cas操作将monitor的owner设置为thread0。在字节码中对应monitorenter操作指令\nthread1执行到synchronized代码时,发现obj的markword指向了一个monitor并且owner不为null 并且不为抢锁线程,这时会进入entrylist进行blocked，thread2也一样\nthread0执行完同步代码退出synchronized，把obj markword里的数据还原比如hashcode，这些数据是存在monitor对象中的，然后根据不同的策略去唤醒entrylist的thread1和thread2的blocked线程，两个线程去抢owner。在字节码中对应monitorexit操作指令\n\n偏向锁：当一个线程访问加了同步锁的代码块时，会在对象头中存储当前线程的 ID，后续这个线程进入和退出这段加了同步锁的代码块时，不需要再次加锁和释放锁。而是直接比较对象头里面是否存储了指向当前线程的偏向锁。如果相等表示偏向锁是偏向于当前线程的，就不需要再尝试获得锁了。\n说白了就是消除无竞争情况下的性能消耗，避免一个线程的情况下也去竞争锁，造成浪费资源。\n底层实现原理：\n\n首先获取锁 对象的 MarkWord，判断是否处于可偏向状态。偏向锁状态位0，锁标志01\n如果是可偏向状态，则通过 CAS 操作，把当前线程的 ID 写入到 MarkWorda) 如果 CAS 成功，那么 MarkWord就会记录当前线程的ID。 表示已经获得了锁对象的偏向锁，接着执行同步代码块b) 如果 CAS 失败，说明有其他线程已经获得了偏向锁，这种情况说明当前锁存在竞争，需要撤销已获得偏向锁的线程，并且把它持有的锁升级为轻量级锁（这个操作需要等到全局安全点，也就是没有线程在执行字节码）才能执行\n如果是已偏向状态，需要检查 MarkWord 中存储的线程ID 是否等于当前线程的 线程IDa) 如果相等，不需要再次获得锁，可直接执行同步代码块b) 如果不相等，说明当前锁偏向于其他线程，需要撤销偏向锁并升级到轻量级锁\n\n轻量级锁：线程在执行同步块之前，JVM会先在当前线程的栈桢中创建 一个LockRecord\n然后线程尝试使用CAS将对象头中的MarkWord替换为指向锁记录的指针(即00)，官方称为Displaced Mark Word，谁成功将LockRecord贴上去了，谁就拿到锁了。\n如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。\n轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。\n轻量级锁不进行阻塞，而是使用自旋的方式，自旋虽然提升了响应速度，但是会增大CPU的消耗\n重量级锁：当竞争加剧，比如自旋次数超过某一阈值，就会升级为重量级锁，JDK1.6之前，需要自己进行调优设置自旋阈值，需要参考CPU核数。而以后的版本加入了自适应自旋，由JVM自动控制。\n此时需要向操作系统申请资源，申请mutex，将MarkWord替换为指向mutex的指针，拿到重量级锁\n其他线程进入阻塞队列，等待OS的调度，wait状态的线程不消耗cpu\n阻塞线程需要cpu从用户态转到内核态，代价比较大。而且可能会出现刚阻塞不久，锁就被释放的情况，所以阻塞的方式会降低响应速度\n锁会随着线程的竞争情况逐渐升级，偏向锁 &#x3D;&gt; 轻量级锁 &#x3D;&gt; 重量级锁 。锁可以升级但是不能降级。升级的目的是为了提高获得锁和释放锁的效率。\nVolatileVolatile关键字的作用主要有如下两个：\n\n线程的可见性：当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。\n顺序一致性：禁止指令重排序\n\nVolatile和synchronized的区别\n\nVolatile是轻量级的synchronized，因为它不会引起上下文的切换和调度，所以Volatile性能更好。\nVolatile只能修饰变量，synchronized可以修饰方法，静态方法，代码块，类。\nvolatile仅能实现变量的修改可见性，并不能保证原子性，synchronized则可以保证原子性。\n多线程访问volatile不会发生阻塞，而synchronized会发生阻塞。\nvolatile是变量在多线程之间的可见性，synchronize是多线程之间访问资源的同步性。\n\n如何保证线程的可见性JAVA的内存模型线程之间的共享变量存储在主内存中，而每一个线程都有一个私有的本地内存，local memory存储了该线程读写的共享变量的副本。所以当一个线程在本地内存更新共享变量的副本后，需要重新写入主内存。\n如何将新值刷新到主内存中：\nCPU寄存器-&gt;Cache-&gt;Main memory，写缓冲区可以避免处理器停顿下来等待写入数据而造成的延迟，并且写缓冲区可以合并多次写，减少对内存总线的占用。\n但是在写入主内存之前，另外一个线程是看不到的，所以就需要volatile关键则来保证可见性\n当线程对volatile修饰的变量进行写操作时，汇编指令会多出一个lock前缀，这就是内存屏障，而在多核心环境下，这个前缀会对应两个操作：\n\n将当前缓存行的数据立即写回系统内存\n这个写回内存的操作会使其他cpu里缓存的副本无效化\n\n这就是缓存一致性协议，每个处理器通过嗅探在总线传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，从而需要重新从系统内存中读取数据。\n所以多核心环境下，每一个线程读取被volatile修饰的变量时，都必须在主内存中读取最新的结果，而不是使用local memory内的数据，这样保证了一个线程修改变量的结果其他线程都是可知的，保证了线程的可见性。\n如何禁止指令重排同样依赖于lock前缀，即内存屏障实现\n编译器不会对volatile读与volatile读后面的任意内存操作重排序；\n编译器不会对volatile写与volatile写前面的任意内存操作重排序。\n\n\nUnsafe 方法\n\n**putOrderedXxx()**，使用 StoreStore 屏障，会把最新值更新到主内存，但不会立即失效其它缓存行中的数据，是一种延时更新机制；\n**putXxxVolatile()**，使用 StoreLoad 屏障，会把最新值更新到主内存，同时会把其它缓存行的数据失效，或者说会刷新其它缓存行的数据；\n**putXxx(obj, offset)**，不使用任何屏障，更新对象对应偏移量的值；\n**getXxxVolatile()**，使用 LoadLoad 屏障，会从主内存获取最新值；\n**getXxx(obj, offset)**，不使用任何屏障，读取对象对应偏移量的值；\n\nLocksynchronized存在一些问题：\n\nNonfairSync：加入持有锁的线程因为等待长时间IO或者其他原因，其他等待的线程无法响应中断，只能不断等待\n公平锁即尽量以请求锁的顺序来获取锁。比如同时有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程（最先请求的线程）会获得该锁。\n非公平锁即无法保证锁的获取是按照请求锁的顺序进行的。这样就可能导致某个或者一些线程永远获取不到锁。\n\nsynchronize是悲观锁，独占性很强，对读和写操作均是独占的\n\n使用synchronized关键字无法确认线程是否成功获取到锁\n\n\n异常是否释放synchronized关键字在发生异常时会自动释放占有的锁，因此不会出现死锁；而lock发生异常的时候，必须手动unlock来释放锁，可能会引起死锁。解决方式：try catch包裹代码块，finally中写入unlock\n是否响应中断lock可以用interrupt来中断等待，而synchronized只能不断等待锁的释放，不能响应中断\n是否知道获取锁lock可以通过trylock来知道有没有获取锁，而synchronized不能\n两者的异同\n在JDK1.5之前lock的性能优于synchronized，以后的版本，在不断优化降低锁的重量级后，两者的性能差距缩小。\nlock是一个接口，而synchronized是一个关键字\nlock可以有多个获取锁的方式，可以不用一直等待。而synchronized只能等待\nLock适合用于大量线程的同步，且大量线程竞争激烈时，lock的性能更优，lock锁还能使用readwritelock实现读写分离，提高多线程的读操作效率。\nlock可以实现公平锁与非公平锁，synchronized只能实现非公平锁\n\nAQS即AbstractQueuedSynchronizer类，抽象队列同步器，AQS是JUC的基类\n基于 volitile修饰的状态记录量state+Node对象构建的双向链表，先进先出，也就是队列\n//node类携带的信号量\n//排他锁标识\nstatic final node EXCLUSIVE =  null;\n//后继节点需要被唤醒\nstatic final int SIGNAL    = -1;\n//该节点已失效\nstatic final int CANCELLED = 1;\n\n//只有上一个节点是的ws为SIGNAL，当前节点才有可能被上一个节点唤醒\nvolatile int waitStatus;\n\n\n加锁（非公平为例）当调用lock()时，线程会尝试使用CAS的方式将state从0改变为1，返回true则证明成功拿到锁，将ExclusiveOwnerThread指向当前线程。若为重入，则会增加state的值。\n拿锁失败则会被放入队列。若队列为空，则会建立一个空节点作为哨兵，然后将此节点放在哨兵后。队列中的线程会acquireQueued()，内部由一个死循环实现，自旋地，独占且不可中断的方式获取同步状态，位于第二个节点的线程才有资格抢占锁，抢占后将晋升为头节点，原先的头节点会等待被GC。\n若获取锁失败或无资格获取锁，则会则根据前驱节点的waitStatus决定是否需要挂起线程，若为SIGNAL，则当前节点被安全阻塞。\n若为CANCELLED，则会向前查找到为SIGNAL的节点，并重新设置前驱节点，相当于是剔除了失效节点。\n若为0或者其他状态，通过CAS的方式设置为SIGNAL\n锁的释放release(int arg)，先检测state，若state减一后仍不为0，则代表有重入，返回false，等待下一次的释放。\n当state为0时，才会进行unpark()，即释放锁\nunparkSuccessor()，传入head节点，检测到后继节点中第一个waitStatus为-1的节点，并解除挂起状态\nReentrantLockpublic class ReentrantLock implements Lock\n\n互斥锁，可重入锁，也是可以实现公平锁和非公平锁（默认）的一种锁。内部包含一个AQS对象，并基于AQS实现\nNonfairSync：非公平锁无论是队列里，还是外来线程，都会通过CAS直接尝试获取锁，能抢到锁到直接占有锁，抢不到才会到等待队列的队尾等待。\nfairSync：公平锁则是所有线程并发进入acquire方法，通过hasQueuedPredecessors方法来严格控制队列获取锁的顺序，外来线程无法参与竞争。\n\nReentrantLock内部有三个类\n\nCountDownLatchCountDownLatch是一个倒数的计数器阀门，初始化时阀门关闭，指定计数的数量，当数量倒数减到0时阀门打开，被阻塞线程被唤醒\n工作方式：初始值为线程数，当线程完成自己的任务后，计数器的值就减一，当计数器为0时，表示所有线程都已完成任务。然后等待的线程就可以恢复执行。\n//构造函数，需要指定一个等于线程数的int数值\nCountDownLatch(int count);\n//当前线程调用该方法会进入等待状态，直到同步器状态为0时被其他线程唤醒或者被其他线程中断。也即将计数器减为0返回true的线程负责唤醒阻塞的线程。当计数器为0时，调用await()方法将立即返回\nawait();\n//该方法与await()作用一样，只是添加了等待的时间，如果超过等待时间还没有被唤醒或者被中断，那么阻塞线程将退出阻塞状态;\nawait(long timeout, TimeUnit unit);\n//该方法主要是将指定的计数器减1，当计数器已经是0了调用该方法将会被忽略，也就是说计数器的值最小只能是0\ncountDown();\n\n原理：维护一个AQS，将state设置为Count数量，当state为0时，才会唤醒队列中的线程\nCyclicBarrierCyclicBarrier是一个可循环的屏障，它允许多个线程在执行完相应的操作后彼此等待共同到达一个point，等所有线程都到达后再继续执行。比如等所有运动员都跨过第一个栅栏后，才允许继续向前。\n工作方式：初始值同样为线程数，当线程完成自己的任务后，计数器的值减一，若state不为0，则自身阻塞，直到state为0，即所有线程都完成任务后，才会从障碍点继续运行。\nCyclicBarrier是可以循环的，每个线程可以调用两次的await()方法，重复利用栅栏的计数器。调用nextGeneration()方法，唤醒所有阻塞线程，并重置count。\n原理：维护ReentryLock的Lock方法和Condition实现\n而计数器阀门则不可以循环，count为0后就不能再使用。\nCyclicBarrier和CountDownLatch区别\nCountDownLatch的await()线程会等待计数器减为0，而执行CyclicBarrier的await()方法会使线程进入阻塞等待其他线程到达障点\nCountDownLatch计数器不能重置，CyclicBarrier可以重置循环利用，可以应对更多的情况，比如程序出错后重置\nCountDownLatch是基于AQS的共享模式实现的，CyclicBarrier是基于ReentrantLock和Condition实现的\nCountDownLatch会阻塞主线程，CyclicBarrier不会阻塞主线程，只会阻塞子线程\n\n原子类Atomic\n基本类型\n\nAtomicInteger：线程安全的整型\nAtomicBoolean：线程安全的布尔类型\nAtomicLong：线程安全的长整型\n\n//都是通过CAS操作（unsafe）来实现的\ngetAndIncrement() // 原子化 i++\ngetAndDecrement() // 原子化的 i--\nincrementAndGet() // 原子化的 ++i\ndecrementAndGet() // 原子化的 --i\n    \ngetAndAdd(delta) // 当前值 +=delta，返回 += 前的值\naddAndGet(delta)// 当前值 +=delta，返回 += 后的值\ncompareAndSet(expect, update)//CAS 操作，返回是否成功\n\npublic final int getAndIncrement() &#123;\n    //this对应着当前对应\n    //valueOffset对应着当前属性在对象中的内存偏移地址\n    //1代表着增加的数量\n    //注意是unsafe方法\n    return unsafe.getAndAddInt(this, valueOffset, 1);\n&#125;\npublic final int getAndAddInt(Object var1, long var2, int var4) &#123;\n    int var5;\n    do &#123;\n        //获取在内存中的值\n        var5 = this.getIntVolatile(var1, var2);\n    &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));\n    //自旋CAS，var5是希望的旧值，var5+var4是新值，只有当内存中的值等于var5，也就是当前内存中的值等于希望的旧值的时候，才会更新成功，返回true\n    return var5;\n&#125;\n\n累加器\n\nLongAdder(性能优)\nLongAccumulator\nDoubleAdder\nDoubleAccumulator\n\nLongAdder\n在多线程累加的情况下LongAdder拥有比synchronized,AtomicInteger,AtomicLong,LongAccumulator更高的性能\nsynchronized肯定是最慢的\n\n LongAdder在无竞争的情况，跟AtomicLong一样，对同一个base进行操作\n 当出现竞争关系时则是采用一个数组cells，将一个value拆分进这个数组Cells\n多个线程需要同时对value进行操作时，可以对线程id进行hash得到hash值，再根据hash值映射到这个数组cells的某个下标，再对该下标所对应的值进行自增操作。当所有线程操作完毕，将数组cells的所有值和无竞争值base都加起来作为最终结果。\n总结：为什么这么快LongAdder的基本思路就是分散热点，将value值分散到一个Cell数组中，不同线程会命中到数组的不同槽中，各个线程只对自己槽中的那个值进行CAS操作，这样热点就被分散了，冲突的概率就小很多。\n无并发的时候，单线程下直接CAS操作更新base值。有并发的时候，多线程下分段CAS操作更新Cell数组值\n如果要获取真正的long值，只要将各个槽中的变量值累加返回。sum()会将所有Cell数组中的value和base累加作为返回值\n核心的思想就是将之前AtomicLong一个value的更新压力分散到多个value中去，从而降级更新热点。\n与AtomicLong的区别原理不同：\nAtomicLong是以CAS的自旋方式来进行加减\nLongAdder则是以CAS+Base+Cell数组分散热点，通过空间换时间分散了热点数据\n场景不同：\nAtomicLong适用于低并发下的全局计算，能保证并发情况下计数的准确性，可允许一些性能损耗，要求高精度时可使用\nLongAdder适用于高并发下的全局计算，当需要在高并发下有较好的性能表现，且对值的精确度要求不高时，可以使用\n各有缺点：\nAtomicLong 高并发后性能急剧下降\nLongAdder 求和后还有计算线程修改结果的话，最后结果不够准确\n锁的分类按抽象概念分\n悲观锁：悲观地认为数据大概率会被其他线程操作，所以具有强烈的独占性和排它性，比如synchronized，先加锁再执行代码块\n乐观锁：相反，乐观地认为数据不大会被其他线程操作，所以先执行代码块，遇见线程冲突的情况，再补偿\n自旋锁：自旋锁是乐观锁的一种实现形式，首先需要了解一些概念\n\n按读写属性分\n排他锁：又称写锁，X锁，只有一个线程能访问代码块，synchronized关键字即是排他锁。写的时候，不允许其他线程读，也不允许其他线程写\n共享锁：又称读锁，S锁，可以有多个线程访问代码块，允许同时读，不允许写，必须等所有锁释放后才可以写\n读写锁：概念同上\n\n按粒度分\n统一锁：大粒度的锁，防止出现死锁。锁定A线程，等待B线程；锁定B，等待A；若没有很好地同步，就会出现死锁统一锁便是将A和B统一为一个大锁\n分段锁：JDK1.7 ConcurrentHashMap，如果像HashTable那样锁住整张表，性能会很差，使用分段思想，只对某个segment进行锁定，当锁定一段时，不影响其他段的数据插入，提高了效率，缺点，代码实现复杂。\n\n","slug":"JUC","date":"2022-10-20T06:09:39.000Z","categories_index":"","tags_index":"Java基础知识","author_index":"Samuel"},{"id":"db91e78c8da8e89de1c0960e4a35ed33","title":"字典序问题","content":"给你一个整数 n ，按字典序返回范围 [1, n] 内所有整数。\n你必须设计一个时间复杂度为 O(n) 且使用 O(1) 额外空间的算法。\n示例 1：\n输入：n &#x3D; 13\n输出：[1,10,11,12,13,2,3,4,5,6,7,8,9]\n\n思路：字典序的构建可以看成是一支十叉树\n第一层是1位数字，第二层是2位数字，以此类推。\n而十叉树的前序遍历即是字典序的输出\nclass Solution &#123;\n    List&lt;Integer> ans = new ArrayList&lt;>();\n    public List&lt;Integer> lexicalOrder(int n) &#123;\n        //从第一层开始\n        for (int cur = 1; cur &lt;= 9; cur++) recursion(cur, n);\n        return ans;\n    &#125;\n    void recursion(int cur, int limit) &#123;\n        //前序遍历的终止条件\n        if (cur > limit) return ;\n        ans.add(cur);\n        //进入下一层\n        for (int i = 0; i &lt;= 9; i++) recursion(cur * 10 + i, limit);\n    &#125;\n&#125;\n\n给定整数 n 和 k，返回 [1, n] 中字典序第 k 小的数字\n输入: n &#x3D; 13, k &#x3D; 2\n输出: 10\n解释: 字典序的排列是 [1, 10, 11, 12, 13, 2, 3, 4, 5, 6, 7, 8, 9]，所以第二小的数字是 10。\n\n思路：其实按照第一题的思路可以解决，但是如果n十分巨大，全部遍历一遍会造成超时。\n所以无需全部遍历，只需比较该节点下的子节点总数与k的大小即可\n比较节点数与k的大小来判断是否需要进入子树，还是进入兄弟节点的子树\n但是需要解决的问题是，有一些子树的节点不是满的，所以计算nodeCount时需要分情况\nclass Solution &#123;\n    public int findKthNumber(int n, int k) &#123;\n        //从第一层的第一个节点开始扫描\n        int cur =1;\n        k--;\n        //当k==0时，证明找到节点\n        while(k>0)&#123;\n            long left = cur;\n            long right = cur+1;\n            int nodeCount = 0;\n            //统计cur节点下所有子树的节点数\n            while(left&lt;=n)&#123;\n                nodeCount+=Math.min(right,(int)(n+1))-left;\n                left*=10;\n                right*=10;\n            &#125;\n            //不在cur节点下，进入另一个节点\n            if(nodeCount&lt;=k)&#123;\n                k-=nodeCount;\n                cur++;\n            &#125;\n            else&#123;\n                //在cur节点下，进入cur的子树\n                k--;\n                cur*=10;\n            &#125;\n        &#125;\n        return cur;\n    &#125;\n&#125;\n\n","slug":"字典序问题","date":"2022-10-19T05:30:33.000Z","categories_index":"","tags_index":"LeetCode初见","author_index":"Samuel"},{"id":"8420d36b5907c1ed250973ab1271d588","title":"微软面试题——24点游戏","content":"给定一个长度为4的整数数组 cards 。你有 4 张卡片，每张卡片上都包含一个范围在 [1,9] 的数字。您应该使用运算符 [&#39;+&#39;, &#39;-&#39;, &#39;*&#39;, &#39;/&#39;] 和括号 &#39;(&#39; 和 &#39;)&#39; 将这些卡片上的数字排列成数学表达式，以获得值24。\n输入: cards &#x3D; [4, 1, 8, 7]\n输出: true\n解释: (8-4) * (7-1) &#x3D; 24\n\n显而易见是回溯，但是由于题中给出除法是实数除法，所以必须使用double来进行计算\nclass Solution &#123;\n    static double Target = 24;\n    //浮点数误差最小精度\n    static double standard = 1e-6;\n    public boolean judgePoint24(int[] cards) &#123;\n        return backTrack(new double[]&#123;cards[0],cards[1],cards[2],cards[3]&#125;);\n    &#125;\n    boolean backTrack(double[] nums)&#123;\n        //若最终结果与target的差值小于某一数值，则证明相等\n        if(nums.length ==1 )return Math.abs(nums[0]-Target)&lt;standard;\n        for(int i =0;i&lt;nums.length;i++)&#123;\n            for(int j = i+1;j&lt;nums.length;j++)&#123;\n                //建立一个数组，存储除选中的两个数以外的所有数和这两个数的运算结果\n                double[] next = new double[nums.length-1];\n                for(int k=0,index=0;index&lt;nums.length;index++)&#123;\n                    if(index!=i&amp;&amp;index!=j) next[k++] = nums[index];\n                &#125;\n                //决策树选择\n                for(double num:caculator(nums[i],nums[j]))&#123;\n                    next[next.length-1] = num;\n                    if(backTrack(next)) return true;\n                &#125;\n            &#125;\n        &#125;\n        return false;\n    &#125;\n    //存储两个数可以获得的所有运算结果\n    ArrayList&lt;Double> caculator(double a, double b)&#123;\n        ArrayList&lt;Double> list = new ArrayList();\n        list.add(a*b);\n        list.add(a+b);\n        list.add(a-b);\n        list.add(b-a);\n        //若a绝对值小于精度，则可以认为a为零\n        if(!(Math.abs(a)&lt;standard)) list.add(b/a);\n        if(!(Math.abs(b)&lt;standard)) list.add(a/b);\n        return list;\n    &#125;\n&#125;\n\n","slug":"微软面试题——24点游戏","date":"2022-10-16T11:58:26.000Z","categories_index":"","tags_index":"LeetCode初见","author_index":"Samuel"},{"id":"12f7852204c389ace8749b92fea05496","title":"周赛笔记10/16/2022","content":"6204. 与对应负数同时存在的最大正整数给你一个 不包含 任何零的整数数组 nums ，找出自身与对应的负数都在数组中存在的最大正整数 k \n输入：nums &#x3D; [-1,2,-3,3]\n输出：3\n解释：3 是数组中唯一一个满足题目要求的 k 。\n\n一个HashSet+一遍遍历，秒解\nclass Solution &#123;\n    public int findMaxK(int[] nums) &#123;\n        HashSet&lt;Integer> set = new HashSet&lt;>();\n        int res = Integer.MIN_VALUE;\n        for(int n:nums)&#123;\n            if(set.contains(-n)) res = Math.max(res,Math.abs(n));\n            set.add(n);\n        &#125;\n        return res==Integer.MIN_VALUE?-1:res;\n    &#125;\n&#125;\n\n6205. 反转之后不同整数的数目给你一个由正整数组成的数组nums 。\n你必须取出数组中的每个整数，反转其中每个数位，并将反转后得到的数字添加到数组的末尾。这一操作只针对 nums 中原有的整数执行。\n返回结果数组中不同整数的数目。\n输入：nums &#x3D; [1,13,10,12,31]\n输出：6\n解释：反转每个数字后，结果数组是 [1,13,10,12,31,1,31,1,21,13] 。\n反转后得到的数字添加到数组的末尾并按斜体加粗表示。注意对于整数 10 ，反转之后会变成 01 ，即 1 。\n数组中不同整数的数目为 6（数字 1、10、12、13、21 和 31）\n\n同样一个HashSet+一遍遍历，秒解\nclass Solution &#123;\n    public int countDistinctIntegers(int[] nums) &#123;\n        HashSet&lt;Integer> set = new HashSet();\n        for(int num : nums)&#123;\n            if(num==1) &#123;\n                set.add(num);\n                continue;\n            &#125;\n            set.add(num);\n            int n =0;\n            while(num!=0)&#123;\n                n=n*10+num%10;\n                num/=10;\n            &#125;\n            set.add(n);\n        &#125;\n        return set.size();\n    &#125;\n&#125;\n\n6219. 反转之后的数字和输入：num &#x3D; 443\n输出：true\n解释：172 + 271 &#x3D; 443 ，所以返回 true 。\n\n我以为我的方法很笨，但是发现大家都是同样的解法…\nclass Solution &#123;\n    public boolean sumOfNumberAndReverse(int num) &#123;\n        if(num==0) return true;\n        for(int i=1;i&lt;=num;i++)&#123;\n            if((i+reverseNum(i))==num) return true;\n        &#125;\n        return false;\n    &#125;\n    int reverseNum(int num)&#123;\n        int n =0;\n        while(num!=0)&#123;\n            n=n*10+num%10;\n            num/=10;\n        &#125;\n        return n;\n    &#125;\n&#125;\n\n6207. 统计定界子数组的数目给你一个整数数组 nums 和两个整数 minK 以及 maxK 。\nnums 的定界子数组是满足下述条件的一个子数组：\n子数组中的最小值等于 minK\n子数组中的最大值等于 maxK\n返回定界子数组的数目。\n子数组是数组中的一个连续部分\n输入：nums &#x3D; [1,3,5,2,7,5], minK &#x3D; 1, maxK &#x3D; 5\n输出：2\n解释：定界子数组是 [1,3,5] 和 [1,3,5,2] 。\n\n发呆一小时，没写出来…\n看了好几个解析，写了一个自己的解法，然后有一些自己的理解\nclass Solution &#123;\n public long countSubarrays(int[] nums, int minK, int maxK) &#123;\n        int n = nums.length;\n        long res = 0;\n        int left = 0, minIndex = -1, maxIndex = -1;\n        for (int i = 0; i &lt; n; i++) &#123;\n            //定位出现最大最小值的索引\n            if (nums[i] == minK) minIndex = i;\n            if (nums[i] == maxK) maxIndex = i;\n            //刚进来的数影响了最大值或最小值\n            if (nums[i] &lt; minK || nums[i] > maxK) &#123;\n                //将left定位到刚好不出现越界值的位置\n                left = i + 1;\n                minIndex = maxIndex = -1;\n                //当窗口内同时包含最大值和最小值时，更新结果\n            &#125; else if (minIndex != -1 &amp;&amp; maxIndex != -1) &#123;\n                int min = Math.min(minIndex, maxIndex);\n                res += min - left + 1;\n            &#125;\n        &#125;\n        return res;\n    &#125;\n&#125;\n\n","slug":"周赛笔记10-16-2022","date":"2022-10-16T08:06:31.000Z","categories_index":"","tags_index":"LeetCode初见","author_index":"Samuel"},{"id":"22f311f06a9cae50742dc4cb95ef15a1","title":"子序列数目","content":"输入：s &#x3D; &quot;abc&quot;\n输出：7\n解释：7 个不同的子序列分别是 &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;ab&quot;, &quot;ac&quot;, &quot;bc&quot;, 以及 &quot;abc&quot;。\n\n难度：hard\nclass Solution &#123;\n    //状态转移方程真的不好写，所以我不想用动态规划\n    //思路：以c结尾的子串数目等于：以c之前的所有字母结尾的子序列数目的总和+1\n    public int distinctSubseqII(String s) &#123;\n        char[] arr = s.toCharArray();\n        int n = arr.length;\n        int[] alphaBet  = new int[26];\n        for(int i=0;i&lt;n;i++)&#123;\n            long sum = 0;\n            //求总和\n            for(int j:alphaBet)sum=(sum+j)%1000000007;\n            //+1即加上自身\n            alphaBet[arr[i]-'a'] = (int)sum+1;\n        &#125;\n        long res = 0;\n        for(int i : alphaBet) res = (res+i)%1000000007;\n        return (int)res;\n    &#125;\n&#125;\n","slug":"子序列数目","date":"2022-10-14T14:28:37.000Z","categories_index":"","tags_index":"LeetCode初见","author_index":"Samuel"},{"id":"412f186990736c43d33166b6535da85e","title":"周赛笔记10/9/2022","content":"2432. 处理用时最长的那个任务的员工输入：n &#x3D; 10, logs &#x3D; [[0,3],[2,5],[0,9],[1,15]]\n输出：1\n解释：\n任务 0 于时刻 0 开始，且在时刻 3 结束，共计 3 个单位时间。\n任务 1 于时刻 3 开始，且在时刻 5 结束，共计 2 个单位时间。\n任务 2 于时刻 5 开始，且在时刻 9 结束，共计 4 个单位时间。\n任务 3 于时刻 9 开始，且在时刻 15 结束，共计 6 个单位时间。\n时间最长的任务是任务 3 ，而 id 为 1 的员工是处理此任务的员工，所以返回 1 。\n\n突发奇想，想练习一下sort方法的运用熟练程度\nclass Solution &#123;\n    public int hardestWorker(int n, int[][] logs) &#123;\n        for(int i=logs.length-1;i>=0;i--)&#123;\n            if(i==0) break;\n            else logs[i][1]-=logs[i-1][1];\n        &#125;\n        Arrays.sort(logs,(a,b)->&#123;\n            if(b[1]!=a[1])return b[1]-a[1];\n            else return a[0]-b[0];\n        &#125;);\n        return logs[0][0];\n    &#125;\n&#125;\n\n2433. 找出前缀异或的原始数组输入：pref &#x3D; [5,2,0,3,1]\n输出：[5,7,2,3,2]\n解释：从数组 [5,7,2,3,2] 可以得到如下结果：\n- pref[0] &#x3D; 5\n- pref[1] &#x3D; 5 ^ 7 &#x3D; 2\n- pref[2] &#x3D; 5 ^ 7 ^ 2 &#x3D; 0\n- pref[3] &#x3D; 5 ^ 7 ^ 2 ^ 3 &#x3D; 3\n- pref[4] &#x3D; 5 ^ 7 ^ 2 ^ 3 ^ 2 &#x3D; 1\n\n寻找数学规律即可，只不过确实需要自己写例子推导一下\nclass Solution &#123;\n    public int[] findArray(int[] pref) &#123;\n        int n = pref.length;\n        int[] res = new int[n];\n        if(n&lt;=1) return pref;\n        res[0] = pref[0];\n        for(int i=0,p=1;i&lt;n-1&amp;&amp;p&lt;n;i++)&#123;\n                int j = i+1;\n                res[p++] = pref[i]^pref[j];\n            &#125;\n        return res;\n        &#125;\n&#125;\n\n2435. 矩阵中和能被 K 整除的路径给你一个下标从 0 开始的 m x n 整数矩阵 grid 和一个整数 k \n你从起点 (0, 0) 出发，每一步只能往下或者往右 ，你想要到达终点 (m - 1, n - 1) 。\n\n请你返回路径和能被 k 整除的路径数目，由于答案可能很大，返回答案对 109 + 7 取余 的结果。\n\n我刚开始觉得应该是回溯，因为是图的路径问题，但是有几个用例总是无法通过\n最后看解析才发现需要使用DP，确实有点难，特别是状态转换方程的推导\nclass Solution &#123;\n    public int numberOfPaths(int[][] grid, int k) &#123;\n        int m = grid.length;\n        int n = grid[0].length;\n        //记忆化搜索\n        int[][][] c = new int[m][n][k];//记录dp值\n        c[0][0][grid[0][0]%k]++;//记录第一个元素dp值\n        for(int i=1; i&lt;m; i++)&#123;//记录第一列元素dp值\n            for(int l = 0; l&lt;k; l++)&#123;\n                c[i][0][(l+grid[i][0])%k] += c[i-1][0][l];\n            &#125;\n        &#125;\n        for(int j=1; j&lt;n; j++)&#123;//记录第一行元素dp值\n            for(int l = 0; l&lt;k; l++)&#123;\n                c[0][j][(l+grid[0][j])%k] += c[0][j-1][l];\n            &#125;\n        &#125;\n        for(int i=1; i&lt;m; i++)&#123;//记录其他元素dp值\n            for(int j=1; j&lt;n; j++)&#123;\n                for(int l = 0; l&lt;k; l++)&#123;\n                    c[i][j][(l+grid[i][j])%k] += c[i-1][j][l];\n                    c[i][j][(l+grid[i][j])%k] += c[i][j-1][l];\n                &#125;\n                for(int l = 0; l&lt;k; l++)&#123;//避免整数溢出\n                    if(c[i][j][l] >= 1000000007) c[i][j][l] -=1000000007 ;\n                &#125;\n            &#125;\n        &#125;\n        return c[m-1][n-1][0];\n    &#125;\n&#125;\n\n","slug":"周赛笔记10-9-2022","date":"2022-10-09T05:25:50.000Z","categories_index":"","tags_index":"LeetCode初见","author_index":"Samuel"},{"id":"bdd0b34d75b797c3e041acb9ccf9384c","title":"位运算技巧","content":"//位运算算法技巧\n//不用临时变量交换两个数\na ^= b;\nb ^= a;\na ^= b;\n//判断是否异号（同号）\nboolean f = ((x ^ y) &lt; 0);\n//利用或操作 | 和空格将英文字符转换为小写\n('A' | ' ') = 'a';\n//利用与操作 &amp; 和下划线将英文字符转换为大写\n('b' &amp; '_') = 'B';\n//利用异或操作 ^ 和空格进行英文字符大小写互换\n('D' ^ ' ') = 'd';\n//去掉最后一位1\nn &amp; (n-1);\n//异或运算的特殊性质,异或运算满足交换律和结合律\na ^ a = 0;\na ^ 0 = a;\n//取反码+与运算\nx &amp; ~x = 0;\nx &amp; ~0 =x;\n\n","slug":"位运算技巧","date":"2022-10-02T04:59:51.000Z","categories_index":"","tags_index":"算法归纳","author_index":"Samuel"},{"id":"8a33ad4dd9e973b50a7c9fd8c1c572f8","title":"划分k个相等子集","content":"输入： nums &#x3D; [4, 3, 2, 3, 5, 2, 1], k &#x3D; 4\n输出： True\n说明： 有可能将其分成 4 个子集（5），（1,4），（2,3），（2,3）等于总和\n\n桶问题：若可以划分为k个子集，则想象有k个桶，容量均为sum&#x2F;k，如果我们刚好将桶装满，则返回true，否则返回false\nclass Solution &#123;\n    int sum =0;\n    public boolean canPartitionKSubsets(int[] nums, int k) &#123;\n        if(!isValid(nums,k)) return false;\n        //对数组排序，从后向前搜索\n        Arrays.sort(nums);\n        if(nums[nums.length-1]>sum/k) return false;\n        sum/=k;\n        int[] arr = new int[k];\n        //建立桶的数据结构\n        Arrays.fill(arr,sum);\n        return(backTrack(nums,k,arr,nums.length-1));\n    &#125;\n    boolean isValid(int[] nums, int k)&#123;\n        for(int val : nums) sum+=val;\n        if(sum%k!=0) return false;\n        return true;\n    &#125;\n    boolean backTrack(int[] nums, int k,int[] arr,int cur)&#123;\n        if(cur&lt;0) return true;// cur走到-1时，说明所有的数全部都放进桶里了。这时一定是true\n        for(int i=0;i&lt;k;i++)&#123;\n            //i遍历每一个桶，判断cur指向的数可以放入哪一个桶\n            if(arr[i]==nums[cur]||arr[i]-nums[cur]>=nums[0])&#123;\n                arr[i]-=nums[cur];\n                if(backTrack(nums,k,arr,cur-1)) return true;\n                arr[i]+=nums[cur];\n            &#125;\n        &#125;\n        return false;\n    &#125;\n&#125;\n\n","slug":"划分k个相等子集","date":"2022-09-27T13:57:25.000Z","categories_index":"","tags_index":"LeetCode初见","author_index":"Samuel"},{"id":"a978a5e93d8e6628e9f4ee713be55be8","title":"Redis","content":"Redis的数据结构\n\n\n数据类型\n简单描述\n使用场景\n\n\n\nString\nstring(字符串)是Redis最简单也是使用最广泛的数据结构，它的内部是一个字符数组。String(字符串)是动态字符串，允许修改；它在结构上的实现类似于Java中的ArrayList（默认构造一个大小为10的初始数组），这是冗余分配内存的思想，也称为预分配；这种思想可以减少扩容带来的性能消耗。当string(字符串)的大小达到扩容阈值时，将会对string(字符串)进行扩容，string(字符串)的扩容主要有三种情况：1.长度小于1MB，扩容后为原先的两倍; length &#x3D; length * 2 2.长度大于1MB，扩容后增加1MB; length &#x3D; length + 1MB 3. 字符串的长度最大值为 512MB\n缓存、计数器、分布式锁等。\n\n\nList\nRedis的列表相当于Java语言中的LinkedList，它是一个双向链表数据结构，支持前后顺序遍历。链表结构插入和删除操作快，时间复杂度O(1)，查询慢，时间复杂度O(n)。Redis的list(列表)不是一个简单的LinkedList，而是quicklist ——“快速列表”，quicklist是多个ziplist(压缩列表)组成的双向列表；\n链表、异步队列、微博关注人时间轴列表……\n\n\nHash\nRedis的hash(字典)相当于Java语言中的HashMap，hash(字典)的实现与Java中的HashMap（JDK1.7）的结构也是一致的，它的数据结构也是数组+链表组成的二维结构，Redis中的hash(字典)存储的value只能是字符串值，此外扩容与Java中的HashMap也不同。Java中的HashMap在扩容的时候是一次性完成的，而Redis考虑到其核心存取是单线程的性能问题，为了追求高性能，因而采取了渐进式rehash策略。渐进式rehash指的是并非一次性完成，它是多次完成的，因此需要保留旧的hash结构，所以Redis中的hash(字典)会存在新旧两个hash结构，在rehash结束后也就是旧hash的值全部搬迁到新hash之后，新的hash在功能上才会完全替代以前的hash。\n用户信息、Hash 表……\n\n\nSet\nRedis的set(集合)相当于Java语言里的HashSet，它内部的键值对是无序的、唯一的。它的内部实现了一个所有value为null的特殊字典。\n去重功能、赞、踩、共同好友……\n\n\nBitmaps\nBitmaps 称为位图，严格来说它不是一种数据类型。Bitmaps底层就是字符串（key-value）byte数组。我们可以使用普通的get&#x2F;set直接获取和设值位图的内容，也可以通过Redis提供的位图操作getbit&#x2F;setbit等将byte数组看成“位数组”来处理。Bitmaps 的“位数组”每个单元格只能存储0和1，数组的下标在Bitmaps中称为偏移量。Bitmaps设置时key不存在会自动生成一个新的字符串，如果设置的偏移量超出了现有内容的范围，就会自动将位数组进行零扩充\n员工打卡……\n\n\nGeospatial\nGeospatial是Redis在3.2版本以后增加的地理位置GEO模块\n微信附近的人，在线点餐“附近的餐馆”……\n\n\nHyperLogLog\nHyperLogLog是用来做基数统计的算法，它提供不精确的去重计数方案（这个不精确并不是非常不精确），标准误差是0.81%，对于UV这种统计来说这样的误差范围是被允许的。HyperLogLog的优点在于，输入元素的数量或者体积非常大时，基数计算的存储空间是固定的。在Redis中，每个HyperLogLog键只需要花费12KB内存，就可以计算接近2^64个不同的基数。但是HyperLogLog只能统计基数的大小（也就是数据集的大小，集合的个数），他不能存储元素的本身，不能向set集合那样存储元素本身，也就是说无法返回元素。\n基数统计比如UV等\n\n\n\n字符串int：存储数字\nraw：长度大于39字节，基于SDS\nembstr：长度小于39字节，基于SDS\nSDS结构模型基于C语言，由Redis封装的一种简单高效安全的数据结构\n源码分析SDS的底层实现思路其实十分简单\n\n无符号变量len：记录字符串的长度\n无符号变量free：记录空闲内存的大小\nchar型数组buf：存储字符\n\n其中：buf尾部会自动追加一个空字符，遵循了c语言原生字符串的规范，并且SDS的指针也不是指向起始位置，而是指向buf，使得SDS可以直接使用一部分库函数。\nSDS取消了字节对齐，使得指针移动一位便可以读取到header里的信息。如果没有取消，这个移动的位数是未知的，就无法兼容C语言的库函数了，指针操作也要麻烦很多。\n数据结构优化：如果一个字符串非常短，但是记录信息的头部却占用了更多的空间，这未免有一些浪费，所以SDS会分为五种类型\n\n短字符串：小于32，用一个char类型的flag变量来记录长度，低三位存储类型，高三位存储长度\n短字符串：用一字节的char来记录长度，一字节的flag来记录类型\n长字符串：用2字节的short来记录长度，1字节的flag来记录类型\n长字符串：用4字节的int来记录长度\n超长字符串：用8字节的long来记录字符串\n\nSDS的最大长度：在3.X版本中，因为数据结构中的len属性是由int来修饰的，所以buf的最大长度就是214783647，即512MB\n但是在6.x版本后，长度就更多样了\nSDS相比原生string的优势：\nO(1)时间复杂度获取字符串的长度：因为C语言原生基本数据类型不记录自身长度，当要计算一个字符串的长度必须遍历整个字符串，直到遇到空字符为止，时间复杂度O(n)，而使用SDS则直接获取len属性即可，时间复杂度为O(1)\n二进制安全：在C语言中，用空字符表示字符串的结束，若字符串本身就包含空字符，那么遇到便会截断，即非二进制安全。与其相对的便是二进制安全，SDS使用len属性来判断字符串是否结束，不会受到空字符影响。\n杜绝缓冲区溢出：在C语言中，在对字符串进行拼接操作时，若没有给字符串分配足够的内存，那么就可能产生缓冲区溢出，把其他数据覆盖掉。而SDS的自动扩容机制杜绝了溢出，sdsMakeRoomFor方法：参数：原字符串，待加入的字符串。若空闲空间大于待拼接字符串的长度，则无需扩容；若拼接后的长度小于1M，则直接扩容至新长度的两倍；若拼接后的长度大于1M，则扩容至新长度+1M；扩容后检查类型，若发生变化，则需要为SDS重新分配内存（header的大小也改变了）\n优化的内存分配策略：预分配：扩容后的SDS不会恰好容下新字符串，而是多分配了一些空间，从而减少修改字符串时带来的内存重分配次数；惰性空间释放机制：当缩短字符串时，不会立刻回收空余的空间，而是仅仅更新len属性，空余空间供将来使用，减少内存分配频率，当然Redis也提供了释放未使用空间的方法sdsRemoveFreeSpace\n\nList列表Redis 的列表相当于 Java 语言里面的 LinkedList，这意味着List的插入和删除操作非常块，但是索引定位就比较慢了\nList支持先进先出（lpop）先进后出（rpop）\nList有两种实现方式：压缩列表和双向循环链表\nziplist：节点的数据小于64字节，数据个数小于512个一般的数组都要求每一格的元素大小相同，但是若要存储不同大小的字符串，就需要以最大长度来作为元素大小，会造成一定程度的浪费。而压缩列表就是将元素紧凑，但是会在每个元素的头部追加一个len属性，这样就能很容易计算出下一个元素的内存地址。\n双向链表和linkedlist很相似，可以处理数据量较大的情况，每个节点包含value和前驱，后继节点的指针\nquicklist在redis3.2版本之前，使用ziplist和linkedlist作为列表的底层实现，就使用quicklist\nquicklist其实现也是依赖于ziplist和linkedlist来实现的，它是两个结构的结合。\n它将ziplist来进行分段存储，也就是分成一个个的quicklistNode节点来进行存储。每个quicklistNode指向一个ziplist，然后quicklistNode之间是通过双向指针来进行连接的。\n\n传统链表的缺点：\n\n每个节点都有自己的前后指针，指针会占用内存，当节点内数据较少时，附加空间成本就太高了\n每个节点单独的进行内存分配，当节点过多，造成的内存碎片太多了。影响内存管理的效率。\n\n因此，定义了 quicklist, 将 linkedlist 和 ziplist 结合起来，形成一个，将多个 ziplist 通过前后指针互相连接起来的结构，可以在一定程度上缓解上面说到的两个问题。为了进一步节约内存，Reids 还可以对 ziplist 进行压缩存储，应用 LZF 算法压缩，即quicklistLZF结构\nHash节点的数据小于64字节，数据个数小于512个时由ziplist实现\n其他情况由哈希表实现，和JDK1.7里的hashmap类似，都是无序键值对集合，底层是数组+链表\nhash也有两种实现方式，当数据量小的时候，使用压缩列表，当数据量大的时候，使用散列表。\n但是hash只能存储字符串，并且redis为了保证高性能，采用渐进式的rehash方法，即在不断输入的任务以及hash操作中一步步将旧结构里的内容迁移到新结构中\nSET无序集合，存储一组不重复的数据，类似于HashSet，元素无序且唯一\n同样两种实现方法：有序数组inset（只用于处理整数）和散列表。前者是处理较少的数据，后者是处理大量数据。\nZSET有序键值对集合\n节点的数据小于64字节，数据个数小于128个时由ziplist实现\n其他情况由跳表来实现\nZSET是一个有序集合，它一方面通过set来保证内部value值的唯一性，另一方面通过value的score（权重）来进行排序。\n这个排序的功能是通过Skip List来实现的\n应用场景：\n\n存储粉丝列表，value是粉丝的ID，score是关注时间戳，这样可以对粉丝关注进行排序\n存储学生成绩，value使学生的ID，score是学生的成绩，这样可以对学生的成绩排名\n\n跳表skipList跳表是可以实现二分查找的有序链表，常用于redis的有序集合数据结构\n拥有与红黑树相近的查找，删除，插入效率，并且范围查找效率更优越\n原理在于为有序链表建立多级索引，从而实现跳跃查找，\n最底层包含所有元素，第一级索引包含1&#x2F;2的元素，以此类推。\n每个索引包含了一个指针数组，指向了该索引可以到达的所有节点，数组下标即当前指针所在的层数。\n\n以生成随机数的方式，来为每一个插入的元素设定索引级数，从而无需重建整个索引，降低了时间复杂度\n索引晋升计算模式：random()是个随机数，产生越高的节点层数，概率越低\npublic int randomLevel()&#123;\n    int level = 1;\n    // random()返回一个[0...1)的随机数\n    while (random() &lt; p &amp;&amp; level &lt; MaxLevel)&#123; \n        level += 1;\n    &#125;\n    return level;\n&#125;\n//在redis中p为0.25，MaxLevel为64\n\n跳表自身拥有的优势：\n\n数据天然有序\n插入查询过程类似于二分查找，所以时间复杂度为O(logn)\n与红黑树相比：实现简单，无需变色左旋右旋等操作\n\nRedis的持久化因为redis的数据是在内存里，一旦断电或者宕机，数据便会丢失，所以必须保证数据不会因为故障而丢失\nRDB(redis database)快照，在指定的时间间隔内将内存中的所有数据集快照写入磁盘\nRedis会单独创建fork一个子进程来进行持久化，依靠操作系统的COW机制（写入时复制，在client没有对数据进行写入时，子进程和主进程通过指针共享一个物理页面，当client对数据进行写入修改时，OS才会为页面创建副本，子进程将副本数据写入RDB，而这个过程仍然不影响主进程对数据的修改），fork进程内部的数据便是整个数据库的一个快照。当子进程完成对新RDB文件的写入时，便会拿其替换原来的RDB文件。\nfork 的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等）数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程。 子进程读取数据，然后序列化写到磁盘中。\nRDB是对整个内存的数据进行快照，所以只有一个文件，这种方法适合大规模的数据恢复，而且很方便，因为OS只需要fork一个子进程，服务进程无需进行其他的IO操作，最大化保障redis的性能。\n但是RDB也有一些缺点：最后一次快照无法及时写入内存，可能会发生丢失，因为是由fork子进程来完成持久化，相当于克隆了一份内存数据，当数据集较大时，可能会影响整个服务器的性能。\nAOF(Append Only File)以日志的形式来记录写操作，只记录写指令，恢复时只需从前往后执行一遍即可完成数据恢复的工作。\n记录方式：写后日志：即在数据写入内存后再记录日志，让操作系统先执行命令，只有命令执行成功才能被记录，这种方式排除了错误的指令，并且不会阻塞当前的写操作。\n风险：若写入数据后未来得及记录日志便宕机，就会造成数据丢失。虽然避免了当前命令的阻塞，但是会给下一个操作带来阻塞 的风险，因为AOF日志是在主线程中进行的，写入磁盘时，磁盘的写压力大，可能会造成后序操作的阻塞。\n同步写回：每个操作完成后写回，会影响性能，但是可靠性高\n每秒写回：即每秒进行一次写回，性能适中，但是可能会丢失这一秒内的数据\n操作系统控制的写回：每个写完命令执行完，只是先把日志写到AOF文件的内存缓冲区，由操作系统决定何时写回磁盘。性能好，但是宕机时丢失的数据多\nRedis的事务redis是不支持回滚的：由程序员自行纠正编程错误，无回滚的方式保证了内部的简单快速\n以MULTI开始一个事务，将多个命令入队，入队后不会立即执行，而是放置在等待执行的队列里，由EXEC触发事务\n所有命令都会被序列化，顺序执行，执行过程中不会被其他客户端的命令打断\n在提交之前所有命令都不会被执行\n不保证原子性：有一条命令失败，其他的命令仍然会进行，没有回滚\nredis和memcached的区别memcached全部存储于内存中，断电后会挂掉；redis具有持久化机制\nRedis具有复杂的数据类型\nRedis自己构建了VM机制，一般的系统调用系统函数，会浪费时间去移动和请求\nredis的value值最大可以达到1gb，memcached只有1mb\nRedis分布式锁——Redission\n分布式锁是控制分布式系统或不同系统之间共同访问共享资源的一种锁实现，如果不同的系统或同一个系统的不同主机之间共享了某个资源时，往往需要互斥来防止彼此干扰来保证一致性。\n使用场景：多个服务间保证同一时刻同一时间段内同一用户只能有一个请求（防止关键业务出现并发攻击）\n实现分布式锁的主要步骤：\n\n指定一个 key 作为锁标记，存入 Redis 中，指定一个 唯一的标识 作为 value。\n当 key 不存在时才能设置值，确保同一时间只有一个客户端进程获得锁，满足 互斥性 特性。\n设置一个过期时间，防止因系统异常导致没能删除这个 key，满足 防死锁 特性。\n当处理完业务之后需要清除这个 key 来释放锁，清除 key 时需要校验 value 值，需要满足 解铃还须系铃人 。\n\nRedisson 提供了看门狗，每获得一个锁时，只设置一个很短的过期时间，同时起一个线程在每次快要到超时时间时去刷新锁的过期时间。在释放锁的同时结束这个线程。\nRedLock算法Redisson分布式锁，在某些极端情况下仍然是有缺陷的\n\n客户端长时间内阻塞导致锁失效\n客户端 1 得到了锁，因为网络问题或者 GC 等原因导致长时间阻塞，然后业务程序还没执行完锁就过期了，这时候客户端 2 也能正常拿到锁，可能会导致线程安全问题。\n\nRedis 服务器时钟漂移\n如果 Redis 服务器的机器时间发生了向前跳跃，就会导致这个 key 过早超时失效，比如说客户端 1 拿到锁后，key 还没有到过期时间，但是 Redis 服务器的时间比客户端快了 2 分钟，导致 key 提前就失效了，这时候，如果客户端 1 还没有释放锁的话，就可能导致多个客户端同时持有同一把锁的情况，同样会造成线程安全的问题。\n\n单点实例安全问题\n如果 Redis 是单机模式挂了的话，那所有的客户端都获取不到锁了，假设你是主从模式，但 Redis 的主从同步是异步进行的，如果 Redis 主宕机了，这个时候从机并没有同步到这一把锁，那么机器 B 再次申请的时候就会再次申请到这把锁。\n\n\n引入红锁算法：\n\n客户端在多个 Redis 实例上申请加锁，必须保证大多数节点加锁成功，默认为N&#x2F;2+1个\n解决容错性问题，部分实例异常，剩下的还能加锁成功\n\n大多数节点加锁的总耗时，要小于锁设置的过期时间。\n多实例操作，可能存在网络延迟、丢包、超时等问题，所以就算是大多数节点加锁成功，如果加锁的累积耗时超过了锁的过期时间，那有些节点上的锁可能也已经失效了，还是没有意义的。客户端会记录每次加锁消耗的时间并求和，加锁总耗时小于锁失效时间，锁才算获取成功。\n\n释放锁，要向全部节点发起释放锁请求\n如果部分节点加锁成功，但最后由于异常导致大部分节点没加锁成功，就要释放掉所有redis实例，各节点要保持一致\n\n\nRedis主从主从复制，或者叫主从同步，是指将一台 Redis 服务器的数据，复制到其他的 Redis 服务器。\n前者称为 **主节点(master)**，后者称为 **从节点(slave)**。且数据的复制是 单向 的，只能由主节点到从节点。\nRedis 主从复制支持 主从同步 和 从从同步 两种，后者是 Redis 后续版本新增的功能，以减轻主节点的同步负担。\n\n主从复制的目的：\n\n数据冗余： 主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。\n故障恢复： 当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复 *(实际上是一种服务的冗余)*。\n负载均衡： 在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务 （即写 Redis 数据时应用连接主节点，读 Redis 数据时应用连接从节点），分担服务器负载。尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高 Redis 服务器的并发量。\n高可用基石： 除了上述作用以外，主从复制还是哨兵和集群能够实施的 基础，因此说主从复制是 Redis 高可用的基础。\n\nredis2.7及以前版本主从复制依赖于sync\n\n当主服务器接收到sync命令后，会执行bgsave命令\n主服务器主进程fork的子进程会生成一个RDB文件，同时将RDB快照产生后的所有写操作记录在缓冲区中\nbgsave命令执行完成后，主服务器将生成的RDB文件发送给从服务器\n从服务器接收到RDB文件后，首先会清除本身的全部数据，然后载入RDB文件，将自己的数据状态更新成主服务器的RDB文件的数据状态\n主服务器将缓冲区的写命令发送给从服务器，从服务器接收命令，并执行，完成主从复制\n主从同步依赖于命令传播\n当主服务器接收命令导致数据发生变化时，为了维护主从状态一致，主服务器会将导致自己数据状态发生改变的命令传播到从服务器执行，当从服务器也执行了相同的命令之后，主从服务器之间的数据状态将会保持一致。\nsync命令的缺点：\n\n生成RDB快照文件会占用大量的CPU，磁盘IO资源，令主服务器响应能力下降\n主服务器将生成的RDB文件发送给从服务器，会占用大量网络IO资源\n从服务器接收RDB文件并载入，会导致从服务器阻塞，无法提供服务\n当从服务器掉线再重连后，会产生不一致的问题，而sync无法处理这一情况，只能使用全量同步\n\nredis2.8 — redis4.0尽量减少全量同步的发生，尽可能使用增量同步，在2.8版本之后使用psync命令代替了sync命令来执行同步操作，psync命令同时具备全量同步和增量同步的功能。\n增量同步的实现原理：\n\n复制偏移量\n复制积压缓冲区\n服务器运行 ID\n\n复制偏移量这是主从服务器都会维护的参数\n主服务器向从服务发送数据，传播N个字节的数据，主服务的复制偏移量增加N\n从服务器接收主服务器发送的数据，接收N个字节的数据，从服务器的复制偏移量增加N\n\n假设此时A&#x2F;B正常传播，C从服务器断线\n\n有了复制偏移量之后，从服务器C断线重连后，主服务器只需要发送从服务器缺少的100字节数据即可\n复制积压缓冲区\n复制积压缓冲区是一个固定长度的队列，默认为1MB大小。\n当主服务器数据状态发生改变，主服务器将数据同步给从服务器的同时会另存一份到复制积压缓冲区中\n复制积压缓冲区为了能和偏移量进行匹配，它不仅存储了数据内容，还记录了每个字节对应的偏移量：\n\n所以主服务器可以通过这个缓冲区来知道从服务器缺失了哪些数据\n当从服务器断线重连后，从服务器通过psync命令将自己的复制偏移量（offset）发送给主服务器，主服务器便可通过这个偏移量来判断进行增量传播还是全量同步。\n\n如果偏移量offset+1的数据仍然在复制积压缓冲区中，那么进行增量同步操作\n反之进行全量同步操作，与sync一致\n\n可以由用户自定义缓冲区大小：尽可能的使用增量同步，但是缓冲区又不会占用过大的内存\n服务器运行ID当主服务器宕机后，某台从服务器被选举成为新的主服务器，就通过比较运行ID来区分谁是主服务器\n\n运行ID（run id）是服务器启动时自动生成的40个随机的十六进制字符串，主服务和从服务器均会生成运行ID\n\n当从服务器首次同步主服务器的数据时，主服务器会发送自己的运行ID给从服务器，从服务器会保存在RDB文件中\n\n当从服务器断线重连后，从服务器会向主服务器发送之前保存的主服务器运行ID，如果服务器运行ID匹配，则证明主服务器未发生更改，可以尝试进行增量同步\n\n如果服务器运行ID不匹配，则进行全量同步\n\n\nredis4.0之后psync升级为psync2.0\n psync2.0 抛弃了服务器运行ID，采用了replid和replid2来代替，其中replid存储的是当前主服务器的运行ID，replid2保存的是上一个主服务器运行ID\n通过replid和replid2我们可以解决主服务器切换时，增量同步的问题：\n\n如果replid等于当前主服务器的运行id，那么判断同步方式增量&#x2F;全量同步\n\n如果replid不相等，则判断replid2是否相等（是否同属于上一个主服务器的从服务器），如果相等，仍然可以选择增量&#x2F;全量同步，如果不相等则只能进行全量同步。\n\n\nRedis哨兵Redis Sentinel（哨兵）：由一个或多个Sentinel实例组成的Sentinel系统，它可以监视任意多个主从服务器\n当监视的主服务器宕机时，自动下线主服务器，并且择优选取从服务器升级为新的主服务器。 \nSentinel本质上就是一个Redis服务器，一个拥有较少命令和部分特殊功能的Redis服务器\n哨兵的职能：\n\n监控：不断地检查主节点和从节点是否运作正常。周期性地给所有的主从库发送 PING 命令，检测它们是否仍然在线运行，没有在规定时间内响应哨兵的 PING 命令，哨兵就会把它标记为“下线状态”；若主库下线，就会开始自动切换主库的流程。\n通知：当被监控的某个 Redis 服务器出现问题时， 哨兵可以通过 API 向管理员或者其他应用程序发送通知。当推举出新主库时，哨兵会把新主库的连接信息发给其他从库，和新主库建立连接。同时也会将连接信息通知客户端。\n故障转移：当 主节点 不能正常工作时，哨兵会开始故障转移操作，它会将失效主节点的其中一个 从节点升级为新的主节点，并让其他从节点改为复制新的主节点。\n配置提供：客户端在初始化时，通过连接哨兵来获得当前 Redis 服务的主节点地址，当试图连接失效的主服务器时，哨兵集群也会向客户端返回新主服务器的地址\n\n主观下线和客观下线哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态。如果哨兵发现主库或从库对 PING 命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”。如果检测的是从库，那么哨兵直接标记为“下线”，因为从库的下线影响一般不太大，集群的对外服务不会间断。\n但是，如果检测的是主库，那么，哨兵还不能简单地把它标记为“主观下线”，因为有可能出现误判。一旦错误启动了主从切换，后续的选主和通知操作都会带来额外的计算和通信开销。误判一般会发生在集群网络压力较大、网络拥塞，或者是主库本身压力较大的情况下。\n因为哨兵通常会采用多实例组成的集群模式进行部署，这也被称为哨兵集群。引入集群一起来判断，多个哨兵的网络同时不稳定的概率较小，就可以避免单个哨兵误判的情况。\n在判断主库是否下线时，只有大多数（一半以上）的哨兵实例都判断主库已经“主观下线”了，主库才会被标记为客观下线\n故障转移的步骤\n在Slave中选择数据最新的作为新的Master\n向其他Slave发送新的复制指令，让其他从服务器成为新的Master的Slave\n继续监视旧Master，如果其上线则将旧Master设置为新Master的Slave\n\nRedis的数据过期淘汰策略定期删除策略：启用一个计时器定时监视所有的key，判断key是否过期，过期就删除。这种策略可以保证过期的Key最终都会被删除。缺点：遍历内存中所有的key非常消耗CPU。并且如果key已经过期，但是计时器未被唤起，这段时间内Key仍可以使用\n惰性删除策略：在获取key时，才判断key是否过期，过期即可删除。缺点：若key一直未被使用，那么就算过期了也不会被删除\n定期删除+惰性删除：结合两者的特性，每次选取部分key扫描，减轻了CPU的负担。\n内存淘汰机制：\n\nvolatile-lru：从已设置过期时间的数据集中选取最少使用的数据淘汰\nvolatile-ttl：从已设置过期时间的数据集中选取将要过期的数据淘汰\nvolatile-random：随机选取数据淘汰\nallkeys-lru：当内存不足以容纳新数据时，移除最少使用的Key\nallkeys-random：从数据集中任意选择数据淘汰\nno-eviction：禁止淘汰数据，满了就拒绝写入\n\nRedis缓存穿透缓存穿透是指查询一个根本不存在的数据，缓存层和持久层都不会命中，请求都会压到数据库，从而压垮数据库。\n比如用户一个不存在的用户id获取用户信息\n在日常工作中出于容错的考虑，如果从持久层查不到数据则不写入缓存层，缓存穿透将导致不存在的数据每次请求都要到持久层去查询，失去了缓存保护后端持久的意义。\n缓存穿透解决方案：\n对空值缓存：如果一个查询返回的数据为空（不管数据是否存在），我们仍然把这个空结果（null）进行缓存，设置空结果的过期时间会很短，最长不超过五分钟。\n设置可访问的白名单：使用bitmaps；类型定义一个可以访问的名单，名单id作为bitmaps的偏移量，每次访问和bitmaps里面的id进行比较，如果访问id不在bitmaps里面，进行拦截，不允许访问\n采用布隆过滤器：用布隆过滤器当缓存的索引，只有在布隆过滤器中，才去查询缓存，如果不在布隆器中，则直接返回。\n\n\n布隆过滤器是一种概率型数据结构，它可以告诉你某种东西一定不存在或者可能存在，当布隆过滤器说，某种东西存在时，这种东西可能不存在；当布隆过滤器说，某种东西不存在时，那么这种东西一定不存在。 常用于解决一个元素是否在某个集合中的业务场景，但是判断某种东西是否存在时，可能会被误判。\n向布隆过滤器中添加key时，会使用多个hash函数对key进行hash并取模获得一个位置，每个hash函数都会算得一个不同的位置，把数组的这几个位置都置为1。\n向布隆过滤器询问key是否存在时，计算散列值，看看位数组中这几个位置是否都为1，只要有一个位为0，那么说明布隆过滤器中这个key一定不存在。\n如果这几个位置都是1，只是极有可能存在，因为这些位被置为1可能是因为其他的key存在所致。如果这个位数组比较稀疏，判断正确的概率就会很大，如果这个位数组比较拥挤，判断正确的概率就会降低。\nRedis缓存击穿缓存击穿是指缓存中没有但数据库中有的数据，这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。比如微博热搜的一个突发事件，如果没有把这个词条作为热点词存储到缓存中或者缓存时间到期，那么用户访问这个词时，就会通过缓存，直接访问数据库，引起数据库压力瞬间增大。\n它和缓存穿透的区别在于：缓存击穿是指缓存中没有但数据库中有的数据，由于并发用户特别多，同时读缓存没读到数据，同时数据库取数据引起数据库压力瞬间增大，造成过大压力。缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求。\n缓存击穿解决方案：\n预先设置热门数据：在redis高峰访问前，把一些热门数据提前存入redis中，监控哪些数据是热门数据，实时调整key的过期时长\n使用分布式锁：\n\nRedis缓存雪崩情况一：当数据保存在缓存中，并且设置了过期时间。如果在某一个时刻，大量数据同时过期，此时，再访问这些数据的话，就会发生缓存缺失，应用就会把请求发送给数据库，从数据库中读取数据。如果应用的并发请求量很大，从而导致数据库压力激增\n情况一解决方案\n避免给大量的数据设置相同的过期时间，可以使用一个较小的随机数来作为波动值（随机增加 1~3 分钟），这样一来，不同数据的过期时间有所差别，但差别又不会太大，既避免了大量数据同时过期，同时也保证了这些数据基本在相近的时间失效，仍然能满足业务需求。\n服务降级：对于优先级不同的数据采用不同的应对措施来降低数据库压力。当业务应用访问非核心数据（例如电商商品属性）时，暂时停止从缓存中查询这些数据，而是直接返回预定义信息、空值或是错误信息；当业务应用访问核心数据（例如电商商品库存）时，仍然允许查询缓存，如果缓存缺失，也可以继续通过数据库读取。\n\n情况二：Redis 缓存实例发生故障宕机，无法处理请求，导致大量请求同时积压到持久层，从而发生缓存雪崩。\n情况二解决方案\n服务熔断：暂停业务应用对缓存系统的接口访问。业务应用调用缓存接口时，缓存客户端并不把请求发给 Redis 缓存实例，而是直接返回，等到 Redis 缓存实例重新恢复服务后，再允许应用请求发送到缓存系统。避免引发连锁的数据库雪崩。但是这种方法对业务应用的影响大，因为暂停了访问\n请求限流：不暂停，而是限制访问量，在业务系统的请求入口前端控制每秒进入系统的请求数，避免过多的请求被发送到数据库。\n事前预防：构建 Redis 缓存高可靠集群。如果 Redis 缓存的主节点故障宕机了，从节点还可以切换成为主节点，继续提供缓存服务，避免了由于缓存实例宕机而导致的缓存雪崩问题。\n\nRedis缓存和数据库的数据一致性Redis网络模型Redis为何选择单线程，其性能瓶颈究竟在哪里\n\n\n\n\n\n\n\n\nRedis 官方的对于此的回答是：\n对于一个 DB 来说，CPU 通常不会是瓶颈，因为大多数请求不是 CPU 密集型的，而是 I&#x2F;O 密集型。\n具体到 Redis 的话，如果不考虑 RDB&#x2F;AOF 等持久化，Redis 是完全的纯内存操作，执行速度是非常快的，因此这部分操作通常不会是性能瓶颈，Redis 真正的性能瓶颈在于网络 I&#x2F;O，也就是客户端和服务端之间的网络传输延迟，因此 Redis 选择了单线程的 I&#x2F;O 多路复用来实现它的核心网络模型。\n\n避免过多的上下文切换开销：上下文的切换涉及程序计数器、堆栈指针和程序状态字等一系列的寄存器置换、程序堆栈重置，如果是进程内的多线程切换还OK，因为单一进程内多线程共享进程地址空间，线程上下文切换代价比较小。如果是跨进程调度，则需要切换掉整个进程地址空间，开销就会很大，而单线程则可以规避进程内频繁的线程切换开销，因为程序始终运行在进程中单个线程内，没有多线程切换的场景。\n避免同步机制的开销：如果 Redis 选择多线程模型，又因为 Redis 是一个数据库，那么势必涉及到底层数据同步的问题，则必然会引入同步锁，而Redis 不仅仅提供了简单的 key-value 数据结构，还有 list、set 和 hash 等等数据结构，不同数据结构的加锁粒度又不尽相同，如果引入多线程，同步锁的竞争和锁释放会增加程序复杂度，还会降低性能。\n简单可维护：Redis 选择单线程可以说是多方博弈之后的一种权衡：在保证足够的性能表现之下，使用单线程保持代码的简单和可维护性。\n\nRedis 最初选择的是单线程网络模型，因为CPU通常不会成为性能瓶颈。瓶颈往往是内存和网络，因此单线程足够了。然而随着互联网的飞速发展，互联网业务系统所要处理的线上流量越来越大，Redis 的单线程模式会导致系统消耗很多 CPU 时间在网络 I&#x2F;O 上从而降低吞吐量，所以Redis 的网络 I&#x2F;O 瓶颈就越来越明显。要提升 Redis 的性能有两个方向：优化网络 I&#x2F;O 模块，提高机器内存读写的速度。前者依赖IO模型的设计优化，后者则依赖于硬件的发展。\nRedis到底是不是单线程的？其实Redis 早在4.0就已经引入了多线程。\nRedis4.0引入多线程处理异步任务\nRedis 的 DEL 命令是用来删除掉一个或多个 key 储存的值，它是一个阻塞的命令，删除的 key 里的值最多几十上百个对象时，可以很快完成，阻塞不明显。但是如果你要删的是一个超大的键值对，里面有几百万个对象，那么这条命令可能会阻塞至少好几秒，又因为事件循环是单线程的，所以会阻塞后面的其他事件，导致吞吐量下降。于是，在 Redis4.0 之后增加了一些的非阻塞命令如 UNLINK。\nUNLINK 命令其实就是 DEL 的异步版本，它不会同步删除数据，而是把 key 从 keyspace 中暂时移除掉，然后将任务添加到一个异步队列，由后台线程去删除，不过如果用 UNLINK 去删除一个很小的 key，用异步的方式去做反而开销更大。所以它会先计算一个开销，只有当这个值大于 64 才会使用异步的方式去删除 key，对于基本的数据类型如 List、Set、Hash 这些，开销就是其中存储的对象数量。\nRedis6.0正式在网络模型中实现 I&#x2F;O 多线程\n见下文详解\n为什么redis这么快\n完全基于内存，所以IO效率高\n单线程模型\n合理高效的数据结构\nIO多路复用处理客户端socket连接\n\n单线程事件循环模型（v1.0到v6.0）\n从 Redis 的 v1.0 到 v6.0 版本之前，Redis 的核心网络模型一直是一个典型的单 Reactor 模型：\n利用 epoll&#x2F;select&#x2F;kqueue等多路复用技术，在单线程的事件循环中不断去处理事件（客户端请求），最后回写响应数据到客户端\nclient：客户端对象，Redis 是典型的 CS 架构（Client &lt;—&gt; Server），客户端通过 socket 与服务端建立网络通道然后发送请求命令，服务端执行请求的命令并回复。Redis 使用结构体 client 存储客户端的所有相关信息以及进行数据的收发。因为是NIO，所以面向缓冲区，client对象内包括但不限于读入缓冲区 -- querybuf，写出缓冲区 -- buf，写出数据链表 -- reply\naeApiPoll：I&#x2F;O 多路复用 API，是基于 epoll_wait&#x2F;select&#x2F;kevent 等系统调用的封装，监听等待读写事件触发，然后处理，它是事件循环（Event Loop）中的核心函数，是事件驱动得以运行的基础。\nacceptTcpHandler：连接应答处理器，底层使用系统调用 accept 接受来自客户端的新连接，并为新连接注册绑定命令读取处理器，以备后续处理新的客户端 TCP 连接；\nreadQueryFromClient：命令读取处理器，解析并执行客户端的请求命令。\nbeforeSleep：事件循环中进入 aeApiPoll 等待事件到来之前会执行的函数，其中包含一些日常的任务，比如把 client-&gt;buf 或者 client-&gt;reply （后面会解释为什么这里需要两个缓冲区）中的响应写回到客户端，持久化 AOF 缓冲区的数据到磁盘等，相对应的还有一个 afterSleep 函数，在 aeApiPoll 之后执行。\nsendReplyToClient：命令回复处理器，当一次事件循环之后写出缓冲区中还有数据残留，则这个处理器会被注册绑定到相应的连接上，等连接触发写就绪事件时，它会将写出缓冲区剩余的数据回写到客户端。\nRedis 内部实现了一个高性能的事件库 — AE，基于 epoll&#x2F;select&#x2F;kqueue&#x2F;evport 四种事件驱动技术，实现 Linux&#x2F;MacOS&#x2F;FreeBSD&#x2F;Solaris 多平台的高性能事件循环模型。Redis 的核心网络模型正式构筑在 AE 之上，包括 I&#x2F;O 多路复用、各类处理器的注册绑定，都是基于此才得以运行。\n以下便是单线程事件循环模型的全过程：\n\nRedis 服务器启动，开启主线程事件循环（Event Loop），注册 acceptTcpHandler 连接应答处理器到用户配置的监听端口对应的文件描述符，等待新连接到来；\n客户端和服务端建立网络连接；\nacceptTcpHandler 被调用，主线程将 readQueryFromClient 命令读取处理器绑定到新连接对应的文件描述符上，并初始化一个 client 对象绑定这个客户端连接；\n客户端发送请求命令，触发读就绪事件，主线程调用 readQueryFromClient将从 socket 读取到的命令存入 client-&gt;querybuf 读入缓冲区；\n接着调用 processInputBuffer，在其中使用 processInlineBuffer 或者 processMultibulkBuffer 解析命令，最后调用 processCommand 执行命令；\n根据请求命令的类型（SET, GET, DEL, EXEC 等），分配相应的命令执行器去执行，最后调用 addReply 函数族将响应数据写入到对应 client 的写出缓冲区：client-&gt;buf 是首选的写出缓冲区，固定大小 16KB，一般来说可以缓冲足够多的响应数据，但是如果客户端在时间窗口内需要响应的数据非常大，那么则会自动切换到 client-&gt;reply 链表上去，使用链表理论上能够保存无限大的数据（受限于机器的物理内存），最后把 client 添加进一个 LIFO 队列 clients_pending_write；\n在事件循环（Event Loop）中，主线程执行 beforeSleep –&gt; handleClientsWithPendingWrites，遍历 clients_pending_write 队列，调用 writeToClient 把 client 的写出缓冲区里的数据回写到客户端，如果写出缓冲区还有数据遗留，则注册 sendReplyToClient 命令回复处理器到该连接的写就绪事件，等待客户端可写时在事件循环中再继续回写残余的响应数据。\n\n总结概括：\n主线程承包了连接的处理，命令的解析以及数据的收发。使用命令读取处理器监听文件描述符，当读事件发生时，主线程便会到已经读取到数据的缓冲区进行处理，并写入数据到写缓冲区，写完成后便会将client对象添加到就绪队列中。使用事件循环将队列中的数据写回客户端。\n\n其实就是很典型的单reactor模型\nRedis 的核心网络模型在 6.0 版本之前，一直是单 Reactor 模式，虽然在 4.0 版本中引入了多线程，但是那个更像是针对特定场景（删除超大 key 值等）而打的补丁，并不能被视作核心网络模型的多线程。\nRedis 多线程网络模型（v6.0之后）前文说到，要提升 Redis 的性能有两个方向：优化网络 I&#x2F;O 模块，提高机器内存读写的速度。后者由于硬件的限制，暂时无解。\n网络 I&#x2F;O 的优化又可以分为两个方向：零拷贝技术或者 DPDK 技术，利用多核优势。\n零拷贝具有局限性，无法完全适配 Redis 这一类复杂的网络 I&#x2F;O 场景，因此，利用多核优势成为了优化网络 I&#x2F;O 性价比最高的方案。\n\n\nRedis 服务器启动，开启主线程事件循环（Event Loop），注册 acceptTcpHandler 连接应答处理器到用户配置的监听端口对应的文件描述符，等待新连接到来；\n客户端和服务端建立网络连接；\nacceptTcpHandler 被调用，主线程将 readQueryFromClient 命令读取处理器绑定到新连接对应的文件描述符上，并初始化一个 client 绑定这个客户端连接；\n客户端发送请求命令，触发读就绪事件，服务端主线程不会通过 socket 去读取客户端的请求命令，而是先将 client 放入一个 LIFO 队列 clients_pending_read；\n在事件循环（Event Loop）中，主线程执行 beforeSleep –&gt;handleClientsWithPendingReadsUsingThreads，利用 Round-Robin 轮询策略，把 clients_pending_read队列中的连接均匀地分配给 I&#x2F;O 线程各自的本地 FIFO 任务队列 io_threads_list[id] 和主线程自己，I&#x2F;O 线程通过 socket 读取客户端的请求命令，存入 client-&gt;querybuf 并解析第一个命令，但不执行命令，主线程忙轮询，等待所有 I&#x2F;O 线程完成读取任务；\n主线程和所有 I&#x2F;O 线程都完成了读取任务，主线程结束忙轮询，遍历 clients_pending_read 队列，执行所有客户端连接的请求命令，先调用 processCommandAndResetClient 执行第一条已经解析好的命令，然后调用 processInputBuffer 解析并执行客户端连接的所有命令，在其中使用 processInlineBuffer 或者 processMultibulkBuffer 根据 Redis 协议解析命令，最后调用 processCommand 执行命令；\n根据请求命令的类型（SET, GET, DEL, EXEC 等），分配相应的命令执行器去执行，最后调用 addReply 函数族将响应数据写入到对应 client 的写出缓冲区：client-&gt;buf  client-&gt;reply ，和单线程模型一样，最后把 client 添加进一个 LIFO 队列 clients_pending_write；\n在事件循环（Event Loop）中，主线程执行 beforeSleep –&gt; handleClientsWithPendingWritesUsingThreads，利用 Round-Robin 轮询策略，把 clients_pending_write 队列中的连接均匀地分配给 I&#x2F;O 线程各自的本地 FIFO 任务队列 io_threads_list[id] 和主线程自己，I&#x2F;O 线程通过调用 writeToClient 把 client 的写出缓冲区里的数据回写到客户端，主线程忙轮询，等待所有 I&#x2F;O 线程完成写出任务；\n主线程和所有 I&#x2F;O 线程都完成了写出任务， 主线程结束忙轮询，遍历 clients_pending_write 队列，如果 client 的写出缓冲区还有数据遗留，则注册 sendReplyToClient 到该连接的写就绪事件，等待客户端可写时在事件循环中再继续回写残余的响应数据。\n\n总结：大部分逻辑和之前的单线程模型是一致的，变动的地方仅仅是把读取客户端请求命令和回写响应数据的逻辑异步化，主线程使用轮询将client对象分配给不同的IO线程，每个IO线程自带一个队列，由IO线程完成请求的读取和数据的写回。需要注意的是：I&#x2F;O 线程仅仅是读取和解析客户端命令而不会真正去执行命令，客户端命令的执行最终还是要在主线程上完成。\n既然是多线程，那么有同步锁吗Redis 的多线程模式下，是没有对数据进行锁保护的，事实上 Redis 的多线程模型是全程无锁（Lock-free）的。\n这是通过原子操作+交错访问来实现的，主线程和 I&#x2F;O 线程之间共享的变量有三个：io_threads_pending 计数器、io_threads_op I&#x2F;O 标识符和 io_threads_list 线程本地任务队列。\nio_threads_pending 是原子变量，不需要加锁保护，io_threads_op 和 io_threads_list 这两个变量则是通过控制主线程和 I&#x2F;O 线程交错访问来规避共享数据竞争问题：I&#x2F;O 线程启动之后会通过忙轮询和锁休眠等待主线程的信号，在这之前它不会去访问自己的本地任务队列 io_threads_list[id]，\n而主线程会在分配完所有任务到各个 I&#x2F;O 线程的本地队列之后才去唤醒 I&#x2F;O 线程开始工作\n并且主线程之后在 I&#x2F;O 线程运行期间只会访问自己的本地任务队列 io_threads_list[0] 而不会再去访问 I&#x2F;O 线程的本地队列，这也就保证了主线程永远会在 I&#x2F;O 线程之前访问 io_threads_list 并且之后不再访问，保证了交错访问。\nio_threads_op 同理，主线程会在唤醒 I&#x2F;O 线程之前先设置好 io_threads_op 的值，并且在 I&#x2F;O 线程运行期间不会再去访问这个变量。\nRedis的多线程网络模型和标准的多reactor模式有什么区别？在标准的 Multi-Reactors&#x2F;Master-Workers 模式下，Workers 会完成 网络读 -&gt; 数据解析 -&gt; 命令执行 -&gt; 网络写 整套流程，而Master 只负责分派任务。\n而在 Redis 的多线程方案中，I&#x2F;O 线程任务仅仅是通过 socket 读取客户端请求命令并解析，没有真正去执行命令，所有客户端命令最后还需要回到主线程去执行，因此对多核的利用率并不算高，而且每次主线程都必须在分配完任务之后忙轮询等待所有 I&#x2F;O 线程完成任务之后才能继续执行其他逻辑。\n\n为什么Redis要使用这种不寻常的线程模型？即便是多线程模型，但是也仅仅是针对于网络IO，命令的执行还是只有一个主线程。Redis 之所以如此设计它的多线程网络模型，主要的原因是为了保持兼容性，因为以前 Redis 是单线程的，所有的客户端命令都是在单线程的事件循环里执行的，也因此 Redis 里所有的数据结构都是非线程安全的，现在引入多线程，如果按照标准的 Multi-Reactors&#x2F;Master-Workers 模式来实现，则所有内置的数据结构都必须重构成线程安全的，这个工作量无疑是巨大且麻烦的。所以Redis 目前的多线程方案更像是一个折中的选择：既保持了原系统的兼容性，又能利用多核提升 I&#x2F;O 性能。\n总结：Redis为其多线程网络模型做了哪些优化？\n使用 I&#x2F;O 线程实现网络 I&#x2F;O 多线程化，I&#x2F;O 线程只负责网络 I&#x2F;O 和命令解析，不执行客户端命令\n利用原子操作+交错访问实现无锁的多线程模型\n隔离主进程和其他子进程，让多线程网络模型能发挥最大的性能。Redis 通过设置 CPU 亲和性，可以将主进程和子进程绑定到不同的核隔离开来，使之互不干扰\n\n","slug":"Redis随想","date":"2022-09-24T05:45:16.000Z","categories_index":"","tags_index":"数据库基础","author_index":"Samuel"},{"id":"e0c4de6a72c616ec823d805c53472b1a","title":"子集排列问题sucks","content":"回溯算法解决所有子集排列问题形式一：元素无重复，且不可复选，即nums中所有元素均唯一，且最多使用一次\n/* 组合/子集问题回溯算法框架 */\n//使用start参数来避免复选\nvoid backtrack(int[] nums, int start) &#123;\n    // 回溯算法标准框架\n    for (int i = start; i &lt; nums.length; i++) &#123;\n        // 做选择\n        track.addLast(nums[i]);\n        // 注意参数\n        backtrack(nums, i + 1);\n        // 撤销选择\n        track.removeLast();\n    &#125;\n&#125;\n/* 排列问题回溯算法框架 */\n//使用used数组来记录已选过的元素，避免复选\nvoid backtrack(int[] nums) &#123;\n    for (int i = 0; i &lt; nums.length; i++) &#123;\n        // 剪枝逻辑\n        if (used[i]) &#123;\n            continue;\n        &#125;\n        // 做选择\n        used[i] = true;\n        track.addLast(nums[i]);\n\n        backtrack(nums);\n        // 撤销选择\n        track.removeLast();\n        used[i] = false;\n    &#125;\n&#125;\n\n形式二：元素有重复，但是不可以复选，即nums中存在重复的元素，但是每个元素只能使用一次\nArrays.sort(nums);\n//为数组排序，使得相同的元素排在一起\n/* 组合/子集问题回溯算法框架 */\nvoid backtrack(int[] nums, int start) &#123;\n    // 回溯算法标准框架\n    for (int i = start; i &lt; nums.length; i++) &#123;\n        // 剪枝逻辑，跳过值相同的相邻树枝\n        if (i > start &amp;&amp; nums[i] == nums[i - 1]) &#123;\n            continue;\n        &#125;\n        // 做选择\n        track.addLast(nums[i]);\n        // 注意参数\n        backtrack(nums, i + 1);\n        // 撤销选择\n        track.removeLast();\n    &#125;\n&#125;\n\n\nArrays.sort(nums);\n/* 排列问题回溯算法框架 */\nvoid backtrack(int[] nums) &#123;\n    for (int i = 0; i &lt; nums.length; i++) &#123;\n        // 剪枝逻辑\n        if (used[i]) &#123;\n            continue;\n        &#125;\n        // 剪枝逻辑，固定相同的元素在排列中的相对位置，若i-1未被选择，那么i也不能选，相当于固定了顺序\n        if (i > 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; !used[i - 1]) &#123;\n            continue;\n        &#125;\n        // 做选择\n        used[i] = true;\n        track.addLast(nums[i]);\n\n        backtrack(nums);\n        // 撤销选择\n        track.removeLast();\n        used[i] = false;\n    &#125;\n&#125;\n\n形式三：元素无重复，但是可以复选\n/* 组合/子集问题回溯算法框架 */\nvoid backtrack(int[] nums, int start) &#123;\n    // 回溯算法标准框架\n    for (int i = start; i &lt; nums.length; i++) &#123;\n        // 做选择\n        track.addLast(nums[i]);\n        // 注意参数\n        backtrack(nums, i);\n        // 撤销选择\n        track.removeLast();\n    &#125;\n&#125;\n\n\n/* 排列问题回溯算法框架 */\nvoid backtrack(int[] nums) &#123;\n    for (int i = 0; i &lt; nums.length; i++) &#123;\n        // 做选择\n        track.addLast(nums[i]);\n        backtrack(nums);\n        // 撤销选择\n        track.removeLast();\n    &#125;\n&#125;\n","slug":"子集排列问题sucks","date":"2022-09-13T05:14:49.000Z","categories_index":"","tags_index":"算法归纳","author_index":"Samuel"},{"id":"d819bd760b595babeef6cadb7a50d452","title":"JVM相关知识","content":"JAVA内存区域讲解运行时数据区域分为两部分：线程共享和线程私有\n线程共享区域：\n堆：是虚拟机内存的最大的一块，此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存，注意是“几乎”，JDK1.7之后，当方法中的对象引用没有被返回或者未被外部使用，就会直接在栈上分配内存。同时，堆也是垃圾收集器管理的主要区域，所以也被称为GC堆。\n\nJDK1.8之前还有永久代实现的方法区，方法区是运行时数据区域的一个逻辑区域，在不同虚拟上方法区的实现是不同的，当虚拟机要使用一个类时，它需要读取并解析class文件获取相关信息，再将信息存入到方法区。方法区会存储已被虚拟机加载的类信息，字段信息，方法信息，常量，静态变量，即时编译器编译后的代码缓存。\n方法区有两种具体实现：永久代permanent gen和元空间metaspace。前者拥有一个由本身JVM设置的大小上限，无法调整，而在8版本之后，转而使用元空间，后者使用的是计算机的直接内存，溢出的概率更小。\n方法区内比较常见的有静态变量和字符串常量池，后者是为了减少string类的内存消耗而专门开辟的，可以避免字符串的重复创建。方法区是一个公共且抽象的概念，在不同虚拟机上可以有不同的实现。\n\n\n\n\n\n线程私有区域：\n虚拟机栈：由一个个栈帧组成，栈帧内包含：局部变量表（八大原始类型，对象引用），操作数栈（作为方法调用的中转站，存放中间计算结果，实现CPU的寄存器的功能），动态链接（当一个方法需要调用其他方法时，动态链接就是未来将符号引用转换为调用方法的直接引用），方法返回地址。方法调用的数据通过栈进行传递，每一个方法没调用时都会有一个对应的栈帧被压入，每一个方法调用结束后，都会有一个栈帧被弹出。当函数调用陷入无限循环，或者压栈太多，导致线程请求的栈的深度超过JAVA虚拟机栈的最大深度时，就会抛出,stackoverflow。栈帧的弹出：return语句，异常抛出，随方法的调用而创建，随方法的结束而销毁，所以无论方法是否正常完成还是异常完成，都可以视为方法结束。\n本地方法栈：和虚拟机栈十分相似，但是本地方法是由c++编写的，所以这个栈是为native方法服务的，同样也会创建栈帧，同样也会抛出栈溢出的错误。\n程序计数器PC：一块较小的内存空间，就是一个计数器，可以看作是当前线程执行的字节码的行号指示器，字节码解释器通过改变PC的值来选取下一条要执行的字节码指令，从而实现循环，跳转，异常处理等功能。每个线程都需要一个独立的PC，PC也是唯一一个不会出现outofmemory的内存区域。执行native方法时PC为空。\n\nJAVA堆GC详解堆分为三部分：新生代，老年代，永久代（JDK8移除，功能由元空间代替实现）\n新生代Young Gen新生代用来存放新生的对象，一般占据1&#x2F;3。新生代中存放着大量刚刚创建的对象，但是大部分对象的存活时间都很短，所以会进行频繁的GC。新生代又分为三个部分Eden，SurvivorFrom，SurvivorTo 。这三个部分默认为8：1：1\n为什么要分配为8：1：1\n因为大部分对象都是朝生夕死，所以Eden区就设置大一些，存活区就设置小一些\nEden区：Java新创建的对象绝大部分会分配在Eden区（如果对象太大，则直接分配到老年代）。当Eden区内存不够的时候，就会触发MinorGC（新生代采用的是复制算法），对新生代进行一次垃圾回收。\nSurvivorFrom区和SurvivorTo区：在GC开始的时候，对象只会存在于Eden区和名为From的Survivor区，To区是空的，一次MinorGc过后，Eden区和SurvivorFrom区存活的对象会移动到SurvivorTo区中，然后会清空Eden区和SurvivorFrom区，并对存活的对象的年龄+1，如果对象的年龄达到15，则直接分配到老年代。MinorGC完成后，SurvivorFrom区和SurvivorTo区的功能进行互换。下一次MinorGC时，会把SurvivorTo区和Eden区存活的对象放入SurvivorFrom区中，并计算对象存活的年龄。\n老年代Old Gen老年代用于存放生命周期较长的内存对象，老年代比较稳定，不会频繁的进行MajorGC。\n而在MaiorGC之前才会先进行一次MinorGc，使得新生的对象进入老年代而导致空间不够才会触发。当无法找到足够大的连续空间分配给新创建的较大对象也会提前触发一次MajorGC进行垃圾回收腾出空间。\n在老年代中，MajorGC采用了标记—清除算法：首先扫描一次所有老年代里的对象，标记出存活的对象，然后回收没有标记的对象。MajorGC的耗时比较长。因为要扫描再回收。MajorGC会产生内存碎片，当老年代也没有内存分配给新来的对象的时候，就会抛出OOM（Out of Memory）异常。\n永久代Permanent Gen（方法区）永久代中包含了虚拟机中可以通过反射获取到的数据，比如Class对象和Method对象。JVM用于描述应用程序中用到的类和方法的元数据，如类的层级信息(包名，父类名，修饰符，接口)，方法的编译信息（参数，返回值，修饰符）及字节码，常量，静态变量就存储在永久代中，如果有类不再需要使用，空间会被释放留给其他类，full GC会进行永久代的回收\n不同的java虚拟机之间可能会进行类共享，因此又分为只读区和读写区\n永久代是有大小上限的，默认为64M，在堆内存中划出一块连续的空间分配给永久代\n元空间Meta SpaceJDK8开始，永久代被彻底删除，替换为元空间，JVM忽略了permsize这个参数，也就是没有outOfMemoryError异常。\n字符串常量池和静态变量也转移到了堆内存，因为字符串在永久代中容易造成性能问题\n元空间使用本地内存来存储类的元数据，所以不再归JVM管理\n为什么要抛弃永久代：\n\n永久代的大小在启动时就会固定好，很难进行调优修改\n元空间使用堆外内存，不由JVM管理，由OS来管理，所以可以不暂停GC的情况下释放类数据\n元空间的每个类加载器都有专门的存储空间\n充分利用了java语言规范的好处：类及相关的元数据的生命周期与类加载器一致\n省略了GC的扫描和压缩的时间\n元空间里面对象的位置是固定的，无需堆内存内GC时将对象不断移动\n元空间只进行线性分配，指针碰撞+OS本地内存&#x3D;大小上限提升，分配内存更迅捷\n\nGC堆内有大量的对象，所以需要GC来不断处理，以保证堆内存空间的合理使用\n并行（Parallel）：多个GC线程并行工作，用户线程等待\n并发（Concurrent）：用户线程和垃圾GC线程同时进行\n如何判断一个对象能否被删除\n被虚拟机栈，本地方法栈，静态变量，字符串常量引用的对象，不能被GC\n若可以被删除：打上标记\n\n标记清理算法：扫描一遍全部对象，删除带标记的对象，容易产生内存碎片\n标记整理算法：扫描一遍全部对象，删除带标记的对象，清理后需要紧凑，不断移动对象，代价比较大\n复制算法：分为1区和2区，无需删除的对象被紧凑复制到2区，然后清空1区，需要两倍的内存\n分代算法：核心是同时发挥“标记整理”和“复制”的优点，让他们分别去处理最适合自己的情况。分代就是为对象设置年龄，在新生代就触发新生代GC也叫minorGC，在老年代就触发老年代GC，也叫major GC，当方法区空间不足时会触发全局GC，也叫full GC\n\n\n\n新生代的GC垃圾回收器：（全部都是复制算法，参考上文）\n\nSerial：最基本，历史最悠久的收集器。单线程，简单，适合于单CPU环境，没有线程交互的开销，所以可以全力进行垃圾回收。需要Stop The World，但是效率不高\nParNew：其实就是多线程版的Serial，适合于多CPU环境，同样需要Stop The World\nParallel Scavenge：吞吐量优先收集器，同样是并行的。PS自带GC自适应调节策略：动态设置Eden和存活区的比例，新生代的大小，晋升老年代的对象年龄。虚拟机会根据运行状态信息来动态调整以获取最优的吞吐量和响应时间。\n\n老年代的GC\nCMS：回收停顿时间优先收集器，基于标记清除算法混合标记整理，并发（Concurrent），低停顿。\nSerial Old：老年代版本Serial，标记整理\nParallel Old：老年代版本的Parallel，标记整理\n\nCMS低停顿的第一次尝试\n\n初始标记：单线程+Stop The World，只扫描和GC root直接关联的对象\n并发标记：并发，进行GC root tracing，在初始标记的基础上继续向下追溯标记，标记出所有存活对象，用户线程可并发\n重新标记：Stop The World，修正并发标记期间因为用户线程的运行而造成的标记变动\n并发清除：并发清除垃圾\n\n并发标记和并发清除是可以和用户线程同时进行的，另外两个阶段需要Stop The World\n特点：\n\n对CPU资源非常敏感：在并发阶段，虽然是并发，但是由于会占用一部分的处理器资源，从而会影响用户线程的性能。CMS默认的回收线程数是（CPU核心数+3）&#x2F;4，所以如果当CPU核心数小于4个，用户线程受到的影响就会非常大。CMS曾经提供过解决方法，就是在并发标记，并发清除的阶段让回收线程和用户线程交替进行从而减少影响。但是效果有限，在JDK9后就被彻底弃用了。\n无法在一次GC流程中处理浮动垃圾：由于具有并发性，用户线程常常会在GC时产生新的垃圾对象，所以无法一次清除。所以需要为老年代设置阈值，JDK1.5是68%，JDK6是92%，当碎片过多时会直接触发GC进行整理。所以会出现一些极端情况，在一次GC还未结束时，老年代使用了91%的空间，且用户线程仍然在不断创建新对象，老年代已经无法容纳，此时会出现并发失败。虚拟机不得不冻结所有的用户线程，转而使用serial收集器来GC，此时效率就大大降低了。\n容易产生空间碎片：因为使用的是标记清除，所以会产生空间碎片，在JDK9之前，设定在因为碎片过多而产生FULL GC时进行碎片整理，即对碎片有一定容忍度。\n\nG1收集器一款面向服务端应用的垃圾收集器，抛弃了传统的分代思想\n步骤：\n\n初始标记：单线程+Stop The World，只扫描和GC root直接关联的对象\n并发标记：并发，进行GC root tracing，可达性分析，在初始标记的基础上继续向下追溯标记，标记出所有存活对象，用户线程可并发\n重新标记：Stop The World，修正并发标记期间因为用户线程的运行而造成的标记变动\n筛选回收：根据region的回收价值和用户期望的停顿时间来进行回收（stop the world）\n\n特点：\n\n以region代替分代思想：G1可以独自管理整个堆\n可预测的停顿：G1能够建立可预测的停顿时间模型，能让使用者明确指定在一个时间段内，消耗在GC上的时间不超过N毫秒，原理：复制算法优先处理垃圾多的区域，可控\n整体看是标记整理，region之间看是标记复制，不会产生碎片\n\nC1和CMS的区别：\n\n管理区域：C1可以管理整个堆，且会将堆分为若干个region来管理，region中可以划分新生代和老年代，且新生代和老年代的大小可以动态调整\nG1收集器可预测垃圾回收的停顿时间（建立可预测的停顿时间模型），这个是G1的优势\n最后一个阶段，CMS是并发的，而C1不是\nG1产生的内存占用比CMS更高\n\nG1如何实现可预测的停顿时间模型？\n将region作为GC的最小单元，每次GC时都会跟踪每个region里垃圾堆积的价值，比如回收的代价，以及回收该region需要的时间，等因素进行综合评估。评估后会维护一个优先级列表，每次会优先处理回收价值最高的region。从而将GC效率最大化。\n三色标记法CMS算法的基础是通过可达性分析找到存活的对象，然后给存活的对象打个标记，最终在清理的时候，如果一个对象没有任何标记，就表示这个对象不可达，需要被清理，标记算法就是使用的三色标记。\n并发标记阶段是从GC Root直接关联的对象开始枚举的过程\nGC Root\n虚拟机栈（栈帧中的局部变量表）中引用的对象\n本地方法栈中 JNI（即一般说的 Native 方法）引用的对象\n方法区中类静态属性引用的对象\n方法区中常量引用的对象\n\n对象的三个状态：\n\n白色：这个对象还没有被访问过，在初始阶段，所有对象都是白色，所有都枚举完仍是白色的对象将会被当做垃圾对象被清理\n灰色：这个对象已经被访问过，但是这个对象所直接引用的对象中，至少还有一个没有被访问到，表示这个对象正在枚举中\n黑色：对象和它所直接引用的所有对象都被访问过。这里只要访问过就行，比如A只引用了B，B引用了C、D，那么只要A和B都被访问过，A就是黑色，即使B所引用的C或D还没有被访问到，此时B就是灰色。\n\n大致流程：\n\n首先我们从GC Roots开始枚举，它们所有的直接引用变为灰色，自己变为黑色。可以想象有一个队列用于存储灰色对象，会把这些灰色对象放到这个队列中\n然后从队列中取出一个灰色对象进行分析：将这个对象所有的直接引用变为灰色，放入队列中，然后这个对象变为黑色；如果取出的这个灰色对象没有直接引用，那么直接变成黑色\n继续从队列中取出一个灰色对象进行分析，分析步骤和第二步相同，一直重复直到灰色队列为空\n分析完成后仍然是白色的对象就是不可达的对象，可以作为垃圾被清理\n最后重置标记状态\n\n可能出现的两种问题\n\n一个本应该是垃圾的对象被视为了非垃圾\n一个本应该不是垃圾的对象被视为了垃圾\n\n解决方式\n\n增量更新：站在新增引用的对象的角度来解决问题，在增加引用前添加一个写屏障，在屏障中记录新的引用。然后将引用关系中的黑色对象重新设置为灰色，在重新标记阶段再扫描一次，CMS\n原始快照：站在减少引用的对象的角度来解决问题，当灰色对象要删除指向白色对象的引用关系时，就将这个要删除的引用记录下来，在并发扫描结束之后，再将这些记录过的引用关系中的灰色对象为根，重新扫描一次。G1使用，效率更高，但是会产生更多的浮动垃圾，只能等待下次GC\n\n这也可以简化理解为，无论引用关系删除与否，都会按照刚刚开始扫描那一刻的对象图快照来进行搜索\n垃圾收集器如何选择Client模式下的虚拟机：Serial\n注重高吞吐量以及CPU资源敏感：Parallel Scavenge +Parallel Old\n最小化Stop The World时间：G1或者ParNew+CMS\n类文件结构解析字节码：.class扩展名\n\n魔数：magic number：每个class文件的头4个字节被称为魔数（CAFEBABE）唯一作用便是确定这个文件是否为一个能被虚拟机接收的class文件\nclass文件版本号：小版本号+大版本号。高版本的JVM可以执行低版本的class文件\n常量池：常量池计数器+常量池数据区。计数器从1开始，若有某些指向常量池的索引值需要表达“不引用常量池中的项目”这一含义，则可以将索引值设为0。常量池数据区中主要存储两大常量：字面量：即文本字符串，或者被final修饰的常量等。符号引用：package，接口的全名，方法名称或描述符，字段名称或描述符等等。与c不同的是，java在编译时，不会有连接这一步骤，而是会在虚拟机加载class文件时进行动态连接，虚拟机在进行类加载时，将会从常量池中获得对应的符号引用，在类创建时或运行时解析，并翻译到具体的内存地址中。常量池中的每一项都是一个表。常量池可以看作是class文件里的资源仓库，占用空间最大。\n访问标志：用于识别类或者接口的访问信息，比如class是类还是接口，public还是abstract，是否被final修饰等\n索引集合：当前类，父类，接口索引集合\n字段表集合：描述接口或类中声明的变量，不包括方法内声明的局部变量。字段计数器+字段表数据区\n方法表集合：方法计数器+方法数据区\n\n类加载过程加载加载主要完成下面三件事情\n\n通过全类名获取定义此类的二进制字节流\n将字节流代表的静态数据结构转换为方法区的运行时数据结构\n在内存中生成一个代表该类的class对象，作为方法区数据的访问入口\n\n连接——验证\n文件格式验证：是否符合class文件格式的规范（CAFEBABE），主次版本号是否在虚拟机的处理范围内，常量池中的的常量是否都可以支持\n元数据验证：对字节码的信息进行语义分析，保证描述的信息符合java的语言规范，比如这个类是否有父类，这个类是否继承了不被允许继承的类\n字节码验证：这是最为复杂的一个阶段，通过数据流和控制流的分析，确定程序语义是合法，符合逻辑的，比如确保任意时刻操作数栈都能配合工作\n符号引用验证：确保解析动作能正确执行\n\n连接——准备这个阶段会正式为变量分配内存并设置初始变量，仅包括类变量,static\n连接——解析将常量池里的符号引用替换为直接引用，主要针对，接口，字段，类方法。符号引用就是用一组符号来描述目标，可以是任何字面量；直接引用就是直接指向目标的指针，偏移量\n初始化这是类加载的最后一步，执行初始化方法，在这一步，JVM才真正开始执行类中定义的java程序代码\nJAVA的类加载器\nBootstrap类加载器：即引导类加载器，由C++语言实现，无父类。主要加载的是JVM自身需要的类，是虚拟机自身的一部分，它负责&#x2F;lib路径下的核心类库或-Xbootclasspath参数指定的路径下的jar包加载到内存中，虚拟机按照文件名识别jar包，处于安全考虑，启动类加载器只加载包名为java,javax,sun等开头的jar包，即使将不符合要求的jar包丢入lib目录下也没法被识别。\nExtention类加载器：即扩展类加载器，是指sun公司实现的ExtClassLoader类，由Java语言实现，父类加载器为null，是Launcher中的静态内部类，它负责加载&#x2F;lib&#x2F;ext目录或者由系统变量-Djava.ext.dir指定位路径中的类库，开发者可以直接使用标准扩展类加载器。\nApplication类加载器：即应用程序加载器，是指sun公司实现的appClassLoader，父类加载器为扩展类加载器。它负责加载class-path指定路径下的库类，也就是我们经常用到的classpath，一般情况下该类加载是程序中默认的类加载器。\nCustom自定义类加载器：负责加载用户自定义路径下的类包，父类加载器为应用程序加载器\n\n类加载器的三大特征：\n\n委托性：即双亲委派机制，当类A被加载时，首先会委托给父类加载器。引导类加载器会在lib目录下查找是否存在，找到便加载，未找到便回到扩展类加载器。扩展类加载器会在&#x2F;lib&#x2F;ext目录下查找，找到便加载，未找到便回到应用程序加载器。应用程序加载器会在classPath路径下查找，找到则加载，未找到则抛出ClassNotFoundException异常\n可见性：父类加载器加载的类可以被子类观察到，但是子类加载的类对父类不可见\n一个类只可以被加载一次\n\n双亲委派机制：\n\n\nHOTSPOT虚拟机对象创建的过程类加载检测虚拟机遇到new指令时，首先检查这条指令的参数是否能在常量池中定位到这个类的引用，检查这个符号引用代表的类是否已经被加载过，解析，或初始化。若没有，则先执行相应的类加载过程。\n分配内存为新对象分配内存，所需内存大小在类加载完成后就可以确定，分配内存的任务等同于将一块确定大小的内存从堆中划分出来。\n\n指针碰撞：堆内存规整，将用过的内存和没用过的内存整合到两边，中间有一个分界指针，只需要将指针移动相应大小即可完成分配。\n空闲列表：堆内存不规整，虚拟机会维护一个列表，列表中会记录哪些内存块是可用的，寻找到一块满足大小的内存分配后，更新列表。\n\n初始化零值当内存分配后，需要将分配到的内存空间都初始化为0值，这一步保证了对象的字段在java代码中可以不赋值就能直接被使用，程序能访问这些字段的数据类型对应的0值\n设置对象头这个对象是哪个类的实例，对象的HashCode，如何才能找到类的元数据信息，等信息处理后放入对象头中、\n执行init方法在虚拟机的视角来看，对象的创建已经完成，但是对于java程序来说，对象创建才刚刚开始，在init之前所有的字段都是零值，init之后便会将对象按照程序员的意愿进行初始化，一个真正可用的对象才算真正创建。\nHotSpot的oop-klass模型我们平时写的java类编译成.class文件，JVM加载.class文件，那么加载.class文件之后在JVM中就是oop-klass（C++）模型形式存在的\nJVM内部基于oop-klass模型描述一个java类以及其实例\njava类元信息用klass描述，对象用oop来描述\n\njvm在加载class时，会创建instanceKlass，表示其元数据，包括常量池、字段、方法等，存放在方法区\n在new一个对象时，jvm创建instanceOopDesc，来表示这个对象，存放在堆区\n其引用，存放在栈区；\n在JVM中，Hotspot并没有将Java对象直接映射成C++对象，而是实现了Java的对象模型（oop-klass）\n因为C++的对象里含有虚表，这个虚表实现了C++对象的多态，而JVM不希望每个对象中都包含一份虚函数表\n所以就把对象模型拆成 klass 和 oop，其中 oop 中不含有任何虚函数，而 klass 就含有虚函数表\n四种引用类型强引用一般创建对象时如Object obj&#x3D;new Object()，obj指向堆内的instanceOOP，这个指向就是最常见的强引用\n只要强引用存在，垃圾收集器就不会回收被引用的对象。\n软引用使用SoftReference类包装创建的对象如SoftReference softRef &#x3D; new SoftReference&lt;&gt;(obj)\n此时softRef会以强引用指向堆内的SR对象实例，然后SR会以软引用的方式再指向Object实例\n当要发生内存溢出时，软引用对象会被回收，无论是否被引用。\n对适合作为缓存的对象实例添加软引用，内存够的适合拿来即用，内存不够的时候就被回收，避免OOM\n弱引用和软引用类似，使用weakRefence类来进行包装\n不过必要性再次降低，当GC时，无论内存是否够用，都会被回收\n解决Map或者ThreadLocal的内存泄露问题\n虚引用使用PhantomReference来包装，PhantomReference pr &#x3D; new PhantomReference&lt;&gt;(obj,QUEUE);\n这个队列就是引用队列ReferenceQueue，虚引用必须指定相应的引用队列\n虚引用也称作幽灵引用，虚引用并不会影响对象的生命周期，虚引用的特点就是可以充当信号量：\n即当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到引用队列中，可以通过判断queue里面是不是有对象来判断你的对象是不是要被回收了\n这个特性可以用于管理操作系统的本地内存：\n一些网络编程框架如基于NIO的netty，会使用操作系统的本地内存块作为buffer来接收管道传输的数据，\n通常会在JVM里创建指向这个内存块的指针来进行管理，而GC的范围仅限于JVM\n所以就需要进行通知：当这个指针被回收时-&gt;虚引用进入队列-&gt;检测到队列里有虚引用-&gt;回收指针以及指向的OS内存块\n","slug":"JVM基础","date":"2022-09-12T04:37:43.000Z","categories_index":"","tags_index":"Java基础知识","author_index":"Samuel"},{"id":"b8307bc7cc4dad51e597289f7dfa286e","title":"JAVA的字符串","content":"String&amp;StringBuilderString的底层数据结构是数组char value[]\npublic final class String\nimplements java.io.Serializable, Comparable&lt;String>, CharSequence &#123;\n\t/** The value is used for character storage. */\n\tprivate final char value[];\n\t/** Cache the hash code for the string */\n\tprivate int hash; // Default to 0\n\t/** use serialVersionUID from JDK 1.0.2 for interoperability */\n\tprivate static final long serialVersionUID = -6849794470754667710L;\n&#125;\n\nString的类用于存放字符串的方法都用了final来修饰，也就是创建后均不可以被改变，当我们进行一个字符串相连的操作时，便会创建出新的对象\nString str_1 = new String(\"ab\");\nString str_2 = new String(\"ab\");\nString str_3 = \"ab\";\n\n\nSystem.out.println(str_1 == str_2); //false\nSystem.out.println(str_1 == str_2.intern());//false\nSystem.out.println(str_1.intern() == str_2.intern());//true\nSystem.out.println(str_1 == str_3);//false\nSystem.out.println(str_1.intern() == str_3);//true\n\n结论：\n\n&#x3D;&#x3D; ， 在引用类型中是对比的地址，比如str1和str2，两个new出来的对象置于堆内存中，地址肯定不同；但是如果是基础类型如str3，就是对比值；当然也有equal方法，这是对比的是哈希值\nintern()，这是一个本地方法，底层由c++实现，它的作用是将值推进常量池\nString str_3 = &quot;ab&quot;这种赋值方法JVM做了优化，不会创建对象，直接将值放进常量池\n\nStringBuilder//初始化，同样是数组\nnew StringBuilder(16);\n\npublic StringBuilder() &#123;\n\tsuper(16);\n&#125;\nAbstractStringBuilder(int capacity) &#123;\n\tvalue = new char[capacity];\n&#125;\n\n//添加元素\nstringBuilder.append(\"a\");\n\npublic AbstractStringBuilder append(String str) &#123;\n\tif (str == null)\n\treturn appendNull();\n\tint len = str.length();\n\tensureCapacityInternal(count + len);\n\tstr.getChars(0, len, value, count);\n\tcount += len;\n\treturn this;\n&#125;\n\nprivate void ensureCapacityInternal(int minimumCapacity) &#123;\n\t// overflow-conscious code\n\tif (minimumCapacity - value.length > 0)\n\texpandCapacity(minimumCapacity);\n&#125;\nvoid expandCapacity(int minimumCapacity) &#123;\n\tint newCapacity = value.length * 2 + 2;\n\tif (newCapacity - minimumCapacity &lt; 0) newCapacity = minimumCapacity;\n\tif (newCapacity &lt; 0) &#123;\n\t\tif (minimumCapacity &lt; 0) // overflow\n\t\tthrow new OutOfMemoryError();\n\tnewCapacity = Integer.MAX_VALUE;\n\t&#125;\n\tvalue = Arrays.copyOf(value, newCapacity);\n&#125;\n\n对字符串的各种操作方法字符串类\nString：不可修改\n当使用字符串的相加操作时，不会删掉原字符串，而是在常量池里面新建一个新的String，储存修改后的结果\nequals();\n//boolean比较两个字符串是否相等\ncompareTo();\n//基于每个字符进行Unicode值比较，若完全相等，返回0；小于参数，返回负数；大于参数，返回正数\ncontains();\n//boolean若包含某个字符，返回true\nindexOf();\n//返回字符第一次出现的索引，未找到则返回-1、\nstartsWith(); endsWith();\n//boolean测试字符串是否以参数为前缀开头;是否以参数为后缀结尾\nreplaceAll(String regex,String replacement);\n//将字符串中的所有的regex替换为replacement\nsplit(String regex);\nString[] arr = str.split(\",\");\n//每个字符以regex分割并返回一个string型数组\nsubstring();\n//可以接收两个参数，返回这个索引截取的子串\ntrim();\n//删除前置和后置的所有空格\ntoUpperCase();toLowerCase();\n//大小写转换\njoin(\"mark\",\"\");\n//为一系列字符串添加分割符并拼成一个新的字符串\n\nStringBuilder：可以修改，可以在常量池里原地修改字符串\nStringBuffer：可以修改，且线程安全，基本与StringBuilder相同\nappend();\n//字符串连接\ntoString();\n//返回一个与构建器相同的String\nsetCharAt(int i, char c);\n//把某个位置的字符置为C\ninsert(int offset, String str/char c);\n//在指定位置之前插入字符串或字符\ndelete(int startIndex,int endIndex);\n//删除指定范围内的字符串\n\n\ndeleteCharAt (int index);\n//删除某个字符\nreplace(int start,int end,String str);\n//在指定范围内用str替换\n reverse();\n//字符串反转\nsubstring(int start,int end);\n//返回子串\n\n如何将ArrayList转换为数组？\nArrayList&lt;Integer> list = new ArrayList&lt;>();\nfor (int i = 0; i &lt; 10; i++) &#123;\n\tlist.add(i);\n&#125;\n//toArray()会返回一个object数组，所以在对元素进行获取时需要进行类型转换\nObject[] o = list.toArray();\nfor (Object value : o) &#123;  \n    int num = (int) value;\n\tSystem.out.println(num);\n &#125;\n","slug":"Java的字符串","date":"2022-08-14T04:57:02.000Z","categories_index":"","tags_index":"Java基础知识","author_index":"Samuel"},{"id":"9a0ea7adf62049ce83652b0a7c894a59","title":"Java数据结构","content":"ArrayListArrayList即数组列表，是基于数组实现的，这个数组可以插入任何元素，只不过这个数组是可以按需扩容，可以进行数据拷贝的\nArrayList的构造private static final int DEFAULT_CAPACITY = 10;\n//默认初始化容量\nprivate int size; \n//size指elementData中实际有多少元素\ntransient Object[] elementData;\n//element.length指集合容量\n//transient关键字只能修饰变量，不可修饰方法和类，该变量被序列化后将无法被访问\nprotected transient int modCount = 0;\n//记录对list操作的次数\n\n//无参构造\nprivate static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;\npublic ArrayList() &#123;\n    this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;\n&#125;\n//当使用无参构造时，给elementData数组赋值了一个空数组，这个空数组知道当无参构造时，第一次添加元素后如何扩容。构造时赋予空数组，而当第一次添加元素时，容量便会扩充到10\n\n//有参构造\nprivate static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;\npublic ArrayList(int initialCapacity) &#123;\n    if (initialCapacity > 0) &#123;\n        this.elementData = new Object[initialCapacity];\n        //参数大于零且合法，便初始化一个数组便赋值给elementData\n    &#125; else if (initialCapacity == 0) &#123;\n        //参数为零，便将空数组赋值给elementData\n        this.elementData = EMPTY_ELEMENTDATA;\n    &#125; else &#123;\n        //参数不合法，提示错误\n        throw new IllegalArgumentException(\"Illegal Capacity: \"+\n                                  \t\t\tinitialCapacity);\n    &#125;\n&#125;\n\n//使用指定collection来构造\npublic ArrayList(Collection&lt;? extends E> c) &#123;\n    elementData = c.toArray();\n    //将collection c转化为数组并赋值给elementData\n    if ((size = elementData.length) != 0) &#123;、\n        // c.toArray might (incorrectly) not return Object[] (see 6260652)\n        if (elementData.getClass() != Object[].class)\n            //若elementData的数组类型不是object，就做一次转换\n        elementData = Arrays.copyOf(elementData, size, Object[].class);\n    &#125; else &#123;\n        // replace with empty array.\n        this.elementData = EMPTY_ELEMENTDATA;\n    &#125;\n&#125;\n\nArrayList的相关操作//add 操作\npublic boolean add(E e) &#123;\n    ensureCapacityInternal(size + 1);  // Increments modCount!!\n    //对size进行自增操作，即成功添加新元素\n    elementData[size++] = e;\n    return true;\n&#125;\n\nprivate void ensureCapacityInternal(int minCapacity) &#123;\n    //当使用无参构造时，添加一个元素时会将容量设置为默认10，并进行扩容\n    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123;\n        minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);\n    &#125;\n    ensureExplicitCapacity(minCapacity);\n&#125;\n\nprivate void ensureExplicitCapacity(int minCapacity) &#123;\n    //确认是否需要扩容：即size+1是否会超出容量\n    modCount++;\n    // overflow-conscious code\n    if (minCapacity - elementData.length > 0)\n        //扩容，使用grow方法\n        grow(minCapacity);\n&#125;\n\n//grow操作，当添加元素发现容量不足或无参构造第一次添加元素时，需要扩容\nprivate void grow(int minCapacity) &#123;\n    // overflow-conscious code\n    int oldCapacity = elementData.length;\n    int newCapacity = oldCapacity + (oldCapacity >> 1);\n    //将容量扩充至原大小的1.5倍，但是这个大小可能有大有小，所以需要if语句来进行判断\n    if (newCapacity - minCapacity &lt; 0)\n        newCapacity = minCapacity;\n    //扩容后的容量还是很小，不满足需要的容量，则直接将需要的容量赋值给newCapacity\n    if (newCapacity - MAX_ARRAY_SIZE > 0)\n        //扩容后的容量太大了，就改变扩容方式\n        newCapacity = hugeCapacity(minCapacity);\n    // minCapacity is usually close to size, so this is a win:\n    //将原数组的大小扩充至newCapacity\n    elementData = Arrays.copyOf(elementData, newCapacity);\n&#125;\n\n//当扩大1.5倍后超出了最大范围，那么就干脆将大小设为最大范围\nprivate static int hugeCapacity(int minCapacity) &#123;\n    if (minCapacity &lt; 0) // overflow\n        throw new OutOfMemoryError();\n    return (minCapacity > MAX_ARRAY_SIZE) ?\n        Integer.MAX_VALUE :\n        MAX_ARRAY_SIZE;\n&#125;\n\nprivate static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;\n\n//remove操作\n//输入索引\npublic E remove(int index) &#123;\n    //检测这个元素是否处于数组的最后一个位置\n    rangeCheck(index);\n    modCount++;\n    E oldValue = elementData(index);\n    int numMoved = size - index - 1;\n    if (numMoved > 0)\n        //若index不在最后一位，则将index+1开始向后的所有元素向前移动一位，相当于删除了index位置的元素\n        System.arraycopy(elementData, index+1, elementData, index, numMoved);\n    //将最后一位赋值为null\n    elementData[--size] = null; // clear to let GC do its work\n    return oldValue;\n&#125;\n//参数直接为指定元素\npublic boolean remove(Object o) &#123;\n    if (o == null) &#123;\n        for (int index = 0; index &lt; size; index++)\n            if (elementData[index] == null) &#123;\n                fastRemove(index);\n                return true;\n            &#125;\n    &#125; else &#123;\n        for (int index = 0; index &lt; size; index++)\n            if (o.equals(elementData[index])) &#123;\n                fastRemove(index);\n                return true;\n            &#125;\n    &#125;\n    return false;\n&#125;\n\nprivate void fastRemove(int index) &#123;\n    modCount++;\n    int numMoved = size - index - 1;\n    if (numMoved > 0)\n        System.arraycopy(elementData, index+1, elementData, index,numMoved);\n    elementData[--size] = null; // clear to let GC do its work\n&#125;\n\n//get操作\npublic E get(int index) &#123;\n    rangeCheck(index);\n    return elementData(index);\n&#125;\n//由于arraylist的底层基于数组，获取元素就很简单，直接调用数组访问即可\n\n//迭代器\n//由上述源码可知，在进行remove的时候，size是时刻动态变化的，所以不能对arrayList进行for循环遍历来remove元素，这样容易造成结果不准确甚至数组下标越界\npublic Iterator&lt;E> iterator() &#123;\n    return new Itr();\n&#125;\n//当创建迭代器时 list.iterator();会直接返回一个Itr对象\n\n\n//ArrayList的内部类Itr实现了Iterator接口，该类有三个方法\nprivate class Itr implements Iterator&lt;E> &#123;\n    int cursor = 0 ;       // index of next element to return，下一个要访问的元素\n    int lastRet = -1; // index of last element returned; -1 if no such\n    int expectedModCount = modCount;//代表对ArrayList修改次数的期望值，初始为modCount\n\n    public boolean hasNext() &#123;\n        return cursor != size;\n    &#125;\n\n    @SuppressWarnings(\"unchecked\")\n    public E next() &#123;\n        //判断expectedModCount是否和modCount相等\n        checkForComodification();\n        int i = cursor;\n        //判断是否越界\n        if (i >= size)\n            throw new NoSuchElementException();\n        Object[] elementData = ArrayList.this.elementData;\n        if (i >= elementData.length)\n            throw new ConcurrentModificationException();\n        cursor = i + 1;\n        return (E) elementData[lastRet = i];//lastRet和cursor都自增1，并返回自增后的lastRet\n    &#125;\n\n    public void remove() &#123;\n        //\n        if (lastRet &lt; 0)\n            throw new IllegalStateException();\n        checkForComodification();\n\n        try &#123;\n            ArrayList.this.remove(lastRet);\n            //调用ArrayList的remove方法并将两个游标向前移动一位\n            cursor = lastRet;\n            lastRet = -1;\n            expectedModCount = modCount;\n        &#125; catch (IndexOutOfBoundsException ex) &#123;\n            throw new ConcurrentModificationException();\n        &#125;\n    &#125;\n\n    final void checkForComodification() &#123;\n        if (modCount != expectedModCount)\n            throw new ConcurrentModificationException();\n    &#125;\n&#125;\n//如果要对ArrayList进行遍历操作，就要使用迭代器，且在remove之前必须hasnext和next\n\n如何将ArrayList转换为普通数组？\nArrayList&lt;Integer> list = new ArrayList&lt;>();\nObject[] o = list.toArray();\n\nLinkedListlinkedlist与arraylist不同，后者基于一个被维护的数组来实现动态调整大小，而前者则是一个双向链表\n链表的优势：当插入和删除比较频繁的时候，链表相较于数组能有更高的效率(通常情况下，也有特殊情况，比如arraylist的中间插入效率就要高一些)，但是查找效率却不高。\n//内部类node的源码\n//一个对象对应一个节点\n    private static class Node&lt;E> &#123;\n       //元素的引用\n       //如果为null,表示没有存储任何元素，如果不为null,表示存储了某种类型的元素\n       E item;\n       //下一个节点的引用\n       //引用代表了对象的十六进制地址值,所以也可以注释为:下一个节点在内存中的地址\n       //如果为null,可能是空链表，也可能是尾节点\n       Node&lt;E> next;\n       Node&lt;E> prev;\n       Node(Node&lt;E> prev, E element, Node&lt;E> next) &#123;\n          //元素的引用初始化\n          this.item = element;\n          //上一个节点的引用初始化\n          this.next = next;\n          //下一个节点的引用初始化\n          this.prev = prev;\n       &#125;\n    &#125;\n\n//变量\ntransient int size = 0;\n//元素数量\ntransient Node&lt;E> last;\n//首节点的固定引用，必须先创建首节点，才能创建下一个节点\ntransient Node&lt;E> first;\n//尾节点的固定引用\n\n\n\n//头插\nprivate void linkFirst(E e) &#123;\n    //再创建一个指针f指向首节点\n\tfinal Node&lt;E> f = first;\n    //前指针为空，后指针指向f\n\tfinal Node&lt;E> newNode = new Node&lt;>(null, e, f);\n    //将first首指针指向newnode，代表newnode成为新的首元素\n\tfirst = newNode;\n    //若f指向的元素为空，证明加入newnode前链表为空，那么newnode既是首元素，也是尾元素\n\tif (f == null) last = newNode;\n    //若不为空，将前指针指向newnode，形成双向链表\n\telse f.prev = newNode;\n\tsize++; modCount++;\n&#125;\n//linkedlist的头插效率非常高，因为arraylist的头插需要进行大量的移位，元素复制的操作，还可能需要进行扩容，而链表只需调整指针的指向即可\n\n//尾插\nvoid linkLast(E e) &#123;\n    //与头插大同小异\n\tfinal Node&lt;E> l = last;\n    //最后一个节点的next为null\n\tfinal Node&lt;E> newNode = new Node&lt;>(l, e, null);\n\tlast = newNode;\n\tif (l == null) first = newNode;\n\telse l.next = newNode;\n\tsize++; modCount++;\n&#125;\n//出乎意料地是，linkedlist的尾插效率却比arraylist要低，因为arraylist无需进行移位拷贝操作，而linkedlist则需要创建对象，后者要耗时许多\n\n//中间插入\npublic void add(int index, E element) &#123;\n    //输入索引和元素，检查索引范围是否合法\n\tcheckPositionIndex(index);\n    //若索引为size则进行尾插\n\tif (index == size) linkLast(element);\n    //不是，则进行中间插入\n\telse inkBefore(element, node(index));\n&#125;\nNode&lt;E> node(int index) &#123;\n\t// assert isElementIndex(index);\n    //size>>1：size的一半，判断元素在左半区间，还是右半区间\n\tif (index &lt; (size >> 1)) &#123;\n        //在左半区间，操纵first指针找到index元素\n\t\tNode&lt;E> x = first;\n\t\tfor (int i = 0; i &lt; index; i++)\n\t\tx = x.next;\n\t\treturn x;&#125; \n    else &#123;\n        //在右半区间，操纵last指针找到index元素\n\t\tNode&lt;E> x = last;\n\t\tfor (int i = size - 1; i > index; i--)\n\t\tx = x.prev;\n\t\treturn x;&#125;\n&#125;\nvoid linkBefore(E e, Node&lt;E> succ) &#123;\n\t// assert succ != null;\n    //在index所指的元素之前插入新元素\n\tfinal Node&lt;E> pred = succ.prev;\n\tfinal Node&lt;E> newNode = new Node&lt;>(pred, e, succ);\n\tsucc.prev = newNode;\n\tif (pred == null) first = newNode;\n\telse pred.next = newNode;\n\tsize++; modCount++;\n&#125;\n//在数据量较大的时候，中间插入相比arrayList仍然会消耗较多的时间，所以CRUD效率不是绝对的可以分高下，需要根据应用场景和数据量等来综合考量\n\n//删除节点\npublic boolean remove(Object o) &#123;\nif (o == null) &#123;\nfor (Node&lt;E> x = first; x != null; x = x.next) &#123;\nif (x.item == null) &#123;\n\tunlink(x);\n\treturn true;\n\t\t&#125;\n\t&#125;\n&#125; else &#123;\n\tfor (Node&lt;E> x = first; x != null; x = x.next) &#123;\n    if (o.equals(x.item)) &#123;\n\tunlink(x);\n\treturn true;\n\t\t&#125;\n\t&#125;\n&#125;\nreturn false;\n&#125;\n//解链操作，即将这个元素从链表中移除\nE unlink(Node&lt;E> x) &#123;\n// assert x != null;\n\tfinal E element = x.item;\n\tfinal Node&lt;E> next = x.next;\n\tfinal Node&lt;E> prev = x.prev;\n    //若上个结点为空，则直接将首指针指向next\n\tif (prev == null) first = next; \n    //断掉x的prev指针\n    else &#123;prev.next = next;x.prev = null;&#125;\n    //若下一个结点为空，则直接将尾结点指向prev\n\tif (next == null) last = prev;\n    //断掉x的next指针\n    else &#123;next.prev = prev;x.next = null;&#125;\n\tx.item = null;\n\tsize--;\n\tmodCount++;\n\treturn element;\n\t&#125;\n","slug":"Java数据结构","date":"2022-08-12T05:41:02.000Z","categories_index":"","tags_index":"Java基础知识","author_index":"Samuel"}]