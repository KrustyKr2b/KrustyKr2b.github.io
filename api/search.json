[{"id":"6ba55d3e12601017e69aa7613dde8806","title":"周赛笔记11/13/2022","content":"6234.最小公倍数为 K 的子数组数目给你一个整数数组 nums 和一个整数 k ，请你统计并返回 nums 的 子数组 中满足 元素最小公倍数为 k 的子数组数目。\n子数组 是数组中一个连续非空的元素序列。数组的最小公倍数 是可被所有数组元素整除的最小正整数。\n示例 1 ：\n输入：nums &#x3D; [3,6,2,7,1], k &#x3D; 6\n输出：4\n解释：以 6 为最小公倍数的子数组是：\n- [3,6]\n- [3,6,2]\n- [6,2]\n- [6]\n\n//两个for循环扫描\nclass Solution &#123;\n    public int subarrayLCM(int[] nums, int k) &#123;\n        int ans =0;\n        int n=nums.length;\n        for(int i=0;i&lt;n;i++)&#123;\n            if(nums[i]==k) ans++;\n            int temp=nums[i];\n            for(int j=i+1;j&lt;n;j++)&#123;\n                //最小公倍数的传递性，a,b,c的最小公倍数为：a,b的最小公倍数k与c的最小公倍数\n                temp=minMul(temp,nums[j]);\n                if(temp==k) ans++;\n            &#125;\n        &#125;\n        return ans;\n    &#125;\n    //可以记住这个算法\n    //利用最大公约数求最小公倍数\n    int minMul(int a, int b)&#123;\n        int sum = a*b;\n        return sum/gcd(a,b);\n    &#125;\n    //辗转相除法求最大公约数\n    int gcd(int a,int b)&#123;\n        return (b==0)?a:gcd(b,a%b);\n    &#125;\n&#125;\n\n6235.逐层排序二叉树所需的最少操作数目给你一个 值互不相同 的二叉树的根节点 root 。\n在一步操作中，你可以选择 同一层 上任意两个节点，交换这两个节点的值。\n返回每一层按 严格递增顺序 排序所需的最少操作数目。\n节点的 层数 是该节点和根节点之间的路径的边数。\n\n输入：root &#x3D; [1,4,3,7,6,8,5,null,null,null,null,9,null,10]\n输出：3\n解释：\n- 交换 4 和 3 。第 2 层变为 [3,4] 。\n- 交换 7 和 5 。第 3 层变为 [5,6,8,7] 。\n- 交换 8 和 7 。第 3 层变为 [5,6,7,8] 。\n共计用了 3 步操作，所以返回 3 。\n可以证明 3 是需要的最少操作数目。\n\n//复习二叉树的层序遍历\nclass Solution &#123;\n    //层序遍历，生成每层的数组记录，对数组记录进行操作，记录操作次数\n    public int minimumOperations(TreeNode root) &#123;\n        if(root==null) return 0;\n        int res = 0;\n        Deque&lt;TreeNode> q = new ArrayDeque&lt;>();\n        q.add(root);\n        while(q.peek()!=null)&#123;\n            int n = q.size();\n            int[] record = new int[n];\n            for(int i=0;n>0;n--)&#123;\n                TreeNode node = q.poll();\n                record[i++] = node.val;\n                if(node.left != null) q.add(node.left);\n                if(node.right !=null)q.add(node.right);\n            &#125;\n            res+=count(record);\n        &#125;\n    return res;\n    &#125;\n    //记录将数组变为有序的最小交换次数\n    int count(int[] record)&#123;\n        //比较与排序过的数组的索引差异，不断交换，直到相同\n        HashMap&lt;Integer,Integer> map = new HashMap();\n        int[] sorted = record.clone();\n        Arrays.sort(sorted);\n        int count=0;\n        for(int i=0;i&lt;record.length;i++) map.put(sorted[i],i);\n        for(int i=0;i&lt;record.length;i++)&#123;\n            while(true)&#123;\n                int index = map.get(record[i]);\n                if(index!=i)&#123;\n                    count++;\n                    swap(record,index,i);\n                &#125;\n                else break;\n            &#125;\n        &#125;\n        return count;\n    &#125;\n    void swap(int[] nums, int i,int j)&#123;\n        int temp = nums[i];\n        nums[i]=nums[j];\n        nums[j]=temp;\n    &#125;\n&#125;\n\n","slug":"周赛笔记11-13-2022","date":"2022-11-13T08:22:18.000Z","categories_index":"","tags_index":"LeetCode初见","author_index":"Samuel"},{"id":"2e8864ab557e295b3f55e14c06a19e33","title":"Java基础知识汇总","content":"Object类中有哪些方法\nequals()：未被重写前，由&#x3D;&#x3D;来实现，比较引用数据类型的引用地址是否相同\nHashCode()：本地方法，未被重写前返回对象在堆上的唯一地址值，可以看作是对象的身份ID\nclone()：实现了cloneable接口才可以调用该方法，实现对象的浅复制\ngetClass()：final修饰，获取运行时的类型\ntoString()：若参数为变量，则返回对应变量的string对象，若参数为一个对象，则返回堆内存对象的地址\nfinalize()：在GC准备释放对象所占用的内存空间之前，它将首先调用finalize()方法，finalize()方法中一般用于释放非Java 资源（如打开的文件资源、数据库连接等）,或是调用native方法时分配的内存(比如C语言的malloc()）。\nwait()：使线程阻塞等待\nnotify()：唤醒等待的线程\nnofityAll()：唤醒在该对象上等待的所有线程\n\nJAVA的八大数据类型可以分为四个大类：整型，字符型，浮点型，布尔型\n\nboolean：JVM中并没有提供boolean专用的字节码指令，在编译后会以int型来表示，4字节。boolean[]会以byte数组来表示，1字节\nchar：可以赋值单字符以及整型数值，表示数字的取值范围为0~65536，2字节\nbyte：范围为-128 - 128，1字节\nshort：范围为：-32768-32768，2字节\nint：范围为：-2,147,483,648-2,147,483,647，4字节\nlong：范围为；-2^63-2^63-1，8字节\nfloat：单精度浮点数，4字节\ndouble：双精度浮点数，8字节\n\n接口和抽象类有哪些区别相同点：\n\n不能被实例化\n可以将抽象类和接口类型作为引用类型\n一个类如果继承了某个抽象类或者实现了某个接口都需要对其中的抽象方法全部实现\n\n不同点：\n\n抽象类中可以定义构造器，可以有抽象方法和具体方法，抽象类中可以定义成员变量，一个类只能继承一个抽象类，抽象类中可以包含静态方法，抽象类中的成员可以由private,protected,public修饰\n接口中的成员全部都是由public修饰，不能定义构造器，只能有抽象方法，不能有静态方法，一个类可以实现多个接口\n\n除了语法上的异同之外，两者还有语义上的不同。抽象类适合描述某一更具体的概念，比如狗是一种动物，而不能说狗实现了动物的接口。接口则用于描述多个事物的共同特征，比如鸟实现了flyable接口，这个flyable就是一种行为特征，当然也可以描述其他的特征。\nString,StringBuilder,StringBuffer的区别\nString的底层是一个由final修饰的char型数组，String是静态只读的，当改变变量的值时，其实只是改变了引用对象的指向，指向了新创建的字符串，而原字符串仍存在于字符串常量池。\nStringBuffer（JDK1.0引入）：引用对象指向一个空间，包含一个可自行扩容的char型数组和字符串长度计数变量Count，StringBuffer的所有方法均被synchronized修饰。扩容时会开辟一块新的空间用于创建更大的数组，并将原数据复制过去，并改变引用对象的指向。\nStringBuilder(JDK1.5引入)：取消了synchronized方法修饰，所以效率更高，但是线程不安全。\n\nObject o = new Object()在内存中占用多少个字节？一个对象在内存中的存储布局：markword：8字节，锁信息+HashCode+GC信息；classPointer:4字节；对齐：保证大小能被8整除；数据段：即对象内声明的变量\n所以一个空对象最小为16字节\n对象如何定位？HotSpot虚拟机默认使用直接定位：指针直接指向堆内存内的对象，对象内的classPointer指向方法区内的class。优点：直接访问快；缺点：GC时，若需要移动对象，则指针也需要改变\n句柄方式（间接方式）：指针指向另一个结构体，该结构体内有两个指针，分别指向堆内存和方法区。优点：对象小，GC时无需改动指针。缺点：比直接访问更慢\n对象的创建过程new指令：申请内存空间，为成员变量设立默认值\ninvokespecial汇编码：调用构造方法，为成员变量设定初始值\nastore汇编码：建立引用，让指针指向堆\n面向对象有哪些特征面向对象是一种编程思想，即万物皆可归类抽象，万物皆可对象；有三大特征\n\n封装：类与外界的封装关系，即隐藏类内部的实现机制，对外部而言，它的内部细节是隐藏的，只暴露了自身的访问方法。使用者按照既定的方式来调用方法，不必关心方法的内部实现，便于使用，增强了代码的可维护性。\n继承：类与类的关系，即从已有的类中派生出新的类，即子类与父类，也可以称作超类和基类。从多个类中抽象出一个基类，使其具备多个类的共同特性，使用extends关键字继承某个类后，就具备了父类的属性，并扩展新的属性。在父类中使用private关键字来限制不会被继承。\n多态：多个类的关系，必备的三个要素：继承，重写，父类引用指向子类对象\n\nArrayList与LinkedList的区别\nArrayList是基于索引的数据接口，底层是数组，可以在常数级的复杂度对元素进行随机访问。而LinkedList是基于Node对象列表的形式存储数据，底层是一个双向链表，查找元素是O（n）。因此LinkedList的插入，添加，删除操作，总体上会更快，因为不是数组，不需要移动元素，重新计算索引和大小，但是LinkedList更占内存，因为每一个node都会封装前驱指针和后继指针。\n如果你需要经常随机访问数据，更加推荐使用ArrayList；如果需要经常插入删除元素，推荐使用LinkedList。\n多提一嘴：其实总体上ArrayList性能其实更加优越一些。第一，LinkedList的每一个node都有指针，更占内存，第二：虽然LinkedList的头插效率很高，但是尾插效率却不见得十分高效，因为数组的尾插无需进行拷贝和移位，而链表则需要创建node对象。并且有人测试过，在数据量较大时，链表的中间插入仍会比ArrayList耗时更多。所以俺还是无脑选择ArrayList~\n\n","slug":"JAVA基础知识汇总","date":"2022-11-13T07:48:43.000Z","categories_index":"","tags_index":"Java基础知识","author_index":"Samuel"},{"id":"2a1374b017f253762c103f23513f4420","title":"NIO select poll和epoll","content":"套接字编程Socket，表示进程间网络通信的特殊文件类型。本质是内核借助缓冲区形成的伪文件。Linux将套接字封装成文件的目的是为了统一接口，使得读写套接字和读写文件的操作一致。\n在TCP&#x2F;IP协议中，“IP地址+TCP或UDP端口号”唯一标识网络通讯中的一个进程。\n“IP地址+端口号”就对应一个socket。欲建立连接的两个进程各自有一个socket来标识，那么这两个socket组成的socket pair就唯一标识一个连接。因此可以用Socket来描述网络连接的一对一关系。\n\n一个文件描述符指向一个套接字\n一个套接字内部由内核借助两个缓冲区实现，一个写缓冲、读缓冲。\n在通信过程中， 套接字一定是成对出现的。一端的发送缓冲区对应对端的接收缓冲区\n\n\nsocket()创建一个socket\nbind()为socket绑定ip+port\nlisten()设置监听上限，即同时跟服务器建立socket连接的数量\naccept()：阻塞监听客户端连接，创建一个新的socket用来与客户端通信\nconnect()：客户端使用现有的socket与服务器建立连接，如果不使用bind绑定客户端地址结构，采用“隐式绑定”，系统自动分配ip+port\n\n网络IO同步：同步就是一个任务的完成需要依赖另外一个任务时，只有等待被依赖的任务完成后，依赖的任务才能算完成，这是一种可靠的任务序列。也就是说，调用会等待返回结果计算完成才能继续执行。BIO,NIO,select,poll,epoll都是同步的，只不过会有阻塞，非阻塞的区别。\n异步：异步是不需要等待被依赖的任务完成，只是通知被依赖的任务要完成什么工作，依赖的任务也立即执行，只要自己完成了整个任务就算完成了。也就是说，其实异步调用会直接返回，但是这个结果不是计算的结果，当结果计算出来之后，才通知被调用的程序。\n阻塞：阻塞调用是指调用结果返回之前，当前线程会被挂起，一直处于等待消息通知，不能够执行其他业务。\n非阻塞：不管可不可以读写，它都会立即返回，返回成功说明读写操作完成了，返回失败会设置相应errno状态码，根据这个errno可以进一步执行其他处理。它不会像阻塞IO那样，卡在那里不动。\nBIO即阻塞IO，一个socket对应一个线程，若无数据发送则会一直阻塞等待，造成资源浪费\n特别是在JAVA环境下，线程的创建，切换，代价高昂\n结构简单，适合规模小，低并发的情况\n\n特点：面向流的，阻塞的java1.4以前的io模型，一连接对一个线程，原始的IO是面向流的，不存在缓存的概念。\nJava IO面向流意味着每次从流中读一个或多个字节，直至读取所有字节，它们没有被缓存在任何地方。\n此外，它不能前后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区\nJava IO的各种流是阻塞的，这意味着当一个线程调用read或 write方法时，该线程被阻塞，直到有一些数据被读取，或数据完全写入，该线程在此期间不能再干任何事情了。\nNIO非阻塞IO，指使用一个线程不断轮询来管理所有套接字，即一个while死循环来不断遍历，一旦发现有数据便进行处理。\n做到了单线程也能管理所有套接字。这是非阻塞的，就算没有数据也不会停下来，而是返回无数据的标识，然后再进行下一次的轮询。\nNIO是面向缓冲区的，每个连接都有一个缓冲区来暂存数据，由管道来进行双向传输\n\nselector实现循环监听通道信号的组件\n一个selector 对应一个线程， 多个channel以事件的方式注册于selector，代表一个进程便可以处理多个连接\nselector 会在各个通道上切换，只有在连接&#x2F;通道真正有读写事件发生时，才会进行读写，就大大地减少了系统开销，并且不必为每个连接都创建一个线程，不用去维护多个线程，避免了多线程之间的上下文切换导致的开销\nchannelNIO的通道类似于流，但有些区别如下：\n\n通道可以同时进行读写，而流只能读或者只能写\n通道可以实现异步读写数据\n通道可以从缓冲读数据，也可以写数据到缓冲\n\nchannel 是双向的, 可以返回底层操作系统的情况, 比如Linux ，底层的操作系统通道就是双向的\nbufferBuffer 就是一个内存块 ，底层是有一个数组\nchannel 提供从文件、网络读取数据的渠道，但是读取或写入的数据都必须经由 Buffer\n数据的读取写入是通过Buffer, 这个和BIO不同 , BIO 中要么是输入流，或者是输出流，不能双向\n但是NIO的Buffer 是可以读也可以写, 需要 flip 方法切换\n特点：面向块，非阻塞NIO是面向缓冲区的。数据被读取到缓冲区，需要时可在缓冲区中前后移动，这就增加了处理过程中的灵活性。\nJava NIO的非阻塞模式，使一个线程从某通道发送请求读取数据，如果目前没有数据可用时，就什么都不会获取，而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事情。 非阻塞写也是如此，一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同时可以去做别的事情。\nNIO是可以做到用一个线程来处理多个操作的。selector会不断循环监听channel，如果通道中没有数据即没有请求时它可以去处理别的通道或者做其他的事情，如果通道中有数据它就会选择这个通道然后进行处理，实现了一个线程处理多个连接。\nselectNIO是一种十分创新的思想，但是也有许多问题，比如忙循环。\n若一直在用户空间进行轮询，则会资源浪费，复杂度至少为O(n)\n而select就是将所有的fd收集并交给内核，进行一次系统调用，复杂度降为O(1)\n\n内核会返回一个整数，若小于零，代表没有任何数据或请求到达，若大于零，代表可以进行处理。若等于零，代表等待超时。\n每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大\n同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大\nfd_set的大小是有限制的，即单个进程能维护的套接字的大小有限，32位为1024，64位机默认是2048。可以修改。\npollpoll的实现和select很相似，不同的是用于管理文件描述符的集合由数组变为了链表，所以没有最大连接数的限制。存在和select同样的问题\nepoll 与前面所有的轮询机制不同，epoll使用的是事件驱动，即当发生事件时，每个fd上有注册有回调函数，当网卡接收到数据时会回调该函数，同时将该fd的引用放入rdlist就绪列表中。\n当调用epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可。\n如果rdlist不为空，则把发生的事件复制到用户态，同时将事件数量返回给用户。\n避免了遍历所有的fd，只检查发生事件的fd\n&#x2F;&#x2F; 数据结构\n&#x2F;&#x2F; 每一个epoll对象都有一个独立的eventpoll结构体\n&#x2F;&#x2F; 用于存放通过epoll_ctl方法向epoll对象中添加进来的事件\nstruct eventpoll &#123;\n    &#x2F;*红黑树的根节点，这颗树中存储着所有添加到epoll中的需要监控的事件*&#x2F;\n    struct rb_root  rbr;\n    &#x2F;*双链表中则存放着将要通过epoll_wait返回给用户的满足条件的事件*&#x2F;\n    struct list_head rdlist;\n&#125;;\n\n执行流程\n\n调用epoll_create()创建一个ep对象，在内核空间中开辟了一块空间存储eventpoll，返回一个文件句柄，即红黑树的根节点\n调用epoll_ctl()向红黑树中添加、删除、修改fd\n调用epoll_wait()等待，当有事件发生时网卡驱动会调用fd上注册的函数并将该fd添加到rdlist中，解除阻塞。由于fd的引用在红黑树上，所以查找速度很快。\n\n\n总结：\n\nEPOLL支持的最大文件描述符上限是整个系统最大可打开的文件数目, 1G内存理论上最大创建10万个文件描述符\n每个文件描述符上都有一个callback函数，当socket有事件发生时会回调这个函数将该fd的引用添加到就绪列表中，select和poll并不会明确指出是哪些文件描述符就绪，而epoll会。造成的区别就是，系统调用返回后，调用select和poll的程序需要遍历监听的整个文件描述符找到是谁处于就绪，而epoll则直接处理即可\nselect、poll采用轮询的方式来检查文件描述符是否处于就绪态，而epoll采用回调机制。造成的结果就是，随着fd的增加，select和poll的效率会线性降低，而epoll不会受到太大影响，除非活跃的socket很多\n\n","slug":"NIO-select-poll和epoll","date":"2022-11-02T05:45:40.000Z","categories_index":"","tags_index":"网络编程基础知识","author_index":"Samuel"},{"id":"52c15247d71045907737fa627f8aa035","title":"洪水淹没算法","content":"695. 岛屿的最大面积\n输入：grid &#x3D; [[0,0,1,0,0,0,0,1,0,0,0,0,0],[0,0,0,0,0,0,0,1,1,1,0,0,0],[0,1,1,0,1,0,0,0,0,0,0,0,0],[0,1,0,0,1,1,0,0,1,0,1,0,0],[0,1,0,0,1,1,0,0,1,1,1,0,0],[0,0,0,0,0,0,0,0,0,0,1,0,0],[0,0,0,0,0,0,0,1,1,1,0,0,0],[0,0,0,0,0,0,0,1,1,0,0,0,0]]\n输出：6\n解释：答案不应该是 11 ，因为岛屿只能包含水平或垂直这四个方向上的 1 。\n\nclass Solution &#123;\n    public int maxAreaOfIsland(int[][] grid) &#123;\n        int res =0;\n        int m=grid.length;\n        int n=grid[0].length;\n        for(int i=0;i&lt;m;i++)&#123;\n            for(int j=0;j&lt;n;j++)&#123;\n                if(grid[i][j]==1)&#123;\n                    res=Math.max(res,FloodFill(grid,i,j));\n                &#125;\n            &#125;\n        &#125;\n        return res;\n    &#125;\n    //淹没与i,j相邻的陆地并记录下面积\n    int FloodFill(int[][] grid,int i, int j)&#123;\n        if(!isValid(i,j,grid)) return 0;\n        if(grid[i][j]==0) return 0;\n        grid[i][j]=0;\n        return FloodFill(grid,i+1,j)\n        +FloodFill(grid,i,j+1)\n        +FloodFill(grid,i-1,j)\n        +FloodFill(grid,i,j-1) +1;\n\n    &#125;\n    boolean isValid(int i,int j,int[][] grid)&#123;\n        if(i>=0 &amp;&amp; j>=0 &amp;&amp; i&lt;grid.length &amp;&amp; j&lt;grid[0].length)&#123;\n            return true;\n        &#125;\n        return false;\n    &#125;\n&#125;\n\n200. 岛屿数量给你一个由 ‘1’（陆地）和 ‘0’（水）组成的的二维网格，请你计算网格中岛屿的数量。\n岛屿总是被水包围，并且每座岛屿只能由水平方向和或竖直方向上相邻的陆地连接形成。\n此外，你可以假设该网格的四条边均被水包围。\n输入：grid &#x3D; [\n  [&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;1&quot;,&quot;0&quot;],\n  [&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;1&quot;,&quot;0&quot;],\n  [&quot;1&quot;,&quot;1&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;],\n  [&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;,&quot;0&quot;]\n]\n输出：1\n\nclass Solution &#123;\n    //二维数组的递归遍历和floodfill算法\n    public int numIslands(char[][] grid) &#123;\n        int res =0;\n        int m = grid.length;\n        int n = grid[0].length;\n        for(int i=0;i&lt;m;i++)&#123;\n            for(int j=0;j&lt;n;j++)&#123;\n                if(grid[i][j] == '1')&#123;\n                    res++;\n                    FloodFill(grid,i,j);\n                &#125;\n            &#125;\n        &#125;\n        return res;\n    &#125;\n    //洪水填充算法，将1周围的所有1都改变为0，最终使得图中的1的数目便是岛屿的数目\n    void FloodFill(char[][] grid, int i, int j)&#123;\n        if(!isValid(i,j,grid)) return;\n        if(grid[i][j] == '0') return;\n        grid[i][j] = '0';\n        FloodFill(grid,i+1,j);\n        FloodFill(grid,i,j+1);\n        FloodFill(grid,i-1,j);\n        FloodFill(grid,i,j-1);\n    &#125;\n    boolean isValid(int i,int j,char[][] grid)&#123;\n        if(i>=0 &amp;&amp; j>=0 &amp;&amp; i&lt;grid.length &amp;&amp; j&lt;grid[0].length)&#123;\n            return true;\n        &#125;\n        return false;\n    &#125;\n&#125;\n\n","slug":"洪水淹没算法","date":"2022-10-31T06:51:29.000Z","categories_index":"","tags_index":"LeetCode初见","author_index":"Samuel"},{"id":"293c17b4d2a4292133cc4d1ffd7f8725","title":"计算机网络","content":"计算机网络的分层模型OSI七层模型\n应用层：计算机上的网络应用，传输应用报文，如HTTP，SMTP\n表示层：用于处理交换信息的表示格式（处理语法和处理语义），格式变换，数据加密解密，数据压缩等功能\n会话层：向表示层建立连接，并传输有序的数据，也就是建立同步SYN\n运输层：负责两个进程的通信，即端到端，如TCP UDP\n网络层：讲分组从源端传到目的端，注重传输过程中的路径选择，如IP\n链路层：讲网络层的数据包封装成帧，如CSMA\n物理层：以比特流的方式传输\n\n上面4层是端到端的，也就是关注的是数据从源主机交付到目的主机，而不管每步是怎么传输的\n下面3层是点到点的，关注数据在传输过程中下一步是怎么走的，也就是路由是如何转发的\nTCP&#x2F;IP四层模型\n应用层（应用层+表示层+会话层）\n运输层\n网络层\n网络接口层（物理层+链路层）\n\n五层参考模型\n应用层\n运输层 \n网络层\n链路层\n物理层\n\n运输层协议UDP特点\n\n无连接状态：UDP无需任何准备就可以传输数据，也没有引入建立连接的时延。并且UDP也不维护连接状态\n精确控制发送数据的时机：应用程序将数据传给UDP，UDP可以立即将数据封装为UDP报文并传递给网络层，而TCP引入了拥塞机制来控制发送方的频率。\n\n报文结构：\nUDP首部仅四个部分\n\n源端口号：2字节\n目的端口号：2字节\n长度：2字节\n校验和：2字节\n\nUDP的校验和：应用数据的所有16比特字之和的反码\nTCP特点\n\n保证发送有效，有序的字节流，是面向流的协议，基于TCP:HTTP\n首部20字节\n\nTCP首部的标志字段\n\nURG&#x3D;1 表明紧急指针字段有效，表示有紧急数据，应该尽快传输\nACK&#x3D;1 表明确认字段有效\nPSH&#x3D;1 表示接收方此时应该尽快交付缓冲区的数据\nRST&#x3D;1 表示TCP连接出现严重错误，必须释放连接，再重新建立连接\nSYN&#x3D;1 表示这是一个连接请求或者连接接受报文\nFIN&#x3D;1 表示此段数据的发送端已经发送完毕最后一个数据段，并要求释放连接\n\nTCP的连接管理三次握手：\n\n开始处于CLOSED，客户机向服务器发送TCP SYN报文段，使用seq指定初始序号，这个请求报文是没有数据的，客户机进入SYN_SENT\n服务器收到客户机的SYN报文段，使用带ACK的SYN报文段来回复，为该连接分配缓冲区和相关变量，使用seq指定相关序号\n客户机接到服务器的SYN报文段，客户机为连接分配缓冲，使用ACK报文段回复（SYN&#x3D;0），可能会有数据，客户机进入ESTABLISHED\n\nSYN ：Synchronize Sequence Numbers 即握手信号\n为什么需要三次：第二步服务器向客户机提供了自己的初始序号，因此再需要一次握手来确认此序号\n四次挥手：\n\n客户机发送TCP FIN报文段到服务器，进入FIN_WAIT_1\n服务器收到FIN，回复ACK，进入FIN_WAIT_2\n服务器发送FIN报文给客户机，此时连接半关闭，\n客户机接收FIN，回复ACK报文，进入TIME_WAIT，时间结束后，释放资源，服务器收到后连接关闭\n\nTCP的有限状态机\n\n\nCLOSED 没有任何连接状态\nLISTEN 侦听状态，等待来自远方TCP端口的连接请求 \nSYN-SENT 在发送连接请求后，等待对方确认 \nSYN-RECEIVED 在收到和发送一个连接请求后，等待对方确认 \nESTABLISHED 代表传输连接建立，双方进入数据传送状态 \nFIN-WAIT-1 主动关闭,主机已发送关闭连接请求，等待对方确认 \nFIN-WAIT-2 主动关闭,主机已收到对方关闭传输连接确认，等待对方发送关闭传输连接请求 \nTIME-WAIT 完成双向传输连接关闭，等待所有分组消失 \nCLOSE-WAIT 被动关闭,收到对方发来的关闭连接请求，并已确认 \nLAST-ACK 被动关闭,等待最后一个关闭传输连接确认，并等待所有分组消失\nCLOSING 如果通信双方同时发送FIN数据包，则同时进行关闭操作，则双方将同时进入TCP_CLOSING状态。 \t具体的，本地发送一个FIN数据包以结束本地数据包发送，如果在等待应答期间，接收到远端发送的FIN数据包，则本地将状态设置为TCP_CLOSING状态。 \t在接收到应答后，再继续装入到TCP_CLOSE_WAIT状态。\n\nTCP的拥塞控制\n当cwnd &lt; ssthresh时，慢启动，指数增长\n当cwnd &gt; ssthresh时，拥塞避免，线性增长\n出现三个冗余确认，快速恢复，ssthresh &#x3D; cwnd&#x2F;2 ; cwnd &#x3D; ssthresh+3*MSS；此后每收到一个冗余ACK就增加一个MSS，直到收到正确的ACK，cwnd&#x3D;ssthresh,进入慢增长\n出现timeout，ssthresh &#x3D; cwnd&#x2F;2 ; cwnd &#x3D; 1MSS\n\nTCP可靠传输机制的保证：\n检验和：用于检验一个分组中的比特错误\n\n定时器：用于超时检验，发生超时事件时重传\n\n序号：为一系列分组编号，可以检测出丢失分组以及冗余分组\n\nACK：用于告诉发送方分组被正确接收\n\nNAK：用于告诉发送方分组未被正确接收\n\n窗口：发送方被限制发送的序号范围\n\n\nGBN 回退N步 go-back-N将序号队列分为四部分\n\n已被确认\n窗口内：已发送，未被确认\n窗口内：可用，未发送\n不可用\n\n若窗口内某一序号n的ACK timeout，则需要重传n之后的所有分组\n当接收到正确序号的ACK时，窗口便前移一个序号\n0123 +rcv ack0 &#x3D;&gt; 1234\n1234 +rcv ack1 &#x3D;&gt; 2345\nack2 timeout &#x3D;&gt;re_send (2345)\n接受方无buffer，失序分组会被丢弃，所以需要重发来重新确认顺序\n选择性重传SR selective repeat接收方添加buffer，按序提交给上层\n发送方只重发没有确认的分组\n为每一个分组都添加timer，缓冲区的存在可以暂存失序但正确的分组\n待重传分组到达并恢复顺序后，再统一交付给上层\nTCP和UDP的区别\n通信即时性：UDP协议的双方随时都可以进行通信，而TCP协议的双方必须经过三次握手后才能通信，并且要经过四次挥手才能断开连接\n对象不同：UDP是面向报文的，接收来自应用层的数据直接加上首部就发送。而TCP是将应用层的数据看作字节流，为其设立缓存，将数据进行打包并发送\n通信数量不同：UDP支持单播，多播，广播；TCP只支持单播\n数据的安全性不同：网络层以上提供的都是不可靠的传输协议，UDP也是。而TCP保证了可靠传输，解决了丢失，乱序等问题\n报文大小不同：UDP首部结构简单，8字节；而TCP报文首部有20字节，最大可达60字节。\n\n如何使UDP可靠运输层不能改变，网络层及下层都无法保证可靠，所以需要从应用层来保证可靠\n核心出发点：在应用层模仿TCP的可靠性传输\n如：\n\n添加添加seq&#x2F;ack机制，确保数据发送到对端\n添加发送和接收缓冲区，主要是用户超时重传\n添加超时重传机制\n\n送端发送数据时，生成一个随机seq&#x3D;x，然后每一片按照数据大小分配seq。数据到达接收端后接收端放入缓存，并发送一个ack&#x3D;x的包，表示对方已经收到了数据。发送端收到了ack包后，删除缓冲区对应的数据。时间到后，定时任务检查是否需要重传数据。\n只不过都是由应用层的软件来实现的，比如使用UDP数据包+序列号，UDP数据包+时间戳等方法，在服务器端进行应答确认机制。\n比如RUDP或者RTP都是基于UDP实现的可靠传输协议。\nQUIC协议HTTP3弃用TCP后，使用了基于UDP的QUIC协议，使用UDP实现了TCP+TLS的特性，且仅需一次握手即可建立可靠连接（0-RTT 握手）\n如何实现可靠传输\n\n包号PKN+确认应答SACK来保证确认接收和数据有序性\n滑动窗口：应用层实现\n拥塞控制：应用层实现\n\n如何避免对头阻塞\n\n弃用TCP\n使用二进制帧格式的数据结构，面向流的传输，给每个请求流都分配一个独立的滑动窗口\n\n\n为什么QQ使用的是UDP协议登陆和保持连接状态采用TCP，和好友之间发送消息采用UDP，内网传文件采用了P2P\n\n当时没有epoll这种可以支持成千上万tcp并发连接的技术，所以使用了应用层封装后的UDP来解决大并发的问题。后面也懒得修改\n国内网络环境水平参差复杂，特别是在千禧年，带宽窄且抖动厉害，此时TCP的等待握手反而会成为劣势，占用宝贵的时间资源和性能资源\nUDP的特性，即时封装即时发送，所以在在应用层的控制下，可以更快地探测和重传。\n\nQQ如何实现可靠：使用上层协议来实现可靠，如果客户端使用UDP协议发出消息后，服务器收到该包，需要使用UDP协议发回一个应答包。如此来保证消息可以无遗漏传输\nHTTP协议超文本传输协议，基于TCP实现\n特点\n可靠\n简单快速：客户向服务器请求服务时，只需传输方法和路径\n灵活：支持任意类型的数据\n无状态，无持久化\n\n请求指令\nGET：从服务器获取一个资源\nPUT：将来自客户端的资源存储到服务器中\nPOST：将客户端数据发送到服务器应用程序中去\nDELETE：从服务器中删除资源\nHEAD：仅发送HTTP首部\n\nGET和POST的区别：\n\nget通过URL传输数据，比如以字段&#x3D;value的形式，以？和&amp;连接。传输少量数据，URL是可见的，可能会泄漏信息。\nPOST可以传输大量数据，且支持标准字符集，可以正确传输中文字符\n前者着重于获取资源，后者着重于发送数据\n\n状态码响应报文都会携带一个状态码来告知请求报文的状态\n\n200：正确返回\n302：重定向\n404：没找到\n\n报文请求报文\n起始行：请求指令，URL，HTTP版本号\n首部：描述浏览器可以接受的字符集，编码方式，期望的语言\n主体：可能会有，也可能没有\n\n响应报文\n起始行：版本号，状态码\n首部：返回的数据类型，长度等信息\n主体：二进制流\n\nCookie身份标识：向服务器表明自己的身份\nCookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。\nCookie存储的数据量有限，且都是保存在客户端浏览器中，大小一般不超过4kb\n\n在服务器发送响应后，会顺带将Set-Cookie也发送给客户端。\n当客户端保存后，之后给服务器发送请求时，都会在请求中包含Cookie的头部\n应用：判断用户是否已经登录网站，购物车\nSession当用户登录时，发送用户名和密码后，服务端查询数据库是否存在该用户，如果有的话，会自动生成一个sessionid，用于记录登录的时间、状态、属于哪个用户，过期时间等信息，并将这些信息保存在服务端\n同时，将这些信息通过cookie的形式将这些数据返回给客户端\n当用户再次登录该服务器，访问其他接口的时候，会自动带上sessionid，服务器接收到请求后会自动查询有没有存储这个sessionid的信息\n\nCookie和Session的区别：\n\nSession因为存储在服务器上，所以安全性比Cookie更高。\nCookie中只能存储ASCII字符串，如果是略微复杂的信息如java 对象，unicode字符串，比较艰难，需要进行编码，而session可以存取任意类型的数据，包括java对象\n隐私策略不同：cookie对客户端可见，客户端的程序是可以窥探到cookie的。而session对客户端是不可见的。\ncookie的过期时间可以设置得很长，而session因为存储在服务器上，出于性能的考虑，不能将存活时间设置得太长\n当并发量高的时候，session的资源消耗会很高，而cookie就不会给服务器造成太大压力\n\n存在的问题\n\n存储在服务器，消耗大量的存储资源\n查询速度会成为瓶颈，导致响应速度慢\n在跨端、跨服务器时，需要session同步\n通过架设数据库集群redis，会导致维护成本高，配置复杂\n\nToken服务器不存储用户数据，而是直接通过加密的方式把用户数据通过令牌的方式返回给客户端，该令牌将会由服务器自己设置。\n每次用户访问时，都会携带这个令牌，用来证明自己的身份，从而得到自己的状态和数据。\n服务器不需要存储用户资源导致资源占用过多的问题，也不需要每次查询从而加快了响应速度，而且传递的方式也由双方协定，不管是否跨域，都可以正常传递。\n\n但是，这种token容易被伪造，因为只要任何人拿到了这种令牌都可以称自己是合法的用户\n从而获取一些私密的信息，此时如果服务器能拥有某种方式使得能证明该用户是合法的就显得极为重要\nsign:由服务端进行设置，且只有服务器知道签名和密钥。\n当用户登录时，服务器提取将用户信息（payload）和header组成新的数据，然后再加上sign进行加密得到一个token。\n当用户发起请求后，由服务器对sign进行解密，然后再结合自己设置的sign进行对比，如果一致，就证明该token合法，如果不一致，该token就是非法的\nJWT是token的一个实现形式，全称为JSON Web Token，本质是一个字符串，他将用户的信息保存到一个json字符串中，然后进行编码后得到一个JWT token，并且这个JWT token带有签名信息，接收后可以校验是否被篡改\nJWT的优势：\n\n数据量小，传输速度快\n以JSON加密保存，跨语言\n不依赖于cookie和session，适合于分布式微服务\n\nJWT的结构header头部是一个描述JWT元数据的JSON对象\n&#123;\n  &quot;alg&quot;: &quot;HS256&quot;,&#x2F;&#x2F;签名使用的算法\n  &quot;typ&quot;: &quot;JWT&quot;&#x2F;&#x2F;令牌名称\n&#125;\n\nPayload有效载荷，提供七个可选字段：\niss：发行人 exp：到期时间 sub：主题 aud：用户 nbf：在此之前不可用 iat：发布时间 jti：JWT ID用于标识该JWT\n&#123;\n  &quot;sub&quot;: &quot;1234567890&quot;,\n  &quot;name&quot;: &quot;Helen&quot;,\n  &quot;admin&quot;: true\n&#125;\n\nSignature签名哈希部分是对上面两部分数据签名，需要使用base64编码后的header和payload数据，通过指定的算法生成哈希，以确保数据不会被篡改。\n首先，需要指定一个密钥（secret）。该密钥仅仅为保存在服务器中，并且不能向用户公开。\n然后，使用header中指定的签名算法（默认情况下为HMAC SHA256）根据以下公式生成签名\nHMACSHA256(base64UrlEncode(header)+\".\"+base64UrlEncode(payload),secret);\n\n在计算出签名哈希后，JWT头，有效载荷和签名哈希的三个部分组合成一个字符串，每个部分用.分隔，就构成整个JWT对象\n\n注意JWT每部分的作用，在服务端接收到客户端发送过来的JWT token之后：\nheader和payload可以直接利用base64解码出原文，从header中获取哈希签名的算法，从payload中获取有效数据signature由于使用了不可逆的加密算法，无法解码出原文，它的作用是校验token有没有被篡改。\n服务端获取header中的加密算法之后，利用该算法加上secretKey对header、payload进行加密，比对加密后的数据和客户端发送过来的签名是否一致，注意secretKey只能保存在服务端。\n对于不同的加密算法secretKey含义有所不同，一般对于MD5类型的摘要加密算法，secretKey实际上代表的是盐值\nHTTP1.0和HTTP1.1的区别长连接​       HTTP1.1支持长连接和请求的流水线处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1中默认开启长连接keep-alive，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。\n节约带宽​       HTTP1.0中存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能。HTTP1.1支持只发送header信息（不带任何body信息），如果服务器认为客户端有权限请求服务器，则返回100，客户端接收到100才开始把请求body发送到服务器；如果返回401，客户端就可以不用发送请求body了节约了带宽。\nHOST域​       在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名，HTTP1.0没有host域。随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机，并且它们共享一个IP地址。HTTP1.1的请求消息和响应消息都支持host域，且请求消息中如果没有host域会报告一个错误（400 Bad Request）。\n缓存处理​       在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1.1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。\n错误通知的管理​       在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。\nHTTP1.1和HTTP2.0的区别多路复用​\tHTTP2引入了帧和流的概念，将数据分成一个个的二进制形式的帧。帧上面除了 HTTP 数据，还包含数据长度、流标识符、帧类型等信息。而流就是一个建立连接后的双向的虚拟字节流，流具有并行性，即二进制帧都是并行传输的，无需按序等待。HTTP&#x2F;2 会将所有 HTTP 请求打散成帧，在一个 TCP 连接上做并发请求，充分利用 TCP 带宽。避免了队头阻塞。\n头部数据压缩​       在HTTP1.1中，HTTP请求和响应都是由状态行、请求&#x2F;响应头部、消息主体三部分组成。一般而言，消息主体都会经过gzip压缩，或者本身传输的就是压缩过后的二进制文件，但状态行和头部却没有经过任何压缩，直接以纯文本传输。随着Web功能越来越复杂，每个页面产生的请求数也越来越多，导致消耗在头部的流量越来越大，HTTP2.0对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快。\n服务器推送​       服务端推送是一种在客户端请求之前发送数据的机制。网页使用了许多资源：HTML、样式表、脚本、图片等等。在HTTP1.1中这些资源每一个都必须明确地请求。这是一个很慢的过程。为了改善延迟，HTTP2.0引入了server push，它允许服务端推送资源给浏览器，免得客户端再次创建连接发送请求到服务器端获取。这样客户端可以直接从本地加载这些资源，不用再通过网络。\nHTTPSHTTP+SSL，是可加密的，身份认证的网络协议，更加安全\nSSL&#x2F;TLSHTTP的缺点：报文都是明文的，始终可见，安全性低\n对称加密：双方使用同一种方式来加密和解密，如果加密的规则被破解，那么就不存在密文了\n非对称加密：公钥加密后，必须由私钥解密；反之必须由公钥解密。\nSSL证书：由CA颁发，拥有SSL证书的服务器就可以向客户端提供公钥，支持HTTPS连接\n计算机输入URL后会发生什么浏览器查找域名的IP地址\n客户端发起请求后，浏览器解析域名。首先浏览器会查看本地磁盘的host文件（已被舍弃），是否有对应的IP地址，如果有就直接使用\n如果没有，就会发送一个DNS请求给本地的DNS服务器，比如中国移动\n本地DNS服务器会查询缓存记录，如果缓存存在，就直接返回结果。如果没有，本地DNS服务器还要向DNS根服务器进行查询\n根 DNS 服务器不记录具体的域名和 IP 地址的对应关系，而是告诉本地 DNS 服务器到顶级域名服务器进行查询，并给出顶级域名服务器的地址（迭代查询）\n本地 DNS 服务器继续向域服务器发出请求，域服务器收到请求之后，不会直接返回域名和 IP 地址的对应关系，而是告诉本地 DNS 服务器权威域名服务器的地址\n本地 DNS 服务器向权威域名服务器发出请求，收到一个域名和 IP 地址对应关系，本地 DNS 服务器不仅要把 IP 地址返回给客户端，还要把这个对应关系保存在缓存中，以备下次别的用户访问。\n\n浏览器向web服务器发送一个HTTP请求拿到IP地址后，浏览器会以一个随机端口号向服务器的80端口发起TCP的连接请求\n三次握手建立TCP连接\n建立了 TCP 连接之后，发起了一个 HTTP 请求，如 GET、POST等\n服务器的重定向访问301和302重定向对比两个状态码都表示重定向，但301表示旧地址的资源已经被永久的移除了，搜索引擎在抓取新的内容时将旧的网络地址交换为重定向后的网址；302表示旧的地址资源还在，这个重定向只是临时的从旧地址跳转到新地址，搜索引擎会抓取新的内容而保存旧的地址。防止一个页面出现多个缓存。\n浏览器会重新发送HTTP请求\n服务器处理并返回HTTP响应，浏览器显示HTML","slug":"计算机网络","date":"2022-10-31T06:51:13.000Z","categories_index":"","tags_index":"计算机基础知识","author_index":"Samuel"},{"id":"a7e90bf30b292f0f6e0827bd156cab5e","title":"HashMap","content":"HashCodeHashCode()，在未被重写前，即object类中，是一个Native方法，默认返回对象在堆中的地址，是一个独特值，可以看作是对象的身份ID\n而在String类中，HashCode被重写\npublic int hashCode() &#123;\n       int h = hash;\n       if (h == 0 &amp;&amp; value.length > 0) &#123;\n           char val[] = value;\n\n           for (int i = 0; i &lt; value.length; i++) &#123;\n               h = 31 * h + val[i];\n           &#125;\n           hash = h;\n       &#125;\n       return h;\n   &#125;\n\n为什么使用31作为乘数？？？\n\n31是一个不大不小的奇质数，如果选择偶数计算，会导致乘积运算时的数据溢出。如果选择一个很小的数，那么hashcode会分布在一个很小的范围内，容易造成哈希值的冲突；如果选择一个很大的数，那么可能会超出整型变量的范围。\n在二进制中31等于2&lt;&lt;5-1，那么31*i即为（i&lt;&lt;5）-i，这种乘积运算可以直接通过位移来提升性能，JVM也支持这种优化方式\n不止31，33，37，39，41也可以作为乘数，当我们使用超过50,000个 单词来计算hashcode，这5个乘数都得到的哈希值冲突都小于7，31最小。同时hash的目的就是让数据尽可能分散排布，而以31作为乘数得到的结果分布最为均匀。\n\nHashMap如何计算索引值第一步：计算hashstatic final int hash(Object key) &#123;\n    int h;\n    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);\n&#125;\n//将key的hashCode值 与 key的hashCode值的高16位(无符号右移)，进行^异或运算，得到一个hash值\n\n原理：引入扰动函数\n扰动函数就是为了增大随机性，减少碰撞，在引入扰动函数后散列表的数据分布更加均匀\n第二步：计算索引//n为数组长度从\nindex = hash &amp; (n-1);\n\n一般的散列算法是以取余%来计算散列值的，但是CPU在做 &#x2F;除 或 %取余运算时，效率是很低的。\n所以使用位运算与，可以实现相同的结果，而且效率更高。\nHashMap的容量HashMap的初始化容量通常设置为2的幂次方大小，未指定大小时默认初始化为16，\n这与hash &amp; (n-1)密切相关，2次幂大小的数与运算与取余运算的效果相同\n要减一，即n-1，我们才能获得一个01111这样的值（在和hash进行与运算的时候才可以获得范围合法的索引）\n若指定一个奇数作为capacity，就会调用tableSizeFor()\n若传入17，向正方向寻找一个最接近17的2的幂次方，即为32\n通过位移运算+或运算将17的每一位都改为1，然后再加1，最后就可以得到32\n扩容//负载因子\nstatic final float DEFAULT_LOAD_FACTOR = 0.75f;\n\n负载因子就是一个阈值，当数据量超过这个阈值后，便要进行扩容\n因为hashcode的特性，一个散列表地址可能对应多个元素，所以即使元素数量大于散列表地址数量，也可能出现无法把散列表占满的情况，在这种情况下，某些位置会出现碰撞，这降低了HashMap的性能\n所以当散列表的位置使用到一定程度时，就需要进行扩容，默认0.75，也就是当使用3&#x2F;4后，就进行扩容\n为什么扩容时会直接乘以2：\n\n以2倍扩容的方式扩容，元素在新表中的位置要么不动，要么原脚标位+扩容长度（二的幂次方偏移量），这样会使扩容的效率大大提高（JDK1.8后扩容不用重新rehash）\n可以使元素均匀的散布hashmap中，减少hash碰撞\n\n转换红黑树的条件\n链表长度大于8\nEntry数组大于64\n\nHashCode()和equals()的关系，如何使用？\nequals()来自Object()类，默认使用&#x3D;&#x3D;来比较地址值，判断引用指向是否是一个对象。通过重写该方法来定义新的规则，比如String类中的equals方法就是逐个比较字符串的字符\nHashCode()来自Object()类，这是一个本地方法，在没有被重写时默认返回对象在堆内存上的独特值，可以认为是对象在堆内存中的身份证号，具有唯一性。重写HashCode后，可以返回计算而出的哈希值，即散列算法，用于确定元素的桶位置，例如HashMap\n如何使用：查找一个元素，当调用散列算法后，快速定位到相应位置，若该桶内有元素，则调用equals()，由于哈希碰撞的存在，HashCode()相等时，不一定就是相应的元素，所以必须调用equals()来判断是否为要查找的元素\n\n&#x3D;&#x3D;和equals的区别&#x3D;&#x3D;：若比较的是基本数据类型，则比较的是数值是否相等；如果比较的是引用数据类型，则比较的是地址值\nequals()：用来比较引用指向的对象地址是否相等。不可用于基本数据类型的比较。\n在Object类中，equals就是由&#x3D;&#x3D;来实现的，可以认为equals在被重写前，两者作用是相等的\n为何重写equals后一定要重写hashcode?根据hashcode的规则，两个对象相等其哈希值一定相等\n所以当重写equals后比如在String类中，两个字面量相同的字符串对象equals后一定返回true\n但是如果不重写hashcode，默认返回JVM生成的独特值，此时两个对象的hashcode可能不会相等，与上文说的规则相矛盾。所以必须重写hashcode来符合这个规则\nHashMap为什么是线程不安全的\nJDK1.7可能造成死循环：由于resize时的数据迁移采用头插法（当时的人觉得比较高效），而头插法会导致链表顺序颠倒（因为先插入的元素在后面），当线程A未完成transfer操作时被挂起，而线程B成功完成了transfer操作，线程A再次获取时间片后继续执行transfer，由于头插法导致链表顺序颠倒，便有可能导致生成环形链表。\nJDK1.8可能造成数据丢失：假设两个线程A、B都在进行put操作，并且hash函数计算出的插入下标是相同的，当线程A执行过程中由于时间片耗尽导致被挂起，而线程B得到时间片后在该下标处插入了元素，完成了正常的插入，然后线程A获得时间片，由于之前已经进行了hash碰撞的判断，所有此时不会再进行判断，而是直接进行插入，这就导致了线程B插入的数据被线程A覆盖了，从而线程不安全。\n\nHashMap如何保证线程安全\nCollections.synchronizedMap()方法传入HashMap的引用变量，返回一个新的Map，这个新的Map就是线程安全的，返回的并不是HashMap，而是map的一种实现。该方法封装了所有不安全的HashMap方法，使用了synchronized方法来进行互斥，和HashTable差不多，该方法使用代理模式new了一个新的类，这个类实现了Map接口。该方法的优点：实现简单；缺点：加锁的粒度较大，性能比较差。被synchronizedMap()包裹的map是可以传入null 键的。而concurrentHashmap不可以。\n使用ConcurrentHashMap，使用了新的锁机制，把hashmap拆分成了多个独立的块，这样在高并发的情况下减少了锁冲突的可能。使用的是NonfairSync，这个特性调用CAS指令来保证原子性和互斥性。如果多个线程恰好操作到同一个segment，只有一个线程得到运行。优点：互斥的代码段小，性能更好，发生锁碰撞的几率低。缺点：代码繁琐。\n\nConcurrenHashMap和HashTableHashTable它的每一个方法都是使用了synchronized同步锁机制，将整个入口锁起来，在多线程的情况下，他整个数组结构的入口就只能一条线程执行完成之后其他线程才能进入，无论下标是否相同，是否存在hash碰撞。\n而ConcurrenHashMap由JDK1.5引入，降低了锁粒度且保证了线程安全\nHashEntry内的成员变量value等都是volatile类型的，这样就保证别的线程对value值的修改，get方法可以马上看到\n在JDK1.7之前，在初始化ConcurrentHashMap的时候，会初始化一个Segment数组,容量为16，Segment内部有一个table数组，存储entry数组+链表的结构\n每个Segment都继承了ReentrantLock类，也就是说每个Segment类本身就是一个锁，使用了分段锁的机制，降低了锁粒度。\n在查找时，定位segment和定位table后，依次扫描这个table元素下的的链表，要么找到元素，要么返回null。\n在JDK1.8之后，引入红黑树且取消了segment设计。使用synchronize关键字，为每一个node对象加同步锁，将锁的粒度将到最低。\n","slug":"HashMap","date":"2022-10-30T14:05:57.000Z","categories_index":"","tags_index":"Java基础知识","author_index":"Samuel"},{"id":"6841591cdd97dd7e1d719dfd22576c72","title":"买股票问题","content":"121. 买卖股票的最佳时机你只能选择某一天买入这只股票，并选择在未来的某一个不同的日子卖出该股票。设计一个算法来计算你所能获取的最大利润。\n输入：[7,1,5,3,6,4]\n输出：5\n解释：在第 2 天（股票价格 &#x3D; 1）的时候买入，在第 5 天（股票价格 &#x3D; 6）的时候卖出，最大利润 &#x3D; 6-1 &#x3D; 5 。\n     注意利润不能是 7-1 &#x3D; 6, 因为卖出价格需要大于买入价格；同时，你不能在买入前卖出股票。\n\nclass Solution &#123;\n    public int maxProfit(int[] prices) &#123;\n        int n = prices.length;\n        //dp数组，dp[i][j],今天是第i天，交易状态为j，利润为dp[i][j];\n        int[][] dp =new int[n][2];\n        for(int i =0;i&lt;n;i++)&#123;\n            //base case\n            if(i==0)&#123;\n                dp[i][0] =0;\n                dp[i][1] = -prices[i];\n                continue;\n            &#125;\n            //0代表已卖出，手中无股票；1代表未卖出，手中持有股票\n            dp[i][0] = Math.max(dp[i-1][0],dp[i-1][1]+prices[i]);\n            dp[i][1] = Math.max(dp[i-1][1],-prices[i]);\n        &#125;\n        return dp[n-1][0];\n    &#125;\n&#125;\n\n122. 买卖股票的最佳时机 II输入：prices &#x3D; [7,1,5,3,6,4]\n输出：7\n解释：在第 2 天（股票价格 &#x3D; 1）的时候买入，在第 3 天（股票价格 &#x3D; 5）的时候卖出, 这笔交易所能获得利润 &#x3D; 5 - 1 &#x3D; 4 。\n     随后，在第 4 天（股票价格 &#x3D; 3）的时候买入，在第 5 天（股票价格 &#x3D; 6）的时候卖出, 这笔交易所能获得利润 &#x3D; 6 - 3 &#x3D; 3 。\n     总利润为 4 + 3 &#x3D; 7 。\n\nclass Solution &#123;\n    //特殊之处：可以进行无数次买卖，所以在进行一次买入时可能总利润已经为正数\n    //而只能进行一次买卖的情况下，在买入前的总利润只能为零\n    public int maxProfit(int[] prices) &#123;\n        int n = prices.length;\n        int[][] dp = new int[n][2];\n        for(int i=0;i&lt;n;i++)&#123;\n            if(i==0)&#123;\n                dp[i][0] = 0;\n                dp[i][1] = -prices[i];\n                continue;\n            &#125;\n            dp[i][0] = Math.max(dp[i-1][0],dp[i-1][1]+prices[i]);\n            //区别在这里\n            dp[i][1] = Math.max(dp[i-1][1],dp[i-1][0]-prices[i]);\n        &#125;\n        return dp[n-1][0];\n    &#125;\n&#125;\n\n123. 买卖股票的最佳时机 III最多进行两笔交易\n输入：prices &#x3D; [3,3,5,0,0,3,1,4]\n输出：6\n解释：在第 4 天（股票价格 &#x3D; 0）的时候买入，在第 6 天（股票价格 &#x3D; 3）的时候卖出，这笔交易所能获得利润 &#x3D; 3-0 &#x3D; 3 。\n     随后，在第 7 天（股票价格 &#x3D; 1）的时候买入，在第 8 天 （股票价格 &#x3D; 4）的时候卖出，这笔交易所能获得利润 &#x3D; 4-1 &#x3D; 3 。\n\nclass Solution &#123;\n    //因为限制了买卖次数，所以需要一个三维的dp数组来进行穷举和状态转移\n    //k代表到第i天内，可以最多进行k次交易\n    public int maxProfit(int[] prices) &#123;\n        int n = prices.length;\n        int max_k = 2;\n        int[][][] dp = new int[n][max_k+1][2];\n        for(int i=0;i&lt;n;i++)&#123;\n            for(int k=max_k;k>0;k--)&#123;\n                if(i==0)&#123;\n                    dp[i][k][0] = 0;\n                    dp[i][k][1] = -prices[i];\n                    continue;\n                &#125;\n                dp[i][k][0] = Math.max(dp[i-1][k][0], dp[i-1][k][1] + prices[i]);\n                //在买入的时候进行k的状态转移，因为一次买入就代表一次交易的开始\n                dp[i][k][1] = Math.max(dp[i-1][k][1], dp[i-1][k-1][0] - prices[i]);\n            &#125;\n        &#125;\n        return dp[n-1][max_k][0];\n    &#125;\n&#125;\n\n188. 买卖股票的最佳时机 IV自定义k的情况\n输入：k &#x3D; 2, prices &#x3D; [2,4,1]\n输出：2\n解释：在第 1 天 (股票价格 &#x3D; 2) 的时候买入，在第 2 天 (股票价格 &#x3D; 4) 的时候卖出，这笔交易所能获得利润 &#x3D; 4-2 &#x3D; 2 。\n\nclass Solution &#123;\n    //需要对k进行判断，若k大于某个值便按照无限次来计算，避免了超时的情况\n    public int maxProfit(int k, int[] prices) &#123;\n        int n =prices.length;\n        if(n==0) return 0;\n        if(k>n/2) return ifKequalsInfinite(prices);\n        int[][][] dp = new int[n][k+1][2];\n        for(int i=0;i&lt;n;i++)&#123;\n            //当k=0时，取一些永远不可能的特殊值\n            dp[i][0][0] = 0;\n            dp[i][0][1] = -666;\n        &#125;\n        for(int i=0;i&lt;n;i++)&#123;\n            for(int j=k;j>0;j--)&#123;\n                if(i==0)&#123;\n                    dp[i][j][0] = 0;\n                    dp[i][j][1] = -prices[i];\n                    continue;\n                &#125;\n                dp[i][j][0] = Math.max(dp[i-1][j][0],dp[i-1][j][1]+prices[i]);\n                //如果要保证今天可以进行一次交易，那么到昨天的总交易次数最大只能为j-1，留下一次给今天\n                dp[i][j][1] = Math.max(dp[i-1][j][1],dp[i-1][j-1][0]-prices[i]);\n            &#125;\n        &#125;\n        return dp[n-1][k][0];\n    &#125;\n    //当k足够大时，看作无限大\n    int ifKequalsInfinite(int[] prices)&#123;\n         int n = prices.length;\n        int[][] dp = new int[n][2];\n        for (int i = 0; i &lt; n; i++) &#123;\n            if (i - 1 == -1) &#123;\n            // base case\n            dp[i][0] = 0;\n            dp[i][1] = -prices[i];\n            continue;\n        &#125;\n        dp[i][0] = Math.max(dp[i-1][0], dp[i-1][1] + prices[i]);\n        dp[i][1] = Math.max(dp[i-1][1], dp[i-1][0] - prices[i]);\n    &#125;\n    return dp[n - 1][0];\n    &#125;\n&#125;\n\n","slug":"买股票问题","date":"2022-10-30T13:19:55.000Z","categories_index":"","tags_index":"LeetCode初见","author_index":"Samuel"},{"id":"946249c65165e1a3d66f50e0cb6e89e7","title":"Spring","content":"bean的生命周期Bean的创建分为三个基本步骤\n\n实例化：可以理解为new一个对象，AbstractAutowireCapableBeanFactory中的createBeanInstance方法\n属性注入：可以理解为setter方法完成属性注入，AbstractAutowireCapableBeanFactory的populateBean方法\n初始化：按照Spring的规则配置一些初始化的方法，例如实现AOP代理，注解。AbstractAutowireCapableBeanFactory的initializeBean方法\n\n而Bean的完整生命周期就是在上面三个步骤中穿插执行BeanPostProcessor后置处理器的过程\n\n普通Java对象可以理解为它是用Class对象作为「模板」进而创建出具体的实例，而Spring所管理的Bean不同的是，除了Class对象之外，还会使用BeanDefinition的实例来描述对象的信息，比如说，我们可以在Spring所管理的Bean有一系列的描述：@Scope、@Lazy等等。可以理解为：Class只描述了类的信息，而BeanDefinition描述了对象的信息。\n​\tSpring在启动的时候需要「扫描」在XML/注解/JavaConfig 中需要被Spring管理的Bean信息，随后，会将这些信息封装成BeanDefinition，最后会把这些信息放到一个beanDefinitionMap中，key是beanName，value则是BeanDefinition对象，目前真实对象还没实例化，接着会遍历这个beanDefinitionMap，执行BeanFactoryPostProcessor这个Bean工厂后置处理器\n​\t比如说，我们平时定义的占位符信息，就是通过BeanFactoryPostProcessor的子类PropertyPlaceholderConfigurer进行注入进去，我们也可以自定义BeanFactoryPostProcessor来对我们定义好的Bean元数据进行获取或者修改\n​\tBeanFactoryPostProcessor后置处理器执行完了以后，就到了实例化对象，在Spring里边是通过反射来实现的，一般情况下会通过反射选择合适的构造器来把对象实例化\n//反射创建\nConstructor ctor = Class.getDeclareConstructor();\nObject obj = ctor.newInstance();\n\n​\t实例化只是把对象给创建出来，而对象具体的属性是还没注入的，比如我的对象是UserService，而UserService对象依赖着SendService对象，这时候的SendService还是null的，使用populateBean()进行属性注入，这里便会牵扯出循环依赖的问题\n​\t属性注入后会判断该Bean是否实现了Aware相关的接口，如果存在则填充相关的资源，invokeAwareMethod()，进行BeanName，BeanFactory，BeanClassLoader属性设置\n​\tAware相关的接口处理完之后，就会到BeanPostProcessor后置处理器，BeanPostProcessor后置处理器有两个方法，一个是before，一个是after\n​\tBeanPostProcessor相关子类的before方法执行完，则执行init相关的方法，比如说@PostConstruct、实现了InitializingBean接口、定义的init-method方法\n​\tinit方法执行完之后，就会执行BeanPostProcessor的after方法，AOP就在此实现（关键子类AnnotationAwareAspectJAutoProxyCreator），基本重要的流程已经走完了，我们就可以获取到对象去使用了\n\n对IOC的理解控制反转：一种编程思想，即讲对象交给spring容器来帮我们进行管理。\nDI：依赖注入，把对应的值注入到具体的对象中，即@Autowired或者populateBean\n容器：存放对象，使用Map结构来存储，在spring中一般存在三级缓存，singletonObject存放完整的Bean对象，bean的整个生命周期，从创建到销毁都是由容器来管理。\nAOP是如何实现的AOP是IOC的一个扩展功能，现有IOC，再有AOP，AOP是IOC整个流程的一个扩展点\n\nadvice:切面的工作被描述为通知\nJoinpoint：动态代理所代理实现类中的各个方法称为连接点\nPointcut：代理类中真正增强的方法\nAspect：将通知用到切入点的过程叫切面\n\n在bean的创建过程中有一个步骤可以对bean进行扩展实现，beanPostProcessor后置处理，而AOP就是其中一个扩展\n\n代理对象的创建（advice，切面，切点）\n通过JDK或者CGLIB的方式来生成代理对象\n在执行方法调用的时候，会调用到生成的字节码文件中，会调用DynamicAdvisoredInterceptor类中的intercept方法，从此方法开始执行\n根据之前定义好的通知生成拦截器\n按照拦截器链中以此获取每一个通知，开始进行执行\n\n循环依赖和三级缓存所谓的循环依赖，就是两个或则两个以上的bean互相依赖对方，最终形成闭环\n比如“A对象依赖B对象，而B对象也依赖A对象”，或者“A对象依赖B对象，B对象依赖C对象，C对象依赖A对象”\npublic class A &#123;\n    private B b;\n&#125;\npublic class B &#123;\n    private A a;\n&#125;\n\n在常规情况下，会出现以下情况\n\n通过构建函数创建A对象（A对象是半成品，还没注入属性和调用init方法）。\nA对象需要注入B对象，发现对象池里还没有B对象（对象在创建并且注入属性和初始化完成之后，会放入对象缓存里）。\n通过构建函数创建B对象（B对象是半成品，还没注入属性和调用init方法）。\nB对象需要注入A对象，发现对象池里还没有A对象。\n创建A对象，循环以上步骤。\n\n解决循环依赖的最核心思想：提前曝光\n将半成品A提前放入缓存池，从而可以让B对象成功完成属性注入和初始化，成品B可以让半成品A完成初始化，从而打破了循环依赖\n\n通过构建函数创建A对象（A对象是半成品，还没注入属性和调用init方法）。\nA对象需要注入B对象，发现缓存里还没有B对象，将半成品对象A放入半成品缓存。\n通过构建函数创建B对象（B对象是半成品，还没注入属性和调用init方法）。\nB对象需要注入A对象，从半成品缓存里取到半成品对象A。\nB对象继续注入其他属性和初始化，之后将完成品B对象放入完成品缓存。\nA对象继续注入属性，从完成品缓存中取到完成品B对象并注入。\nA对象继续注入其他属性和初始化，之后将完成品A对象放入完成品缓存。\n\n三级缓存//一级缓存：存放成品bean\nprivate final Map&lt;String, Object> singletonObjects = new ConcurrentHashMap&lt;>(256);\n\n//二级缓存，存放半成品bean，提前曝光的核心\nprivate final Map&lt;String, Object> earlySingletonObjects = new HashMap&lt;>(16);\n\n//三级缓存，存放bean工厂对象，用来生成半成品bean并存入二级缓存中\nprivate final Map&lt;String, ObjectFactory&lt;?>> singletonFactories = new HashMap&lt;>(16);\n\n直接看流程图：\n\n问：这里的第三级缓存有什么用？\n如果我们不考虑AOP的情况下，第三级缓存真没什么用，它直接将实例化阶段创建的对象给返回了。\n如果我们考虑上了AOP，那么流程图会变成：\n\n我们对A进行了AOP代理的话，那么此时getEarlyBeanReference将返回一个代理后的对象，而不是实例化阶段创建的对象，这样就意味着B中注入的A将是一个代理对象而不是A的实例化阶段创建后的对象。\n问：初始化的时候是对A对象本身进行初始化，而容器中以及注入到B中的都是代理对象，这样不会有问题吗？\n不会，这是因为不管是cglib代理还是jdk动态代理生成的代理类，内部都持有一个目标类的引用，当调用代理对象的方法时，实际会去调用目标对象的方法，A完成初始化相当于代理对象自身也完成了初始化。\n问：三级缓存为啥要存一个工厂，而不是直接存一个引用进去呢？\n工厂的目的在于只有真正发生循环依赖的时候，才会去生成代理对象。如果未发生循环依赖，那么就只有一个工厂放那儿，但是不会去通过这个工厂去真正创建对象。\n问：为什么要使用第三级缓存呢，不管有没有循环依赖，我们都提前创建好代理对象，并将代理对象放入缓存，出现循环依赖时，其他对象直接就可以取到代理对象并注入。这样就只会使用两级缓存，不是更方便嘛？\n如果要使用二级缓存解决循环依赖，意味着Bean在构造完后就需要创建代理对象，这样违背了Spring设计原则！！\nSpring结合AOP跟Bean的生命周期，是在Bean创建完全之后通过AnnotationAwareAspectJAutoProxyCreator这个后置处理器来完成的，在这个后置处理的postProcessAfterInitialization方法中对初始化后的Bean完成AOP代理。如果出现了循环依赖，那没有办法，只有给Bean先创建代理，但是没有出现循环依赖的情况下，设计之初就是让Bean在生命周期的最后一步完成代理而不是在实例化后就立马完成代理。\n使用二级缓存：\n\n使用三级缓存：\n\n总结：Spring如何解决循环依赖？\n答：Spring通过三级缓存解决了循环依赖，其中一级缓存为单例池（singletonObjects，一个并发HashMap）,二级缓存为早期曝光对象earlySingletonObjects，三级缓存为早期曝光对象工厂（singletonFactories），二三级缓存均为普通的HashMap。\n当A、B两个类发生循环引用时，在A完成实例化后，就使用实例化后的对象去创建一个对象工厂，并添加到三级缓存中，如果A被AOP代理，那么通过这个工厂获取到的就是A代理后的对象，如果A没有被AOP代理，那么这个工厂获取到的就是A实例化的对象。\n当A进行属性注入时，会去创建B，同时B又依赖了A，所以创建B的同时又会去调用getBean(a)来获取需要的依赖，此时的getBean(a)会从缓存中获取，第一步，先获取到三级缓存中的工厂；第二步，调用对象工工厂的getObject方法来获取到对应的对象，得到这个对象后将其注入到B中。紧接着B会走完它的生命周期流程，包括初始化、后置处理器等。\n当B创建完后，会将B再注入到A中，此时A再完成它的整个生命周期。至此，循环依赖结束！\nJDK和CGLIB动态代理的区别JDK代理使用的是反射机制生成一个实现代理接口的匿名类，在调用具体方法前调用InvokeHandler来处理。\nCGLIB代理使用字节码处理框架ASM，对代理对象类的class文件加载进来，通过修改字节码生成子类。\nJDK创建代理对象效率较高，执行效率较低，JDK动态代理机制是委托机制，只能对实现接口的类生成代理，通过反射动态实现接口类。\nCGLIB创建代理对象效率较低，执行效率高，CGLIB则使用的继承机制，针对类实现代理，被代理类和代理类是继承关系，所以代理类是可以赋值给被代理类的，因为是继承机制，不能代理final修饰的类。\n如果目标对象实现了接口，默认情况下会采用JDK的动态代理实现AOP，可以强制使用CGLIB实现AOP，如果目标对象没有实现了接口，必须采用CGLIB库，spring会自动在JDK动态代理和CGLIB之间转换。\nJDK动态代理只能为接口创建代理，使用上有局限性。实际的场景中我们的类不一定有接口，此时如果我们想为普通的类也实现代理功能，我们就需要用到CGLIB来实现了。\nJDK代理是不需要依赖第三方的库，只要JDK环境就可以进行代理，需要满足以下要求： 1.实现InvocationHandler接口，重写invoke() 2.使用Proxy.newProxyInstance()产生代理对象 3.被代理的对象必须要实现接口\nCGLIB 必须依赖于CGLIB的类库,需要满足以下要求： 1.实现MethodInterceptor接口，重写intercept() 2.使用Enhancer对象.create()产生代理对象\nCGLIB是一个强大、高性能的字节码生成库，它用于在运行时扩展Java类和实现接口，本质上它是通过动态的生成一个子类去覆盖所要代理的类（非final修饰的类和方法）。\nEnhancer既能够代理普通的class，也能够代理接口。Enhancer创建一个被代理对象的子类并且拦截所有的方法调用（包括从Object中继承的toString和hashCode方法）。Enhancer不能够拦截final方法，例如Object.getClass()方法，这是由于Java final方法语义决定的。基于同样的道理，Enhancer也不能对final类进行代理操作。\n事务Spring将JDBC的事务概念带到了业务层中，同样继承了ACID特性，同样也有四种隔离级别\n只不过开启&#x2F;提交&#x2F;回滚的操作交给Spring来执行，而不用自行编码\n一般只需一个注解@Transactional 修饰方法。那么整个方法的代码块都将以事务的规则执行\n事务传播行为当事务方法被另外一个事务方法调用时，必须指定事务应该如何传播\n例如，方法可能继续在当前事务中执行，也可以开启一个新的事务，在自己的事务中执行。\nREQUIRED如果外部方法开启事务并且是 REQUIRED 的话，所有 REQUIRED 修饰的内部方法和外部方法均属于同一事务 ，只要一个方法回滚，整个事务都需要回滚。如果外部方法没有开启事务的话，REQUIRED 修饰的内部方法会开启自己的事务，且开启的事务相互独立，互不干扰。\nREQUIRES_NEW不管外部方法是否开启事务，REQUIRES_NEW 修饰的内部方法都会开启自己的事务，且开启的事务与外部的事务相互独立，互不干扰。\nNESTED如果当前存在事务，就在当前事务内执行；否则，就执行与 REQUIRED 类似的操作。\nSUPPORTS如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。\nNOT_SUPPORTED以非事务方式运行，如果当前存在事务，则把当前事务挂起。\nMANDATORY如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。\nNEVER以非事务方式运行，如果当前存在事务，则抛出异常。\nSpring事务的实现原理是什么？Spring有两种事务的实现方式，第一是编程式事务，即通过手动编码的方式，创建TransactionTemplate对象进行execute()传入业务代码或者transactionManager对象通过commit()提交业务代码来实现。第二就是声明式事务，即使用注解的形式直接拦截方法，基于AOP。编程式事务的粒度更小，是代码块级别的。而声明式事务的粒度稍大一些是整个方法。\n事务操作是AOP的一个核心体现，当一个方法添加@Transactional后，Spring会基于这个类生成代理对象，当使用这个代理对象的方法时，如果有事务，那么会先关闭连接的autocommit，先执行业务逻辑。若无异常，代理逻辑就会提交。若出现异常，就会进行回滚操作。\n","slug":"Spring","date":"2022-10-26T13:17:18.000Z","categories_index":"","tags_index":"JAVA进阶","author_index":"Samuel"},{"id":"838ae74e3a76757d637de803a615bfd9","title":"MySQL","content":"MySQL关系型数据库，插件式的存储引擎，这种架构可以根据业务的需求和实际需要选择合适的存储引擎。\n\n客户端通过协议与服务器连接，发送查询语句，先检查缓存是否命中，若命中直接返回，否则进行语句解析\n预处理，检查语句是否有语法错误，查询优化（是否会使用索引扫描），生成查询计划，启动查询引擎，开始查询，底层存储引擎调用API获取数据，返回给客户端\nMYSQL默认使用B+树索引\n\n字段选择优先级（由优至劣）\n整型\ntime：定长运算快\nenum：枚举，能约束值，内部由整型存储\nchar：定长，需要考虑字符集\nvarchar：不定长，考虑字符集的转换与排序的校对集，速度慢\ntext：无法使用内存临时表\n\n定长优先。能选整型就不要选字符串，够用就行，不要富余分配空间，尽量避免使用Null\nvarchar最多可以定义65535个字节\n事务的ACID\n原子性：要么全部成功，要么全部失败。由undo_log来保证\n一致性：数据库总是从一个状态转移到另一个状态\n隔离性：最终提交前，其他事务不可见，MVCC\n持久性：事务一旦提交，修改将会永久保存到数据库中，内存+redo_log\n\nMYSQL的各种索引\n\n主键索引：一张表一个主键索引，通常与表一起创建。\n唯一索引：如果能确定某个数据列将只包含彼此各不相同的值，在为这个数据列创建索引的时候就应该用关键字UNIQUE把它定义为一个唯一索引。这么做的好处：一是简化了MySQL对这个索引的管理工作，这个索引也因此而变得更有效率；二是MySQL会在有新记录插入数据表时，如果字段的值已经出现过了，MySQL将拒绝插入那条新记录。也就是说，唯一索引可以保证数据记录的唯一性。事实上，在许多场合，人们创建唯一索引的目的往往不是为了提高访问速度，而只是为了避免数据出现重复。\n普通索引：建立在普通字段上的索引，唯一任务是加快对数据的访问速度。因此，应该只为那些最经常出现在查询条件（WHEREc）或排序条件（ORDERBY）中的数据列创建索引。只要有可能，就应该选择一个数据最整齐、最紧凑的数据列（如一个整数类型的数据列）来创建索引。\n复合索引：字符类型字段的前几个字符建立，可以覆盖多个数据列，遵循最左匹配原则，可能会因为order by失效。\n\n三星索引：衡量一个索引是否达到最佳表现的三个维度\n\n第一星：where后面的等值谓词，可以匹配索引列的顺序：意义在于谓索匹配的越多，索引片越窄，最终扫描的数据行也是越小。把 WHERE 后的等值条件列作为索引最开头的列，如此，必须扫描的索引片宽度就会缩至最短。\n第二星：order by的排序是否和索引的顺序一致：意义在于避免进行额外的排序，增加消耗。将 ORDER BY 列加入到索引中，保持列的顺序\n第三星：select的字段是否都为索引列：意义在于避免每一个索引行查询，都需要去聚簇索引进行一次随机IO查询。将查询语句中剩余的列都加入到索引中。\n\n普通索引和唯一索引有什么区别？\n概念上的不同：普通索引可以重复。而唯一索引和主键一样，不可以重复，但在一张表里面只能有一个主键，不能为空，唯一索引可有多个。唯一索引可有一条记录为null。在学校，一般用学号做主键，身份证号作为唯一索引\n查询实现的不同：若查询语句为\nselect id from T where k&#x3D;4\n\n普通索引：查找到满足条件的第一个记录后，继续查找下个记录，直到碰到第一个不满足k&#x3D;4的记录。\n唯一索引：查到第一个满足条件的，就停止搜索。\n若重复数据很多，普通索引多了一次“查找和判断下一条记录”的操作，可能会多次IO，但是总体性能其实差别不大\n更新性能不同：往表中插入一个新记录，InnoDB会有什么反应？\n若在内存中，普通索引直接插入，而唯一索引会判断一次是否有冲突，再插入。判断的性能消耗可以不计\n若不在内存中，普通索引会将数据记录在change buffer；唯一索引会将数据页读入内存再插入。众所周知数据库的IO成本很高，所以普通索引更新数据的性能是要更优的。\n总结：若更新性能优先级更高，选择普通索引。\n四种隔离级别\nread uncommitted：所有事务都可以看见未提交的结果，产生脏读\nread committed：一个事务从开始到提交前，任何数据改变都是不可见的，产生不可重复读问题\nrepeatable read：MySQL默认的隔离级别，解决不可重复读问题，保证同一事物的多个实例在并发读取事务时，会读取到同样的数据行，产生幻读问题（InnoDB的MVCC解决了幻读问题）\nserializable：最高级别的隔离，强制事务排序，不可能相互冲突，其实就是加锁，效率低\n\n存储引擎MyISAM和InnoDB的区别是什么\n\nInnoDB：支持事务，支持外键，聚集索引：文件存储于主键索引的叶子节点上，所以主键索引效率很高，但是辅助索引需要进行回表，并且主键不能过大，因为辅助索引也会存储主键，所以过大的主键会影响索引的大小。最小粒度锁为行锁\nMyISAM：不支持事务，不支持外键，非聚集索引，索引保存的是数据文件的指针，主键索引和辅助索引独立。会创建一个单独的变量保存整个表的行数，读取表行数的速度更快。最小粒度锁为表锁，并发性能不好。\n\n基础架构\nMySQL 主要由下面几部分构成：\n\n连接器： 身份认证和权限相关(登录 MySQL 的时候)。\n查询缓存： 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）\n\n\n\n\n\n\n\n\n\n\n连接建立后，执行查询语句的时候，会先查询缓存，MySQL 会先校验这个 SQL 是否执行过，以 Key-Value 的形式缓存在内存中，Key 是查询预计，Value 是结果集。如果缓存 key 被命中，就会直接返回给客户端，如果没有命中，就会执行后续的操作，完成后也会把结果缓存起来，方便下一次调用。当然在真正执行缓存查询的时候还是会校验用户的权限，是否有该表的查询条件\nMySQL 查询不建议使用缓存，因为查询缓存失效在实际业务场景中可能会非常频繁，假如你对一个表更新的话，这个表上的所有的查询缓存都会被清空。对于不经常更新的数据来说，使用缓存还是可以的。\n\n分析器： 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。\n\n优化器： 按照 MySQL 认为最优的方案去执行。\n\n执行器： 执行语句，然后从存储引擎返回数据。 执行语句之前会先判断是否有权限，如果没有权限的话，就会报错。\n\n日志模块：在server层是binlog归档日志模块\n\n插件式存储引擎 ： 主要负责数据的存储和读取，采用的是插件式架构，支持 InnoDB、MyISAM、Memory 等多种存储引擎\n\n查询语句的执行流程如下：权限校验（如果命中缓存）—&gt;查询缓存—&gt;分析器—&gt;优化器—&gt;权限校验—&gt;执行器—&gt;引擎\n\n更新语句执行流程如下：分析器—-&gt;权限校验—-&gt;执行器—&gt;引擎—redo log(prepare 状态)—&gt;binlog—&gt;redo log(commit状态)\n\n\n索引为什么要有索引一般的应用系统读写比例大约在10：1左右，而且数据的插入和更新出现性能问题的几率小于查询。在生产环境中，最容易出现问题的就是查询操作，因此对查询性能的优化就显得十分重要\n索引的原理索引的本质就是一个满足某种查找算法的数据结构，常见的有BST，AVL，红黑树，Btree，B+树等等\n这些结构以某种方式指向数据（索引结点指向数据记录物理地址的指针）\n\n索引大大减少了服务器需要扫描的数据量，提高了检索效率\n避免排序，减少CPU消耗\n将随机IO转换为顺序IO\n\n数据库的索引会复杂很多，因为数据库不仅面临等值查询，还有范围查询，模糊查询，并值查询等，并且由于数据库的索引一般存储于外存里，查询时磁盘和主存以页为单位交换数据（通常为4k的整数倍），访问外存的时间成本大约是内存的十万倍，所以简单的的搜索树难以满足复杂的应用场景\n索引也是一张表，保存了主键和索引，指向了实体表，也需要占用内存。索引存储于外存，所以索引的查询也需要磁盘IO开销\n虽然提高了查询速度，但是在对实体表进行更新时，索引也需要进行相应的维护更新，而索引的维护也需要开销，降低了更新表的速度\nMySQL主要用到两种索引结构B+树和Hash索引\nInnoDB，MyISAM：默认是B+树\nMemory引擎：默认Hash索引\nHASH索引等值查询很快，计算的hash值与对应的行指针一并存入表中，哈希碰撞的元素以链表的形式相连。也不支持排序，以及模糊查询，并且由于散列算法，键值对的存储是无序的，所以不支持范围查询。\nB+树索引考虑到IO时十分高昂的操作，且数据库动辄百万级数据量，所以当一次IO时，常常以页作为单位来读取数据，当读取一页的数据至内存缓冲区时，实际上才发生了一次IO，所以控制IO的次数对于索引效率的提升，至关重要。\nB+树的特点：\n\n除叶子结点外的子节点：只起到索引的作用，仅存储指针，不存储信息\n所有信息存储于叶子结点，所有叶子结点在底部链接形成一个双向链表（范围查询）\n\n在InnoDB中，叶子节点的容量默认为一页16KB\n叶子节点结构：页目录（主键）+用户数据区域（单向链表，通过主键排序，在插入数据的时候便会排序）\n非叶子节点结构：页指针+指向的该页的最小主键值\n主键索引(聚簇索引)\n二级索引(辅助索引)同样是B+树，以非主键而是以自定义规则的索引，以满足不同的查询需求，属于非聚集索引。\n叶子节点的用户数据区不再存储完整记录，而是存储主键+部分记录。\n所以使用辅助索引有时候需要进行回表，即部分记录无法满足查询需求，需要使用主键来重新到主键索引查找。\n联合索引使用表中的多个字段创建索引，就是 联合索引，也叫 组合索引 或 复合索引\n什么情况下设置了复合索引，但不会使用？\n\n没有符合最左匹配原则\n字段进行了隐私数据类型转化\n引擎估算走辅助索引的时间反而比全表扫描的时间更长\n\n什么是最左匹配原则？\n对于复合索引，若有字段123，若查询时省略字段1，则无法使用索引。\n因为数据库依据联合索引最左的字段来构建 B+ 树，叶子节点的排序是以字段123的顺序进行的，只有先确定了前一个（左侧的值）后，才能确定下一个值。a有序，b才能有序，若a省略，则无法有序查找bc。\n所以，我们在使用联合索引时，可以将区分度高的字段放在最左边，这也可以过滤更多数据\n非聚簇索引的优缺点？\n优点：更新代价比聚集索引要小 。非聚集索引的更新代价就没有聚集索引那么大了，非聚集索引的叶子节点是不存放数据的\n缺点：\n\n跟聚集索引一样，非聚集索引也依赖于有序的数据\n可能会二次查询(回表) :这应该是非聚集索引最大的缺点了。 当查到索引对应的指针或主键后，可能还需要根据指针或主键再到数据文件或表中查询\n\n聚簇索引的优缺点？\n优点：聚集索引的查询速度非常的快，因为整个 B+树本身就是一颗多叉平衡树，叶子节点也都是有序的，定位到索引的节点，就相当于定位到了数据\n缺点：\n\n依赖于有序的数据 ：因为 B+树是多路平衡树，如果索引的数据不是有序的，那么就需要在插入时排序，如果数据是整型还好，否则类似于字符串或 UUID 这种又长又难比较的数据，插入或查找的速度肯定比较慢。\n更新代价大 ： 如果对索引列的数据被修改时，那么对应的索引也将会被修改，而且聚集索引的叶子节点还存放着数据，修改代价肯定是较大的，所以对于主键索引来说，主键一般都是不可被修改的\n\nMYSQL默认使用B+树，为啥要用B+树，不用B树？\n因为两者都是存储于磁盘，而IO是花销很大的操作，InnoDB每次申请磁盘空间时都会申请若干条连续的磁盘块来组成一页，并放入内存，读取索引，放回磁盘，不断重复，直到找到数据。\n所以如果每次申请到的数据都能有助于定位到所需数据，这将会减少IO次数，提高查询效率。\n对于B树，因为B树的每一个结点都会存储键，指针和数据，每个磁盘块的信息存储能力有限，树的高度也会更高，增加了IO次数，所以B树的查询效率波动很大。\n而B+树的非叶子结点只存储键，所以B+树的非叶子结点可以存储更多的信息，降低了树高度，平均一次IO可以获取更多索引，所以B+树更适合外存索引，且查询效率更稳定\n其中在 MySQL 底层对 B+ 树进行进一步优化：\n叶子节之间是双向链表，节点内部是单向链表，且在链表的头结点和尾节点也是循环指向的。（范围查询的关键）\n为什么不用红黑树？\n无论是二叉树还是红黑树，都会因为树的深度过深而导致IO次数变多，效率不高\nInnoDB一颗高度为3的B+树可以存放多少行数据？\nInnoDB的一页大小为16k，若一行数据的大小为1k，那么可以存储16行数据\n若主键ID为bigint型，8字节，指针为6字节，总大小为14字节，那么一页可以存储1170个指针\n所以数据量大约为1170  * 1170 *  16&#x3D; 大约两千万\nMySQL的锁的类型按锁的属性分共享锁：即读锁\n排他锁：即写锁\n按锁的粒度分行级锁：锁住一行或者多行记录\n表级锁：给整个表加锁\n页级锁：介于行级锁和表锁的一种锁，一次锁定相邻的一组记录\n记录锁：行级锁的一种，锁住一条记录，避免数据在查询时被修改的不可重复读问题\n间隙锁：行级锁的一种，只出现在Repeatable read的事务中，解决了幻读的问题\n临键锁：InnoDB的行锁默认算法，就是记录锁和间隙锁的结合版，会锁住查询的记录，同时也会锁住范围内的所有间隙空间\n按锁的状态分意向共享锁\n意向排他锁\nMySQL的主从同步MySQL内建的复制功能是构建大型，高性能应用程序的基础。\n将MySQL的数据分布到多个系统上去，这种分布的机制，是通过将MySQL的某一台主机的数据复制到其它主机（slave）上，并重新执行一遍来实现。\n复制过程中一个服务器充当主服务器，而一个或多个其它服务器充当从服务器。\n主服务器将更新写入二进制日志文件，并维护文件的一个索引以跟踪日志循坏，这些日志可以记录发送到从服务器的更新。\n当一个从服务器连接主服务器时，它通知主服务器从服务器在日志中读取的最后一次成功更新的位置。从服务器接收从那时起发生的任何更新，然后封锁并等待主服务器通知的更新。\nMySQL支持哪些复制\n基于语句的复制：在主服务器上执行的sql语句，在从服务器上执行同样的语句。mysql默认采用基于语句的复制，效率比较高。一旦发现没法精确复制时，会自动选着基于行的复制。\n基于行的复制：把改变的内容复制过去，而不是把命令在从服务器上执行一遍。从mysql 5.0开始支持\n混合类型的复制：默认采用基于语句的复制，一旦发现基于语句的无法精确复制时，就会采用基于行的复制\n\n为什么需要主从同步\n若出现锁表不能读的情况，此时可以使用主从复制，让主库负责写，从库负责读，这样就不影响业务的正常运行\n当IO频率越来越大时，业务量越来越大时，单机已无法满足，此时多库的处理可以提高IO的性能\n\n日志（binlog，redo log和undo log）MySQL 日志 主要包括错误日志、查询日志、慢查询日志、事务日志、二进制日志几大类。其中，比较重要的还要属二进制日志 binlog（归档日志）和事务日志 redo log（重做日志）和 undo log（回滚日志）\n\n1、redo log（重做日志）redo log（重做日志）是InnoDB存储引擎独有的，它让MySQL拥有了崩溃恢复能力\nMySQL 中数据是以页为单位，你查询一条记录，会从硬盘把一页的数据加载出来，加载出来的数据叫数据页，会放入到 Buffer Pool 中。\n后续的查询都是先从 Buffer Pool 中找，没有命中再去硬盘加载，减少硬盘 IO 开销，提升性能。\n更新表数据的时候，也是如此，发现 Buffer Pool 里存在要更新的数据，就直接在 Buffer Pool 里更新。\n然后会把“在某个数据页上做了什么修改”记录到重做日志缓存（redo log buffer）里，接着刷盘到 redo log 文件里\n\n刷盘时机InnoDB 存储引擎为 redo log 的刷盘策略提供了 innodb_flush_log_at_trx_commit 参数，它支持三种策略：\n\n0 ：设置为 0 的时候，表示每次事务提交时不进行刷盘操作\n1 ：设置为 1 的时候，表示每次事务提交时都将进行刷盘操作（默认值）\n2 ：设置为 2 的时候，表示每次事务提交时都只把 redo log buffer 内容写入 page cache\n\ninnodb_flush_log_at_trx_commit 参数默认为 1 ，也就是说当事务提交时会调用 fsync 对 redo log 进行刷盘\n另外，InnoDB 存储引擎有一个后台线程，每隔1 秒，就会把 redo log buffer 中的内容写到文件系统缓存（page cache），然后调用 fsync 刷盘\n也就是说，一个没有提交事务的 redo log 记录，也可能会刷盘\n除了后台线程每秒1次的轮询操作，还有一种情况，当 redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动刷盘\n\n\n为0时，如果MySQL挂了或宕机可能会有1秒数据的丢失\n\n为1时， 只要事务提交成功，redo log记录就一定在硬盘里，不会有任何数据丢失。\n如果事务执行期间MySQL挂了或宕机，这部分日志丢了，但是事务并没有提交，所以日志丢了也不会有损失\n\n为2时， 只要事务提交成功，redo log buffer中的内容只写入文件系统缓存（page cache）。\n如果仅仅只是MySQL挂了不会有任何数据丢失，但是宕机可能会有1秒数据的丢失\n\n\n日志文件组硬盘上存储的 redo log 日志文件不只一个，而是以一个日志文件组的形式出现的，每个的redo日志文件大小都是一样的。\n比如可以配置为一组4个文件，每个文件的大小是 1GB，整个 redo log 日志文件组可以记录4G的内容。\n它采用的是环形数组形式，从头开始写，写到末尾又回到头循环写，如下图所示\n\n在个日志文件组中还有两个重要的属性，分别是 write pos、checkpoint\n\nwrite pos 是当前记录的位置，一边写一边后移\n\ncheckpoint 是当前要擦除的位置，也是往后推移\n\n\n\n每次刷盘 redo log 记录到日志文件组中，write pos 位置就会后移更新。\n\n每次 MySQL 加载日志文件组恢复数据时，会清空加载过的 redo log 记录，并把 checkpoint 后移更新。\n\nwrite pos 和 checkpoint 之间的还空着的部分可以用来写入新的 redo log 记录\n\n如果 write pos 追上 checkpoint ，表示日志文件组满了，这时候不能再写入新的 redo log 记录，MySQL 得停下来，清空一些记录，把 checkpoint 推进一下\n\n\n为什么要用redo log现在我们来思考一个问题： 只要每次把修改后的数据页直接刷盘不就好了，还有 redo log 什么事？\n它们不都是刷盘么？差别在哪里？\n1 Byte = 8bit\n1 KB = 1024 Byte\n1 MB = 1024 KB\n1 GB = 1024 MB\n1 TB = 1024 GB\n\n实际上，数据页大小是16KB，刷盘比较耗时，可能就修改了数据页里的几 Byte 数据，有必要把完整的数据页刷盘吗？\n而且数据页刷盘是随机写，因为一个数据页对应的位置可能在硬盘文件的随机位置，所以性能是很差。\n如果是写 redo log，一行记录可能就占几十 Byte，只包含表空间号、数据页号、磁盘文件偏移量、更新值，再加上是顺序写，所以刷盘速度很快。\n所以用 redo log 形式记录修改内容，性能会远远超过刷数据页的方式，这也让数据库的并发能力更强\n2、binlog（归档日志）redo log 它是物理日志，记录内容是“在某个数据页上做了什么修改”，属于 InnoDB 存储引擎。\n而 binlog 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID&#x3D;2 这一行的 c 字段加 1”，属于MySQL Server 层。\n不管用什么存储引擎，只要发生了表数据更新，都会产生 binlog 日志\nbinlog的作用：主从同步\n可以说MySQL数据库的数据备份、主备、主主、主从都离不开binlog，需要依靠binlog来同步数据，保证数据一致性\n\nbinlog会记录所有涉及更新数据的逻辑操作，并且是顺序写\n记录格式binlog 日志有三种格式，可以通过binlog_format参数指定。\n\nstatement\nrow\nmixed\n\n指定statement，记录的内容是SQL语句原文，比如执行一条update T set update_time=now() where id=1，记录的内容如下\n\n同步数据时，会执行记录的SQL语句，但是有个问题，update_time=now()这里会获取当前系统时间，直接执行会导致与原库的数据不一致。\n为了解决这种问题，我们需要指定为row，记录的内容不再是简单的SQL语句了，还包含操作的具体数据，记录内容如下\n\nrow格式记录的内容看不到详细信息，要通过mysqlbinlog工具解析出来。\nupdate_time=now()变成了具体的时间update_time=1627112756247，条件后面的@1、@2、@3 都是该行数据第 1 个~3 个字段的原始值（假设这张表只有 3 个字段）。\n这样就能保证同步数据的一致性，通常情况下都是指定为row，这样可以为数据库的恢复与同步带来更好的可靠性。\n但是这种格式，需要更大的容量来记录，比较占用空间，恢复与同步时会更消耗IO资源，影响执行速度。\n所以就有了一种折中的方案，指定为mixed，记录的内容是前两者的混合。\nMySQL会判断这条SQL语句是否可能引起数据不一致，如果是，就用row格式，否则就用statement格式\n写入机制binlog的写入时机也非常简单，事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中。\n因为一个事务的binlog不能被拆开，无论这个事务多大，也要确保一次性写入，所以系统会给每个线程分配一个块内存作为binlog cache\n我们可以通过binlog_cache_size参数控制单个线程 binlog cache 大小，如果存储内容超过了这个参数，就要暂存到磁盘（Swap）\n\n\n上图的 write，是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快\n上图的 fsync，才是将数据持久化到磁盘的操作\n\nwrite和fsync的时机，可以由参数sync_binlog控制，默认是0。\n\n为0的时候，表示每次提交事务都只write，由系统自行判断什么时候执行fsync\n\n虽然性能得到提升，但是机器宕机，page cache里面的 binlog 会丢失。\n为了安全起见，可以设置为1，表示每次提交事务都会执行fsync，就如同 redo log 日志刷盘流程 一样\n\n最后还有一种折中方式，可以设置为N(N&gt;1)，表示每次提交事务都write，但累积N个事务后才fsync\n\n\n3、两阶段提交redo log（重做日志）让InnoDB存储引擎拥有了崩溃恢复能力。\nbinlog（归档日志）保证了MySQL集群架构的数据一致性\n虽然它们都属于持久化的保证，但是侧重点不同。\n在执行更新语句过程，会记录redo log与binlog两块日志，以基本的事务为单位，redo log在事务执行过程中可以不断写入，而binlog只有在提交事务时才写入（刷盘），所以redo log与binlog的写入时机不一样\n\n如果binlog在写入时出了问题，而redo log无问题，则在MySQL恢复数据时主的值为redo中的操作值，而其他如SQL从的值则会跟随binlog恢复而无改变造成数据不一致的问题\n为了解决两份日志之间的逻辑一致问题，InnoDB存储引擎使用两阶段提交方案\n原理很简单，将redo log的写入拆成了两个步骤prepare和commit，这就是两阶段提交\n\n使用两阶段提交后，写入binlog时发生异常也不会有影响，因为MySQL根据redo log日志恢复数据时，发现redo log还处于prepare阶段，并且没有对应binlog日志，就会回滚该事务\n如果redo log设置commit阶段发生异常，那会不会回滚事务呢？\n\n并不会回滚事务，它会执行上图框住的逻辑，虽然redo log是处于prepare阶段，但是能通过事务id找到对应的binlog日志，所以MySQL认为是完整的，就会提交事务恢复数据\n4、undo log我们知道如果想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行回滚，在 MySQL 中，恢复机制是通过 回滚日志（undo log） 实现的，所有事务进行的修改都会先记录到这个回滚日志中，然后再执行相关的操作。如果执行过程中遇到异常的话，我们直接利用 回滚日志 中的信息将数据回滚到修改之前的样子即可！并且，回滚日志会先于数据持久化到磁盘上。这样就保证了即使遇到数据库突然宕机等情况，当用户再次启动数据库的时候，数据库还能够通过查询回滚日志来回滚将之前未完成的事务。\n另外，MVCC 的实现依赖于：隐藏字段、Read View、undo log。在内部实现中，InnoDB 通过数据行的 DB_TRX_ID 和 Read View 来判断数据的可见性，如不可见，则通过数据行的 DB_ROLL_PTR 找到 undo log 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 Read View 之前已经提交的修改和该事务本身做的修改\n5、总结MySQL InnoDB 引擎使用 redo log(重做日志) 保证事务的持久性，使用 undo log(回滚日志) 来保证事务的原子性。\nMySQL数据库的数据备份、主备、主主、主从都离不开binlog，需要依靠binlog来同步数据，保证数据一致性\nMVCCMulti-Version Concurrency Control多版本并发控制，实现对数据库的并发访问，实现读写冲突不加锁，非阻塞并发读。\n数据库的并发有三种场景\n\n读读：不存在任何问题，不需要并发控制\n读写：有线程安全问题，可能会造成脏读，幻读，不可重复读等问题\n写写：有线程安全问题，可能存在更新丢失的问题\n\nMVCC的实现原理就是为事务分配单项增长的时间戳，为每个修改保存一个版本，版本与时间戳相关联，解决了脏读，幻读，不可重复读的问题，但是不能解决更新丢失的问题，可以认为MVCC是行级锁的一个变种，但是它在很多情况下避免了加锁操作，因此开销更低\n当前读也叫锁定读Locking Read，读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁，比如update 、delete 、insert\n快照读也叫普通读Consistent Read，就是单纯的select语句，但不包括for update，就是不加锁的非阻塞读，前提是不使用serializable的隔离级别，实现原理即MVCC\n实现原理隐藏字段每行记录除了自定义的字段外，还有数据库隐式定义的字段\nDB_TRX_ID6字节，最近修改事务的ID，即创建这条记录或者最后一次修改这条记录的事务ID\nDB_ROLL_PTR\n7字节，回滚指针，指向这条记录的上一个版本，用于配合undolog\nDB_ROW_ID\n6字节，隐藏的主键，如果数据表没有主键，innoDB就会自动生成一个row_id\nundolog即回滚日志，即进行插入，更新，删除操作后生成的记录链\n当进行insert时，产生的undolog只在事务回滚的时候需要，可以在事务提交后被丢弃\n当进行update和delete操作时，undolog不仅在事务回滚时需要，在快照读时也需要，所以必须保留，只有在回滚或者快照读不涉及该日志时，undolog才会被purge线程清除（若delete_bit为true，且DB_TRX_ID相对于purge线程的read view可见，那么这条记录就一定可以被清除）\n\n由上图可知，不同事物或者相同事物对同一条记录的修改，就会导致该记录的undolog生成一条记录版本的线性链，链首就是最新的旧记录，链尾就是最早的旧记录\nRead ViewRead View是实现repeatable read的基础，当事务进行快照读的时候会产生一个读视图，用来对当前事务的可见性进行判断，也就是说，事务会将生成的ReadView作为条件来判断当前事务能够看见哪个版本的数据，有可能读到最新的数据，也有可能读到undolog里面的某个版本的数据。\nReadView的可见性算法ReadView的三个全局属性：\n\ntrx_list：事务列表，即视图生成时刻系统正活跃未提交的事务ID\nup_limit_id：记录事务列表中ID最小的ID\nlow_limit_id：视图生成时刻系统尚未分配的下一个事务（例如事务123正在活跃，事务4已提交，此时下一个事务ID就是5）\n\n具体的算法如下\n\n取出当前最新记录的DB_TRX_ID，即当前事务ID\n比较DB_TRX_ID&lt;up_limit_id，如果小于则说明当前事务能看见DB_TRX_ID所在的记录，如果大于等于就进入下一个判断\n判断DB_TRX_ID&gt;&#x3D;low_limit_id，如果大于等于，代表DB_TRX_ID所在的记录在readView生成后才出现，对于当前事务肯定不可见，如果小于，进入下一个判断\n判断DB_TRX_ID是否在活跃事务列表中，如果在，说明在视图生成时刻，该事务还没有提交，当前事务无法看见。若不在，说明以及提交，修改的结果可以看见（除自己以外的活跃trx_id都不可见）\n\nRC，RR级别下的视图在RR级别下某个事务对记录的第一次快照读会创建一个视图，此后在进行快照读时都会使用同一个视图，所以无论是否有其他事务对记录进行了修改，使用的都是这个视图，修改是不可见的，所以实现了可重复读的级别\n在RC级别下，每次快照读都会生成一个新的视图，所以在RC级别下总是可以看见其他事务的提交\n总结：MVCC其实就是在事务进行并发读写时提供一个快照，事务只能看见符合可见性的版本链内的记录，从而实现了并发读写的隔离性。RR的隔离级别解决了幻读问题。\nMySQL调优代码优化：\n\n少使用select*，指定具体字段\n尽量少使用order by排序，而使用联合索引\n减少使用Null，有多个null的可以加默认值\nwhere后少使用函数运算\n避免超过五个以上的表连接\n\nSQL：\n\n对于高频筛选字段可以适当建立索引\n一个表的索引不超过五个\n联合索引，遵守最左匹配原则\n\n","slug":"mySQL","date":"2022-10-25T14:02:31.000Z","categories_index":"","tags_index":"数据库基础","author_index":"Samuel"},{"id":"cd132b199d60085bc82ceffbffeca6fd","title":"netty项目记录","content":"","slug":"netty项目记录——react线程模型简述","date":"2022-10-22T09:16:43.000Z","categories_index":"","tags_index":"netty","author_index":"Samuel"},{"id":"4fe89795a63627b54cad79ec28758dc1","title":"netty基础知识","content":"Netty和Tomcat有什么区别？Netty是一个基于NIO的异步网络通信框架，性能高，封装了原生NIO，降低了编码复杂度。\nTomcat是一个Web服务器，是一个Servlet容器，内部只运行Servlet程序并处理HTTP请求。\nNetty封装的是IO模型，用于处理网络数据的传输，不关心具体的协议，其定制性更高\nreactor线程模型reactor就是IO多路复用（NIO）+线程池的结合优化版\nreactor线程模型：主要有四个角色\n\nReactor：把IO事件分配给对应的handler处理，就是IO多路复用的select实现，即轮询监听\nAcceptor：处理客户端连接事件，创建Handler对象\nHandler：将自身与事件绑定，执行非阻塞读、写任务，负责channel的读入，业务处理完成后，负责将结果写出channel\nworker：用来处理handler传来的业务的线程\n\n其中1，2，3存放于主线程中，也称为bossGroup\n4存放于从线程，也就是线程池中，也称为workerGroup\n单reactor-多线程\n主从reactor-多线程这种模型下是把Reactor线程拆分了mainReactor和subReactor两个部分\nmainReactor只处理连接事件，读写事件交给subReactor来处理。业务逻辑还是由线程池来处理\n\n什么是零拷贝应用程序把内核中的一块数据转移到内核中的另一个区域去时，不需要经过先复制到用户空间，再转移到目标内核区域，而是实现直接转移，系统调用transferTo()\nNetty的线程模型是怎么样的Netty同时支持Reactor单线程模型，多线程模型，主从多线程模型，用户可以配置参数在这三种模型之间切换\n服务端启动时，通常会创建两个NioEventLoopGroup实例，对应两个独立的Reactor线程池，bossGroup负责处理客户端的连接请求，workerGroup负责处理IO相关的操作，执行任务等。用户可以根据ServerBootstrap启动类选择参数配置线程模型。\nNetty为什么高性能？\nNIO模型，用最少的资源完成最多的任务\n内存零拷贝，减少不必要的拷贝造成资源浪费，实现更高效率的传输\n串行化处理读写：消息的处理尽可能在同一个线程内完成，避免切换线程的花销，避免多线程竞争和同步锁。调整NIO线程池的线程参数，可以同时启动多个串行化的线程，相比于多线程竞争机制性能更优。\n支持protobuf：protobuf (protocol buffer) 是谷歌内部的混合语言数据标准。通过将结构化的数据进行序列化(串行化)，用于通讯协议、数据存储等领域的语言无关、平台无关、可扩展的序列化结构数据格式。是一个高性能的编解码框架，序列化数据后数据更小，传输速度更快，安全性也更高，netty可以直接在handler内添加protobuf编码解码器。\n内存池设计，申请的内存可以重用\n\n粘包现象：发送abc和def，结果接收到abcdef\n原因：\n\n应用层：接收方的bytebuf设置太大（默认1024）\nTCP滑动窗口足够大，且接收方处理不及时\nTCP的Nagle算法：为了减少广域网的小分组数目，从而减小网络拥塞的出现，会造成粘包。\n\nnetty的解决方案：\n\n短连接，发完一次消息后便断开连接。下一次发消息的时候再次建立连接，重置了缓冲区\n设置合理的缓冲区\n\n半包现象：发送abcdef接收到abc和def\n原因：\n\n应用层：bytebuf过小\nTCP滑动窗口过小\n链路层：MSS限制\n\nnetty解决方案\nFixedLengthFrameDecoder定长帧解码器：固定收到的帧的大小，若收到半包，则延迟交付，直到收到其他消息满足大小，再交付\nLineBasedFrameDecoder行帧解码器：根据特定字符来区分完整的信息，避免半包\nLengthFiledBasedFrameDecoder ：指定内容长度，偏移量，从第几个字节开始读，跳过几个字节再读，从而精准读取内容避免半包\n","slug":"netty基础知识","date":"2022-10-22T08:35:26.000Z","categories_index":"","tags_index":"netty","author_index":"Samuel"},{"id":"a81dd39014b037511fb6ceaf21738564","title":"进程，线程和协程","content":"进程an instance of a computer program that is being executed\n进程是程序的一次执行，是一个程序及其数据，运行环境，在处理机上运行时所发生的活动。\n与程序不同的是，进程具有动态性和生命周期，是系统进行资源分配和调度的独立单位。\n进程的结构：\n\n控制块\n数据段\n程序段\n\n线程的Linux实现而在windows中，线程被抽象为一种比进程更轻量级的可以独立处理事件的单元，支持真线程的系统一定要有线程控制块：TCB，操作系统既要进行进程管理，又要进行线程管理，设计层面是比较复杂的。windows上一定会有相关线程操作的系统调用接口。\n而在Linux中却不一样，从内核的角度来看，并没有线程这个概念，Linux把所有的线程都当作进程来处理，内核也并没有定义独特的调度算法和数据结构来实现线程，线程就是一个与父进程共享资源的进程而已，Linux在创建线程时，会直接创建进程并分配task_struct，同时指定共享资源，所以对于内核来说，它就是进程，线程在Linux中是一个实现进程共享资源的机制。\n在 Linux 中每一个进程都由 task_struct 数据结构来定义。task_struct 就是我们通常所说的 PCB，当我们调用 fork()  时，系统会为我们产生一个 task_struct 结构。然后从父进程，那里继承一些数据，并将PCB插入任务队列中，以待进行进程管理。\n对于线程来说，需要在clone()中指定共享资源\nclone(CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND,0);\n//VM：共享地址空间\n//FS：共享文件系统信息\n//FILES:共享打开的文件\n//SIGHAND：共享阻断信号\n\n而一个普通的fork()就是\nclone(SIGCHLD,0);\n\n内核线程内核需要经常在后台处理操作，这些任务可以交给内核线程来处理。内核线程就是独立运行在内核空间的标准进程。\n内核线程没有独立的地址空间。其指向地址空间的mm指针设置为null，只存在于内核空间\ntask_struct结构中的mm指针：指向进程所拥有的内存描述符\n多线程的优点：并发性提高，占用资源比进程更少。\n多线程缺点：存在大量临界资源，势必会造成各种互斥。编程难度提高，线程的调度和同步需要更多额外的开销。\n线程的通信方式管道：分为匿名管道和命名管道，实质是一个缓冲区，管道的作用正如其名，需要通信的两个进程在管道的两端，进程利用管道传递信息。管道对于管道两端的进程而言，就是一个文件，但是这个文件比较特殊，它不属于文件系统并且只存在于内存中。\n信号signal：信号是软件层次上对中断机制的一种模拟，是一种异步通信方式，进程不必通过任何操作来等待信号的到达。信号可以在用户空间进程和内核之间直接交互，内核可以利用信号来通知用户空间的进程发生了哪些系统事件。\n信号量Semaphore：信号量实质上就是一个标识可用资源数量的计数器，它的值总是非负整数。而只有0和1两种取值的信号量叫做二进制信号量（或二值信号量），可用用来标识某个资源是否可用。\n共享内存:使得多个进程可以可以直接读写同一块内存空间，是针对其他通信机制运行效率较低而设计的。为了在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率\n消息队列:消息队列是消息的链表，具有特定的格式,存放在内存中并由消息队列标识符标识，并且允许一个或多个进程向它写入与读取消息\n套接字:不同客户端的进程间的通信方式\n用户空间和内核空间操作系统为了支持多个应用同时运行，需要保证不同进程之间相对独立，一个进程的崩溃不会影响其他进程，恶意进程不能读取其他进程的数据。于是内存空间被划分为两部分，内核空间和用户空间，内核空间的代码和数据拥有更高的权限，而用户空间的代码不能访问高级别的空间，因此保护了操作系统自身的内存数据。\n用户态：指进程运行在用户地址空间中的状态，被执行的代码要受到 CPU 的很多检查。进程只能访问地址空间中规定的页面的虚拟地址。\n内核态：指进程运行在内核地址空间中的状态，此时 CPU 可以执行任何指令。运行的代码也不受任何的限制，可以自由地访问任何有效地址，也可以直接进行端口的访问。所有系统资源的管理都是在内核态去做的，比如创建一个线程需要分配资源，就需要进入内核态，来完成。\n什么是进程上下文在Linux中，用户程序装入系统形成一个进程的实质是系统为用户程序提供一个完整的运行环境\n进程的运行环境是由它的程序代码和程序运行所需要的数据结构以及硬件环境组成的，进程的运行环境主要包括：\n\n进程空间中的代码和数据、各种数据结构、进程堆栈和共享内存区等。\n环境变量：提供进程运行所需的环境信息。\n系统数据：进程空间中的对进程进行管理和控制所需的信息，包括进程任务结构体以及内核堆栈等。\n进程访问设备或者文件时的权限。\n各种硬件寄存器。\n地址转换信息。\n\n从以上组成情况可以看到，进程的运行环境是动态变化的，尤其是硬件寄存器的值以及进程控制信息是随着进程的运行而不断变化的。在Linux中把系统提供给进程的的处于动态变化的运行环境总和称为进程上下文。\n系统中的每一个进程都有自己的上下文。一个正在使用处理器运行的进程称为当前进程(current)。当前进程因时间片用完或者因等待某个事件而阻塞时，进程调度需要把处理器的使用权从当前进程交给另一个进程，这个过程叫做进程切换。\n此时，被调用进程成为当前进程。在进程切换时系统要把当前进程的上下文保存在指定的内存区域（该进程的任务状态段TSS中），然后把下一个使用处理器运行的进程的上下文设置成当前进程的上下文。\n当一个进程经过调度再次使用CPU运行时，系统要恢复该进程保存的上下文。所以，进程的切换也就是上下文切换。\n在系统内核为用户进程服务时，通常是进程通过系统调用执行内核代码，此时内核为用户进程服务，可以说内核在代替当前进程执行某种服务。所以可以认为，内核态就是内核运行在进程上下文中的状态。\n中断上下文：硬件通过触发信号，导致内核调用中断处理程序，进入内核空间。这个过程中，硬件的一些变量和参数也要传递给内核，内核通过这些参数进行中断处理。所谓的“中断上下文”，其实也可以看作就是硬件传递过来的这些参数和内核需要保存的一些其他环境（主要是当前被打断执行的进程环境）\n如何从用户态进入内核态：中断中断是CPU的一个功能：CPU停下工作后，保留现场，自动的转去执行相应的处理程序，CPU的控制权发生改变，处理完该事件后再返回断点继续执行。避免了CPU的轮询检查，而是转换为事件驱动，向CPU发送中断事件，强制让CPU来执行中断处理程序。发生中断，CPU会立即进入内核态，针对不同的中断信号，采取不同的处理方式。**中断是CPU从用户态进入核心态的唯一途径(如系统调用)**。\n硬中断硬中断时由外部事件引起的，具有随机性和突发性，比如键盘，鼠标的输入，磁盘的读写，缺页。硬中断的中断号是由中断控制器提供的，硬中断是可以屏蔽掉的。\n流程如下\n\n外设 将中断请求发送给中断控制器；\n中断控制器 根据中断优先级，有序地将中断号传递给 CPU；\nCPU 终止执行当前程序流，将 CPU 所有寄存器的数值保存到栈中；\nCPU 根据中断号，从中断向量表中查找中断处理程序的入口地址，执行中断处理程序；\nCPU 恢复寄存器中的数值，返回原程序流停止位置继续执行。\n\n软中断（被动）CPU的内部事件或者程序引起的中断，如程序故障，电压故障。\n软中断（主动）也称作系统调用，用户进程主动要求进入内核态。用户进程通过系统调用申请操作系统提供服务。\n 系统调用使用的是一个特别的中断实现的。具体是:调用 int $0x80的汇编指令，将产生向量为0x80的编程异常（软中断）\n软中断模拟了硬中断的处理过程：\n\n无\n无\nCPU 终止执行当前程序流，将 CPU 所有寄存器的数值保存到栈中；\nCPU 根据中断向量，从中断向量表中查找中断处理程序的入口地址，执行中断处理程序；\nCPU 恢复寄存器中的数值，返回原程序流停止位置继续执行。\n\n一个程序开多少线程合适CPU密集型一个完整的请求，IO操作可以在很短的时间内完成，CPU的运算时间占大部分，线程等待时间接近0\n\n单核CPU：一个CPU对应一个线程，且IO时间短，所以不适合使用多线程。若使用多线程，会造成线程竞争，造成不必要的浪费\n多核：如果是多核CPU，就可以最大化利用CPU的核心数，使用并发编程来提高效率。理论上的线程数量就等于CPU的核数，但是一般会设置为核数+1，这个额外的线程可以保证线程因为缺页中断或者其他原因暂停而不会导致CPU中断工作\n\nIO密集型一个完整请求，除了CPU的运算操作，还有许多IO操作要做，也就是说，IO操作占很大一部分，等待时间较长。\n理论最佳线程数：CPU核心数 * （1&#x2F;CPU利用率），CPU利用率&#x3D;1+（IO耗时&#x2F;CPU耗时）\n如果几乎全是IO耗时，那么就可以说是2N，但是一般也有一个backup，也就是2N+1\n创建线程有哪些方式有四种方式\n继承Thread类\n定义thread类的子类，并重写run方法，该方法的方法体就是线程需要完成的任务，run方法也称为线程执行体。\n创建Thread类的实例，也就是创建了线程对象\n启动线程，即调用线程的start方法\n\n实现Runnable接口\n定义Runnable接口的实现类，重写run方法，run方法同样是线程执行体\n创建实现类的实例，并用这个实例作为Thread类的target来创建Thread对象，这个Thread对象便是线程对象\n启动线程，调用start方法\n\n使用Callable和future创建future接口是jdk1.5引入的，可以用来接收callable接口里call方法的返回值\n有一个实现类futureTask，实现了future和runnable接口，因此可以作为thread类的target\n\n创建callable接口的实现类，并实现call方法，然后创建该实现类的实例\n使用futureTask类来包装callable对象\n使用futureTask对象作为thread对象的target创建并启动线程\n使用futureTask对象的get方法来获取子线程执行结束后的返回值\n\ncall方法比run方法更加强大：可以有返回值，可以抛出异常\n使用executor框架JDK1.5引入的executor框架最大的优点就是把任务的提交和执行解耦\n开发者只需描述好要只需的任务，然后提交即可\n\n创建一个executorService\n若有返回值，将写好的runnable实例或者callable实例作为target submit即可，返回值是一个future对象，所以可以使用get方法获取返回值\n若无返回值，直接使用execute方法即可\n\nexecutor框架的内部使用了线程池的机制，使用线程池性能更好，节约开销\n线程的生命周期创建当使用new关键字创建了一个线程之后，该线程就处于一个新建状态，此时它和其他java对象一样，仅仅被分配了内存，并初始化了成员变量值。没有线程的动态特征，也不会执行线程的执行体\n就绪当调用start方法后，该线程处于就绪状态。JVM会为其创建虚拟机栈和PC，处于这个状态表示线程可以运行了，等待被调度执行\n运行在就绪状态下，若被OS调度，就会进入运行状态。当时间片用完或者调用线程让步时，回到就绪状态\n阻塞\n等待阻塞：线程执行wait方法，JVM会将其放入等待池中，此时线程会释放持有的锁\n同步阻塞：即被synchronized修饰的代码块被其他线程拿到，本线程获取同步锁失败，就会被JVM放入锁池中\n其他阻塞：线程执行sleep或者join方法，或者发出了IO请求。当sleep超时，join等待线程终止或者等待超时，IO完毕，线程就会重新转入就绪状态\n\nsleep：线程睡眠，使线程转入阻塞状态一定时间\nwait：线程等待，使线程放入等待池，指导其他线程调用notify或者notifyall方法来唤醒，此时线程会尝试获取锁，若成功，转为就绪状态，若失败，则进入锁池等待锁的释放。\nyield：线程让步，暂停当前正在执行的线程对象，回到就绪状态，把执行机会让给优先级相同或者更高的线程\njoin：线程加入，等待其他线程终止，在当前进程中调用另一个指定进程的join方法，则当前进程转入阻塞状态，直到另一个进程运行结束，当前进程再由阻塞转为就绪状态\nnotify：线程唤醒，唤醒被wait阻塞的进程\n死亡\nrun方法执行完成，线程正常结束\n抛出异常\n直接调用stop方法来结束（容易造成死锁）\n\n\n协程协程就是轻量级的线程，即在虚拟机的线程栈和PC的基础上再建立更多的栈和PC\n即虚拟机层面的线程，更加轻量级\nJVM的普通线程：1:1模型即JVM层面创建一个线程，就会向OS申请一个线程\n优点：简单，省事\n缺点：重量级大，需要在JVM和OS两个层面都创建等待队列，依赖于OS的线程调度器，对线程的操作如上下文切换，阻塞，唤醒等都需要等待OS的反馈，效率偏低。\nFiber纤程：M:N模型（go语言的goroutine）在JVM里创建一个自身的线程调度器来模拟OS，以及实现自身的调度算法，最先由GO语言实现。\nM:N模型：JVM或者GO语言虚拟机里面的协程数会远远大于OS层面的线程\n因为虚拟机层面的协程切换的花销要远远小于OS层面的上下文切换或者调度，所以协程的效率比普通线程更好\nJVM本身不支持协程，使用代理技术：在进入JVM之前，Fiber代码折算为线程代码，再进入JVM\nThreadLocal即线程本地变量，使公共变量可以在多个线程内进行隔离访问\nstatic ThreadLocal&lt;Object&gt; TL = new ThreadLocal&lt;&gt;();\n若线程1对TL设置内容Value1，此时线程2是无法通过get方法拿到Value1的\n常用方法及实现原理set (T value)：设置线程本地变量的内容\npublic void set(T value) &#123;\n    // 获取当前线程\n    Thread t = Thread.currentThread();\n    // 获取当前线程的threadLocals字段\n    ThreadLocalMap map = getMap(t);\n    // 判断线程的threadLocals是否初始化了\n    if (map != null) &#123;\n        //this就是公共变量TL\n        map.set(this, value);\n    &#125; else &#123;\n        // 没有则创建一个ThreadLocalMap对象进行初始化\n        createMap(t, value);\n    &#125;\n&#125;\n\n每一个thread对象里都会自带一个threadLocals对象，而这个对象就是ThreadLocalMap的实例\nThreadLocalMap就是一个存储Entry即键值对的数组，初始化时threadLocals会设置为null\nThreadLocal.ThreadLocalMap threadLocals = null\n\n所以set方法并不是往tl对象里面装内容，而是以tl的引用为K，value为V，生成Entry装入该线程的map中\nget()：获取线程本地变量的内容\npublic T get() &#123;\n    Thread t = Thread.currentThread();\n    ThreadLocalMap map = getMap(t);\n    if (map != null) &#123;\n        // 获取ThreadLocal对应保留在Map中的Entry对象\n        ThreadLocalMap.Entry e = map.getEntry(this);\n        if (e != null) &#123;\n            @SuppressWarnings(\"unchecked\")\n            // 获取ThreadLocal对象对应的值\n            T result = (T)e.value;\n            return result;\n        &#125;\n    &#125;\n    // map还没有初始化时创建map对象，并设置null，同时返回null\n    return setInitialValue();\n&#125;\n\n\nEntry继承了弱引用类，说明这里的每一个Entry都是一个弱引用，弱引用的使用可以避免内存泄漏\n\n\nThreadLocal对象的作用：\n\n引用作为key来进行查找entry的值\n维护map，ThreadLocalMap的设置删除都是由ThreadLocal来进行的\n\n在ThreadLocalMap的set&#x2F;getEntry中，会对key进行判断，如果key为null，那么value也会被设置为null，这样即使在忘记调用了remove方法，当ThreadLocal被销毁时，对应value的内容也会被清空，避免了内存泄漏。\n为什么ThreadLocal包装的变量可以实现线程隔离？thread对象内不方便手动添加成员变量，所以就使用ThreadLocal来实现成员变量的效果。ThreadLocal对象本身不存储值，而是作为一个key来查找不同线程中的map的value，不同线程以ThreadLocal的弱引用作为key的Entry里的Value肯定都是不同的，每一个线程内的map都保存了一份副本各玩儿各的，所以就实现了线程隔离。\nThreadLocal的应用场景\nSpring的@Transaction事务声明的注解中就使用ThreadLocal保存了当前的Connection对象，避免在本次调用的不同方法中使用不同的Connection对象。\n依赖于ThreadLocal本身的特性，对于需要进行线程隔离的变量可以使用ThreadLocal进行封装\n\n","slug":"协程","date":"2022-10-20T08:53:01.000Z","categories_index":"","tags_index":"Java基础知识","author_index":"Samuel"},{"id":"2b0f61f6bf7b985f1f4587a53651bb18","title":"synchronized,volatile与lock","content":"Synchronized同步锁，保证在同一时刻，被修饰的代码块或方法只有一个线程执行，以达到并发安全的效果\n同步锁是解决并发问题最简单的一种方法，直接给代码块加上此关键字即可\n在JDK1.5之前，Synchronized是一个重量级锁，在以后的版本经过改进后成重量级减小\nsynchronized的作用主要有三个：\n\n原子性：确保线程互斥地访问同步代码；\n可见性：保证共享变量的修改能够及时可见，其实是通过Java内存模型中的“对一个变量unlock操作之前，必须要同步到主内存中；如果对一个变量进行lock操作，则将会清空工作内存中此变量的值，在执行引擎使用此变量前，需要重新从主内存中load操作或assign操作初始化变量值” 来保证的；\n有序性：有效解决重排序问题，即 “一个unlock操作先行发生(happen-before)于后面对同一个锁的lock操作”；\n\n底层实现：对象在JVM的内存布局为：对象头+实例数据+对齐填充\n对象头（12字节）其中有4字节的class pointer和8字节的MarkWord\n后者是实现锁的关键，MarkWord被设计成一个非固定的数据，它会根据对象的状态复用自身的空间，即会随着程序的运行发生变化。MarkWord的最后三字节分别为：1bit记录是否为偏向锁；2bit记录锁标志位。当锁标志位变为00时为轻量级锁，01代表未锁定或者可加偏向锁，10时为重量级锁。\nMonitor对象如果使用Synchronize修饰了一个对象，则MarkWord就会指向一个唯一的Monitor对象，并将标志位改为10，由操作系统提供\nMonitor中有三个变量，分别是Owner、EntryList和WaitSet\nOwner：当线程抢占到锁后，Owner就会指向该线程\nEntryList：当其他线程以自旋形式抢占Owner超过阈值后，便会进入阻塞状态，放入EntryList，等待被唤醒\n具体步骤\nthread0执行synchronize代码的时候，synchronized(obj)的obj对象的markword中ptr_to_heavyweight_monitor（指向monitor的指针）会指向一个monitor对象，执行cas操作将monitor的owner设置为thread0。在字节码中对应monitorenter操作指令\nthread1执行到synchronized代码时,发现obj的markword指向了一个monitor并且owner不为null 并且不为抢锁线程,这时会进入entrylist进行blocked，thread2也一样\nthread0执行完同步代码退出synchronized，把obj markword里的数据还原比如hashcode，这些数据是存在monitor对象中的，然后根据不同的策略去唤醒entrylist的thread1和thread2的blocked线程，两个线程去抢owner。在字节码中对应monitorexit操作指令\n\n偏向锁：当一个线程访问加了同步锁的代码块时，会在对象头中存储当前线程的 ID，后续这个线程进入和退出这段加了同步锁的代码块时，不需要再次加锁和释放锁。而是直接比较对象头里面是否存储了指向当前线程的偏向锁。如果相等表示偏向锁是偏向于当前线程的，就不需要再尝试获得锁了。\n说白了就是消除无竞争情况下的性能消耗，避免一个线程的情况下也去竞争锁，造成浪费资源。\n底层实现原理：\n\n首先获取锁 对象的 MarkWord，判断是否处于可偏向状态。偏向锁状态位0，锁标志01\n如果是可偏向状态，则通过 CAS 操作，把当前线程的 ID 写入到 MarkWorda) 如果 CAS 成功，那么 MarkWord就会记录当前线程的ID。 表示已经获得了锁对象的偏向锁，接着执行同步代码块b) 如果 CAS 失败，说明有其他线程已经获得了偏向锁，这种情况说明当前锁存在竞争，需要撤销已获得偏向锁的线程，并且把它持有的锁升级为轻量级锁（这个操作需要等到全局安全点，也就是没有线程在执行字节码）才能执行\n如果是已偏向状态，需要检查 MarkWord 中存储的线程ID 是否等于当前线程的 线程IDa) 如果相等，不需要再次获得锁，可直接执行同步代码块b) 如果不相等，说明当前锁偏向于其他线程，需要撤销偏向锁并升级到轻量级锁\n\n轻量级锁：线程在执行同步块之前，JVM会先在当前线程的栈桢中创建 一个LockRecord\n然后线程尝试使用CAS将对象头中的MarkWord替换为指向锁记录的指针(即00)，官方称为Displaced Mark Word，谁成功将LockRecord贴上去了，谁就拿到锁了。\n如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。\n轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。\n轻量级锁不进行阻塞，而是使用自旋的方式，自旋虽然提升了响应速度，但是会增大CPU的消耗\n重量级锁：当竞争加剧，比如自旋次数超过某一阈值，就会升级为重量级锁，JDK1.6之前，需要自己进行调优设置自旋阈值，需要参考CPU核数。而以后的版本加入了自适应自旋，由JVM自动控制。\n此时需要向操作系统申请资源，申请mutex，将MarkWord替换为指向mutex的指针，拿到重量级锁\n其他线程进入阻塞队列，等待OS的调度，wait状态的线程不消耗cpu\n阻塞线程需要cpu从用户态转到内核态，代价比较大。而且可能会出现刚阻塞不久，锁就被释放的情况，所以阻塞的方式会降低响应速度\n锁会随着线程的竞争情况逐渐升级，偏向锁 &#x3D;&gt; 轻量级锁 &#x3D;&gt; 重量级锁 。锁可以升级但是不能降级。升级的目的是为了提高获得锁和释放锁的效率。\nVolatileVolatile关键字的作用主要有如下两个：\n\n线程的可见性：当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。\n顺序一致性：禁止指令重排序\n\nVolatile和synchronized的区别\n\nVolatile是轻量级的synchronized，因为它不会引起上下文的切换和调度，所以Volatile性能更好。\nVolatile只能修饰变量，synchronized可以修饰方法，静态方法，代码块，类。\nvolatile仅能实现变量的修改可见性，并不能保证原子性，synchronized则可以保证原子性。\n多线程访问volatile不会发生阻塞，而synchronized会发生阻塞。\nvolatile是变量在多线程之间的可见性，synchronize是多线程之间访问资源的同步性。\n\n如何保证线程的可见性JAVA的内存模型线程之间的共享变量存储在主内存中，而每一个线程都有一个私有的本地内存，local memory存储了该线程读写的共享变量的副本。所以当一个线程在本地内存更新共享变量的副本后，需要重新写入主内存。\n如何将新值刷新到主内存中：\nCPU寄存器-&gt;Cache-&gt;Main memory，写缓冲区可以避免处理器停顿下来等待写入数据而造成的延迟，并且写缓冲区可以合并多次写，减少对内存总线的占用。\n但是在写入主内存之前，另外一个线程是看不到的，所以就需要volatile关键则来保证可见性\n当线程对volatile修饰的变量进行写操作时，汇编指令会多出一个lock前缀，这就是内存屏障，而在多核心环境下，这个前缀会对应两个操作：\n\n将当前缓存行的数据立即写回系统内存\n这个写回内存的操作会使其他cpu里缓存的副本无效化\n\n这就是缓存一致性协议，每个处理器通过嗅探在总线传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，从而需要重新从系统内存中读取数据。\n所以多核心环境下，每一个线程读取被volatile修饰的变量时，都必须在主内存中读取最新的结果，而不是使用local memory内的数据，这样保证了一个线程修改变量的结果其他线程都是可知的，保证了线程的可见性。\n如何禁止指令重排同样依赖于lock前缀，即内存屏障实现\n编译器不会对volatile读与volatile读后面的任意内存操作重排序；\n编译器不会对volatile写与volatile写前面的任意内存操作重排序。\n\n\nLocksynchronized存在一些问题：\n\nNonfairSync：加入持有锁的线程因为等待长时间IO或者其他原因，其他等待的线程无法响应中断，只能不断等待\n公平锁即尽量以请求锁的顺序来获取锁。比如同时有多个线程在等待一个锁，当这个锁被释放时，等待时间最久的线程（最先请求的线程）会获得该锁。\n非公平锁即无法保证锁的获取是按照请求锁的顺序进行的。这样就可能导致某个或者一些线程永远获取不到锁。\n\nsynchronize是悲观锁，独占性很强，对读和写操作均是独占的\n\n使用synchronized关键字无法确认线程是否成功获取到锁\n\n\n异常是否释放synchronized关键字在发生异常时会自动释放占有的锁，因此不会出现死锁；而lock发生异常的时候，必须手动unlock来释放锁，可能会引起死锁。解决方式：try catch包裹代码块，finally中写入unlock\n是否响应中断lock可以用interrupt来中断等待，而synchronized只能不断等待锁的释放，不能响应中断\n是否知道获取锁lock可以通过trylock来知道有没有获取锁，而synchronized不能\n两者的异同\n在JDK1.5之前lock的性能优于synchronized，以后的版本，在不断优化降低锁的重量级后，两者的性能差距缩小。\nlock是一个接口，而synchronized是一个关键字\nlock可以有多个获取锁的方式，可以不用一直等待。而synchronized只能等待\nLock适合用于大量线程的同步，且大量线程竞争激烈时，lock的性能更优，lock锁还能使用readwritelock实现读写分离，提高多线程的读操作效率。\nlock可以实现公平锁与非公平锁，synchronized只能实现非公平锁\n\nAQS即AbstractQueuedSynchronizer类，抽象队列同步器，AQS是JUC的基类\n基于 volitile修饰的状态记录量state+Node对象构建的双向链表，先进先出，也就是队列\n//node类携带的信号量\n//排他锁标识\nstatic final node EXCLUSIVE =  null;\n//后继节点需要被唤醒\nstatic final int SIGNAL    = -1;\n//该节点已失效\nstatic final int CANCELLED = 1;\n\n//只有上一个节点是的ws为SIGNAL，当前节点才有可能被上一个节点唤醒\nvolatile int waitStatus;\n\n\n加锁（非公平为例）当调用lock()时，线程会尝试使用CAS的方式将state从0改变为1，返回true则证明成功拿到锁，将ExclusiveOwnerThread指向当前线程。若为重入，则会增加state的值。\n拿锁失败则会被放入队列。若队列为空，则会建立一个空节点作为哨兵，然后将此节点放在哨兵后。队列中的线程会acquireQueued()，内部由一个死循环实现，自旋地，独占且不可中断的方式获取同步状态，位于第二个节点的线程才有资格抢占锁，抢占后将晋升为头节点，原先的头节点会等待被GC。\n若获取锁失败或无资格获取锁，则会则根据前驱节点的waitStatus决定是否需要挂起线程，若为SIGNAL，则当前节点被安全阻塞。\n若为CANCELLED，则会向前查找到为SIGNAL的节点，并重新设置前驱节点，相当于是剔除了失效节点。\n若为0或者其他状态，通过CAS的方式设置为SIGNAL\n锁的释放release(int arg)，先检测state，若state减一后仍不为0，则代表有重入，返回false，等待下一次的释放。\n当state为0时，才会进行unpark()，即释放锁\nunparkSuccessor()，传入head节点，检测到后继节点中第一个waitStatus为-1的节点，并解除挂起状态\nReentrantLockpublic class ReentrantLock implements Lock\n\n互斥锁，可重入锁，也是可以实现公平锁和非公平锁（默认）的一种锁。内部包含一个AQS对象，并基于AQS实现\nNonfairSync：非公平锁无论是队列里，还是外来线程，都会通过CAS直接尝试获取锁，能抢到锁到直接占有锁，抢不到才会到等待队列的队尾等待。\nfairSync：公平锁则是所有线程并发进入acquire方法，通过hasQueuedPredecessors方法来严格控制队列获取锁的顺序，外来线程无法参与竞争。\n\nReentrantLock内部有三个类\n\nCountDownLatchCountDownLatch是一个倒数的计数器阀门，初始化时阀门关闭，指定计数的数量，当数量倒数减到0时阀门打开，被阻塞线程被唤醒\n工作方式：初始值为线程数，当线程完成自己的任务后，计数器的值就减一，当计数器为0时，表示所有线程都已完成任务。然后等待的线程就可以恢复执行。\nCountDownLatch(int count)：构造函数，需要指定一个等于线程数的int数值;\nawait()：当前线程调用该方法会进入等待状态，直到同步器状态为0时被其他线程唤醒或者被其他线程中断。也即将计数器减为0返回true的线程负责唤醒阻塞的线程。当计数器为0时，调用await()方法将立即返回;\nawait(long timeout, TimeUnit unit)：该方法与await()作用一样，只是添加了等待的时间，如果超过等待时间还没有被唤醒或者被中断，那么阻塞线程将退出阻塞状态;\ncountDown()：该方法主要是将指定的计数器减1，当计数器已经是0了调用该方法将会被忽略，也就是说计数器的值最小只能是0;\n\n原理：维护一个AQS，将state设置为Count数量，当state为0时，才会唤醒队列中的线程\nCyclicBarrierCyclicBarrier是一个可循环的屏障，它允许多个线程在执行完相应的操作后彼此等待共同到达一个point，等所有线程都到达后再继续执行。比如等所有运动员都跨过第一个栅栏后，才允许继续向前。\n工作方式：初始值同样为线程数，当线程完成自己的任务后，计数器的值减一，若state不为0，则自身阻塞，直到state为0，即所有线程都完成任务后，才会从障碍点继续运行。\nCyclicBarrier是可以循环的，每个线程可以调用两次的await()方法，重复利用栅栏的计数器。调用nextGeneration()方法，唤醒所有阻塞线程，并重置count。\n原理：维护ReentryLock的Lock方法和Condition实现\n而计数器阀门则不可以循环，count为0后就不能再使用。\nCyclicBarrier和CountDownLatch区别\nCountDownLatch的await()线程会等待计数器减为0，而执行CyclicBarrier的await()方法会使线程进入阻塞等待其他线程到达障点\nCountDownLatch计数器不能重置，CyclicBarrier可以重置循环利用，可以应对更多的情况，比如程序出错后重置\nCountDownLatch是基于AQS的共享模式实现的，CyclicBarrier是基于ReentrantLock和Condition实现的\nCountDownLatch会阻塞主线程，CyclicBarrier不会阻塞主线程，只会阻塞子线程\n\n","slug":"synchronized-volatile与lock","date":"2022-10-20T06:09:39.000Z","categories_index":"","tags_index":"Java基础知识","author_index":"Samuel"},{"id":"a213144f9a961ec1d4584b73bef34320","title":"一篇关于锁的文章","content":"面试官：解释一下什么是乐观锁，悲观锁，自旋锁，读写锁，排它锁，共享锁，统一锁，分段锁\n这种问题虽然庞大复杂，但是千万不要被干沉默，能说清楚就是P5往上\n按抽象概念分悲观锁悲观地认为数据大概率会被其他线程操作，所以具有强烈的独占性和排它性\n比如synchronized，先加锁再执行代码块\n乐观锁相反，乐观地认为数据不大会被其他线程操作，所以先执行代码块，遇见线程冲突的情况，再补偿\n自旋锁自旋锁是乐观锁的一种实现形式，首先需要了解一些概念\nCAS操作：CAS全称为compare and swap，即比较和交换\n这是JDK提供的原子性操作。语义上是两步操作，但是CPU一条指令即可以完成\n汇编指令：lock cmpxchg  \n原子性保证lock：当执行cmpxchg时，其他CPU不允许打断这个操作，lock是硬件级的实现：锁定北桥信号\nboolean compareAndSwapLong(Object obj,Long valueOffset,long expect,long update);\n//obj:对象的内存地址\n//valueOffset:偏移值\n//expect:期望的旧值\n//update:期望的新值\n\n如果对象中的变量值为expect，则使用新的值update替换expect\n替换成功，返回true；替换失败，即变量值不为expect，返回false；\n特点：非阻塞，即允许多个线程对共享资源进行修改，但是同一时刻只有一个线程可以进行写操作，其他线程并不是被阻塞，而是在不停重试拿到锁。\n在JAVA中若一个线程没有拿到锁被阻塞，就会造成线程的上下文切换，大量线程的重新调度会造成性能的浪费。volatile只能保证有序性和可见性，不能保证原子性。CAS就保证了原子性。\nCAS和volatile两者可以实现无锁并发\n\n\nABA问题：假如线程1使用CAS修改初始值为A的变量X&#x3D;A，那么线程1首先会获取当前变量X的值（A），然后使用CAS操作尝试修改X的值为B，如果使用CAS修改成功了，那么程序运行一定是正常的吗？\n其实未必，这是因为有可能在线程1获取到变量X的值A后，在执行CAS之前，线程2使用了CAS修改了变量X值为B，然后又使用了CAS操作使得变量X值为A，虽然线程A执行了CAS操作时X&#x3D;A，但是这个A已经不是线程1获取到的A了。这就是ABA问题。\nABA问题的产生是因为变量的状态值产生了环形转换，就是变量值可以从A到B，也可以B到A，如果变量的值只能朝着一个方向转换，例如A到B，B到C，不构成环路，就不会存在这个问题。\nJDK中的AtomicStampedReference类给每个变量的状态值都配备了一个时间戳，从而避免了ABA问题。或者是使用版本号，一个数据一个版本号，版本号不同数据值相同，也不会进行修改。\n所以自旋锁便是通过CAS来实现的，在获取锁的时候使用while循环不断进行CAS操作，类似于不断旋转，直到操作成功返回true，在释放锁的时候使用CAS将锁的状态从1变成0。\n按读写属性分排他锁又称写锁，X锁，只有一个线程能访问代码块，synchronized关键字即是排他锁。写的时候，不允许其他线程读，也不允许其他线程写\n共享锁又称读锁，S锁，可以有多个线程访问代码块，允许同时读，不允许写，必须等所有锁释放后才可以写\n读写锁概念同上\n按粒度分统一锁大粒度的锁，防止出现死锁。\n锁定A线程，等待B线程；锁定B，等待A；\n若没有很好地同步，就会出现死锁\n统一锁便是将A和B统一为一个大锁\n分段锁JDK1.7 ConcurrentHashMap\nHashMap是一个很长的链表，所以如果并发插入数据时，如果每次都锁定整个链表，性能会很差\n所以需要加入一种粒度较小的锁，即在一个桶内放入数据时，只锁定一段，而不是整个链表。\n当锁定一段时，不影响其他段的数据插入，提高了效率，缺点，代码实现复杂\n","slug":"一篇关于锁的文章","date":"2022-10-19T08:28:53.000Z","categories_index":"","tags_index":"Java基础知识","author_index":"Samuel"},{"id":"db91e78c8da8e89de1c0960e4a35ed33","title":"字典序问题","content":"给你一个整数 n ，按字典序返回范围 [1, n] 内所有整数。\n你必须设计一个时间复杂度为 O(n) 且使用 O(1) 额外空间的算法。\n示例 1：\n输入：n &#x3D; 13\n输出：[1,10,11,12,13,2,3,4,5,6,7,8,9]\n\n思路：字典序的构建可以看成是一支十叉树\n第一层是1位数字，第二层是2位数字，以此类推。\n而十叉树的前序遍历即是字典序的输出\nclass Solution &#123;\n    List&lt;Integer> ans = new ArrayList&lt;>();\n    public List&lt;Integer> lexicalOrder(int n) &#123;\n        //从第一层开始\n        for (int cur = 1; cur &lt;= 9; cur++) recursion(cur, n);\n        return ans;\n    &#125;\n    void recursion(int cur, int limit) &#123;\n        //前序遍历的终止条件\n        if (cur > limit) return ;\n        ans.add(cur);\n        //进入下一层\n        for (int i = 0; i &lt;= 9; i++) recursion(cur * 10 + i, limit);\n    &#125;\n&#125;\n\n给定整数 n 和 k，返回 [1, n] 中字典序第 k 小的数字\n输入: n &#x3D; 13, k &#x3D; 2\n输出: 10\n解释: 字典序的排列是 [1, 10, 11, 12, 13, 2, 3, 4, 5, 6, 7, 8, 9]，所以第二小的数字是 10。\n\n思路：其实按照第一题的思路可以解决，但是如果n十分巨大，全部遍历一遍会造成超时。\n所以无需全部遍历，只需比较该节点下的子节点总数与k的大小即可\n比较节点数与k的大小来判断是否需要进入子树，还是进入兄弟节点的子树\n但是需要解决的问题是，有一些子树的节点不是满的，所以计算nodeCount时需要分情况\nclass Solution &#123;\n    public int findKthNumber(int n, int k) &#123;\n        //从第一层的第一个节点开始扫描\n        int cur =1;\n        k--;\n        //当k==0时，证明找到节点\n        while(k>0)&#123;\n            long left = cur;\n            long right = cur+1;\n            int nodeCount = 0;\n            //统计cur节点下所有子树的节点数\n            while(left&lt;=n)&#123;\n                nodeCount+=Math.min(right,(int)(n+1))-left;\n                left*=10;\n                right*=10;\n            &#125;\n            //不在cur节点下，进入另一个节点\n            if(nodeCount&lt;=k)&#123;\n                k-=nodeCount;\n                cur++;\n            &#125;\n            else&#123;\n                //在cur节点下，进入cur的子树\n                k--;\n                cur*=10;\n            &#125;\n        &#125;\n        return cur;\n    &#125;\n&#125;\n\n","slug":"字典序问题","date":"2022-10-19T05:30:33.000Z","categories_index":"","tags_index":"LeetCode初见","author_index":"Samuel"},{"id":"d1863bbf8aa3ec7bc32e4a0f3476163f","title":"线程池","content":"何为线程池：一种多线程的处理形式，处理过程中可以将任务添加到队列中，然后在创建线程后自动启动这些任务。\n线程池的优势：\n线程和任务分离，线程可被重用，提升复用性\n控制线程并发数量，统一管理，降低服务器压力\n提升系统响应速度，因为线程池内的线程可以被复用，且线程池内有核心线程待命，所以就减少了创建线程和销毁线程的时间。\n\n应用场景：网购商品秒杀，云盘文件上传，旅行系统购票等等\n为什么要使用线程池JAVA线程的创建十分昂贵，需要JVM和OS配合完成大量的工作\n\n必须为线程堆栈分配和初始化大量的内存块，其中至少包含1MB的栈内存\nJVM的线程模型为1:1模型，即JVM的线程和OS的线程是1:1对应的，需要进行系统调用，以便在OS中创建和注册本地线程\n\nJava的高并发应用频繁创建和销毁线程的操作是十分低效的，且不符合编程规范的，所以需要使用线程池来独立负责线程的创建维护和分配，以提升性能，减少资源消耗。\n解析//构造方法:\npublic ThreadPoolExecutor(int corePoolSize, //核心线程数量\n                              int maximumPoolSize,//     最大线程数\n                              long keepAliveTime, //       最大空闲时间\n                              TimeUnit unit,         //        时间单位\n                              BlockingQueue&lt;Runnable> workQueue,   //   任务队列\n                              ThreadFactory threadFactory,    // 线程工厂\n                              RejectedExecutionHandler handler  //  饱和处理机制\n\t) \n\n参数解释：\n\ncorePoolSize : 指空闲也不允许被销毁的线程，随时待命存放于线程池中\nmaximumPoolSize：指最大线程数，当任务队列满时，需要创建临时进程处理无法进入任务队列的任务。当临时进程空闲时，会被销毁\nkeepAliveTime&amp;TimeUnit：最大空闲时间和时间单位，当临时进程空闲时间超过最大空闲时间后，便会被销毁\nBlockingQueue：任务队列，当核心线程均不空闲时，任务进入队列等待。队列就是一种容器，可以用多种数据结构实现，常见的有ConcurrentMap,PriorityQueue,ArrayBlockingQueue等等。永远推荐使用有界队列，即由数组实现的队列，并设立合理的长度。避免造成等待任务过多消耗系统资源。\nThreadFactory ：线程工厂，手动命名创建线程的工厂，方便抛出错误后定位相应线程池\nRejectedExecutionHandler：拒绝策略，当任务队列满且所有线程均不空闲时，启用饱和处理机制\n\n如何确定核心线程数，最大线程数，任务队列长度核心线程数：IO密集型：CPU数*2；CPU密集型：CPU数+1\n最大线程数：(每秒产生的最大任务数-任务队列长度)*单个任务执行时间\n任务队列长度：核心线程数&#x2F;单个任务执行时间*2\n饱和处理机制有哪些\nAbortPolicy：丢弃任务并抛出异常\nDiscardPolicy：丢弃任务不抛出异常\nDiscardOldestPolicy：丢弃最前面的任务，然后重新提交被拒绝的任务\nCallerRunsPolicy：直接调用线程处理该任务\n\n","slug":"线程池","date":"2022-10-18T12:33:43.000Z","categories_index":"","tags_index":"Java基础知识","author_index":"Samuel"},{"id":"8420d36b5907c1ed250973ab1271d588","title":"微软面试题——24点游戏","content":"给定一个长度为4的整数数组 cards 。你有 4 张卡片，每张卡片上都包含一个范围在 [1,9] 的数字。您应该使用运算符 [&#39;+&#39;, &#39;-&#39;, &#39;*&#39;, &#39;/&#39;] 和括号 &#39;(&#39; 和 &#39;)&#39; 将这些卡片上的数字排列成数学表达式，以获得值24。\n输入: cards &#x3D; [4, 1, 8, 7]\n输出: true\n解释: (8-4) * (7-1) &#x3D; 24\n\n显而易见是回溯，但是由于题中给出除法是实数除法，所以必须使用double来进行计算\nclass Solution &#123;\n    static double Target = 24;\n    //浮点数误差最小精度\n    static double standard = 1e-6;\n    public boolean judgePoint24(int[] cards) &#123;\n        return backTrack(new double[]&#123;cards[0],cards[1],cards[2],cards[3]&#125;);\n    &#125;\n    boolean backTrack(double[] nums)&#123;\n        //若最终结果与target的差值小于某一数值，则证明相等\n        if(nums.length ==1 )return Math.abs(nums[0]-Target)&lt;standard;\n        for(int i =0;i&lt;nums.length;i++)&#123;\n            for(int j = i+1;j&lt;nums.length;j++)&#123;\n                //建立一个数组，存储除选中的两个数以外的所有数和这两个数的运算结果\n                double[] next = new double[nums.length-1];\n                for(int k=0,index=0;index&lt;nums.length;index++)&#123;\n                    if(index!=i&amp;&amp;index!=j) next[k++] = nums[index];\n                &#125;\n                //决策树选择\n                for(double num:caculator(nums[i],nums[j]))&#123;\n                    next[next.length-1] = num;\n                    if(backTrack(next)) return true;\n                &#125;\n            &#125;\n        &#125;\n        return false;\n    &#125;\n    //存储两个数可以获得的所有运算结果\n    ArrayList&lt;Double> caculator(double a, double b)&#123;\n        ArrayList&lt;Double> list = new ArrayList();\n        list.add(a*b);\n        list.add(a+b);\n        list.add(a-b);\n        list.add(b-a);\n        //若a绝对值小于精度，则可以认为a为零\n        if(!(Math.abs(a)&lt;standard)) list.add(b/a);\n        if(!(Math.abs(b)&lt;standard)) list.add(a/b);\n        return list;\n    &#125;\n&#125;\n\n","slug":"微软面试题——24点游戏","date":"2022-10-16T11:58:26.000Z","categories_index":"","tags_index":"LeetCode初见","author_index":"Samuel"},{"id":"12f7852204c389ace8749b92fea05496","title":"周赛笔记10/16/2022","content":"6204. 与对应负数同时存在的最大正整数给你一个 不包含 任何零的整数数组 nums ，找出自身与对应的负数都在数组中存在的最大正整数 k \n输入：nums &#x3D; [-1,2,-3,3]\n输出：3\n解释：3 是数组中唯一一个满足题目要求的 k 。\n\n一个HashSet+一遍遍历，秒解\nclass Solution &#123;\n    public int findMaxK(int[] nums) &#123;\n        HashSet&lt;Integer> set = new HashSet&lt;>();\n        int res = Integer.MIN_VALUE;\n        for(int n:nums)&#123;\n            if(set.contains(-n)) res = Math.max(res,Math.abs(n));\n            set.add(n);\n        &#125;\n        return res==Integer.MIN_VALUE?-1:res;\n    &#125;\n&#125;\n\n6205. 反转之后不同整数的数目给你一个由正整数组成的数组nums 。\n你必须取出数组中的每个整数，反转其中每个数位，并将反转后得到的数字添加到数组的末尾。这一操作只针对 nums 中原有的整数执行。\n返回结果数组中不同整数的数目。\n输入：nums &#x3D; [1,13,10,12,31]\n输出：6\n解释：反转每个数字后，结果数组是 [1,13,10,12,31,1,31,1,21,13] 。\n反转后得到的数字添加到数组的末尾并按斜体加粗表示。注意对于整数 10 ，反转之后会变成 01 ，即 1 。\n数组中不同整数的数目为 6（数字 1、10、12、13、21 和 31）\n\n同样一个HashSet+一遍遍历，秒解\nclass Solution &#123;\n    public int countDistinctIntegers(int[] nums) &#123;\n        HashSet&lt;Integer> set = new HashSet();\n        for(int num : nums)&#123;\n            if(num==1) &#123;\n                set.add(num);\n                continue;\n            &#125;\n            set.add(num);\n            int n =0;\n            while(num!=0)&#123;\n                n=n*10+num%10;\n                num/=10;\n            &#125;\n            set.add(n);\n        &#125;\n        return set.size();\n    &#125;\n&#125;\n\n6219. 反转之后的数字和输入：num &#x3D; 443\n输出：true\n解释：172 + 271 &#x3D; 443 ，所以返回 true 。\n\n我以为我的方法很笨，但是发现大家都是同样的解法…\nclass Solution &#123;\n    public boolean sumOfNumberAndReverse(int num) &#123;\n        if(num==0) return true;\n        for(int i=1;i&lt;=num;i++)&#123;\n            if((i+reverseNum(i))==num) return true;\n        &#125;\n        return false;\n    &#125;\n    int reverseNum(int num)&#123;\n        int n =0;\n        while(num!=0)&#123;\n            n=n*10+num%10;\n            num/=10;\n        &#125;\n        return n;\n    &#125;\n&#125;\n\n6207. 统计定界子数组的数目给你一个整数数组 nums 和两个整数 minK 以及 maxK 。\nnums 的定界子数组是满足下述条件的一个子数组：\n子数组中的最小值等于 minK\n子数组中的最大值等于 maxK\n返回定界子数组的数目。\n子数组是数组中的一个连续部分\n输入：nums &#x3D; [1,3,5,2,7,5], minK &#x3D; 1, maxK &#x3D; 5\n输出：2\n解释：定界子数组是 [1,3,5] 和 [1,3,5,2] 。\n\n发呆一小时，没写出来…\n看了好几个解析，写了一个自己的解法，然后有一些自己的理解\nclass Solution &#123;\n public long countSubarrays(int[] nums, int minK, int maxK) &#123;\n        int n = nums.length;\n        long res = 0;\n        int left = 0, minIndex = -1, maxIndex = -1;\n        for (int i = 0; i &lt; n; i++) &#123;\n            //定位出现最大最小值的索引\n            if (nums[i] == minK) minIndex = i;\n            if (nums[i] == maxK) maxIndex = i;\n            //刚进来的数影响了最大值或最小值\n            if (nums[i] &lt; minK || nums[i] > maxK) &#123;\n                //将left定位到刚好不出现越界值的位置\n                left = i + 1;\n                minIndex = maxIndex = -1;\n                //当窗口内同时包含最大值和最小值时，更新结果\n            &#125; else if (minIndex != -1 &amp;&amp; maxIndex != -1) &#123;\n                int min = Math.min(minIndex, maxIndex);\n                res += min - left + 1;\n            &#125;\n        &#125;\n        return res;\n    &#125;\n&#125;\n\n","slug":"周赛笔记10-16-2022","date":"2022-10-16T08:06:31.000Z","categories_index":"","tags_index":"LeetCode初见","author_index":"Samuel"},{"id":"22f311f06a9cae50742dc4cb95ef15a1","title":"子序列数目","content":"输入：s &#x3D; &quot;abc&quot;\n输出：7\n解释：7 个不同的子序列分别是 &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;ab&quot;, &quot;ac&quot;, &quot;bc&quot;, 以及 &quot;abc&quot;。\n\n难度：hard\nclass Solution &#123;\n    //状态转移方程真的不好写，所以我不想用动态规划\n    //思路：以c结尾的子串数目等于：以c之前的所有字母结尾的子序列数目的总和+1\n    public int distinctSubseqII(String s) &#123;\n        char[] arr = s.toCharArray();\n        int n = arr.length;\n        int[] alphaBet  = new int[26];\n        for(int i=0;i&lt;n;i++)&#123;\n            long sum = 0;\n            //求总和\n            for(int j:alphaBet)sum=(sum+j)%1000000007;\n            //+1即加上自身\n            alphaBet[arr[i]-'a'] = (int)sum+1;\n        &#125;\n        long res = 0;\n        for(int i : alphaBet) res = (res+i)%1000000007;\n        return (int)res;\n    &#125;\n&#125;\n","slug":"子序列数目","date":"2022-10-14T14:28:37.000Z","categories_index":"","tags_index":"LeetCode初见","author_index":"Samuel"},{"id":"412f186990736c43d33166b6535da85e","title":"周赛笔记10/9/2022","content":"2432. 处理用时最长的那个任务的员工输入：n &#x3D; 10, logs &#x3D; [[0,3],[2,5],[0,9],[1,15]]\n输出：1\n解释：\n任务 0 于时刻 0 开始，且在时刻 3 结束，共计 3 个单位时间。\n任务 1 于时刻 3 开始，且在时刻 5 结束，共计 2 个单位时间。\n任务 2 于时刻 5 开始，且在时刻 9 结束，共计 4 个单位时间。\n任务 3 于时刻 9 开始，且在时刻 15 结束，共计 6 个单位时间。\n时间最长的任务是任务 3 ，而 id 为 1 的员工是处理此任务的员工，所以返回 1 。\n\n突发奇想，想练习一下sort方法的运用熟练程度\nclass Solution &#123;\n    public int hardestWorker(int n, int[][] logs) &#123;\n        for(int i=logs.length-1;i>=0;i--)&#123;\n            if(i==0) break;\n            else logs[i][1]-=logs[i-1][1];\n        &#125;\n        Arrays.sort(logs,(a,b)->&#123;\n            if(b[1]!=a[1])return b[1]-a[1];\n            else return a[0]-b[0];\n        &#125;);\n        return logs[0][0];\n    &#125;\n&#125;\n\n2433. 找出前缀异或的原始数组输入：pref &#x3D; [5,2,0,3,1]\n输出：[5,7,2,3,2]\n解释：从数组 [5,7,2,3,2] 可以得到如下结果：\n- pref[0] &#x3D; 5\n- pref[1] &#x3D; 5 ^ 7 &#x3D; 2\n- pref[2] &#x3D; 5 ^ 7 ^ 2 &#x3D; 0\n- pref[3] &#x3D; 5 ^ 7 ^ 2 ^ 3 &#x3D; 3\n- pref[4] &#x3D; 5 ^ 7 ^ 2 ^ 3 ^ 2 &#x3D; 1\n\n寻找数学规律即可，只不过确实需要自己写例子推导一下\nclass Solution &#123;\n    public int[] findArray(int[] pref) &#123;\n        int n = pref.length;\n        int[] res = new int[n];\n        if(n&lt;=1) return pref;\n        res[0] = pref[0];\n        for(int i=0,p=1;i&lt;n-1&amp;&amp;p&lt;n;i++)&#123;\n                int j = i+1;\n                res[p++] = pref[i]^pref[j];\n            &#125;\n        return res;\n        &#125;\n&#125;\n\n2435. 矩阵中和能被 K 整除的路径给你一个下标从 0 开始的 m x n 整数矩阵 grid 和一个整数 k \n你从起点 (0, 0) 出发，每一步只能往下或者往右 ，你想要到达终点 (m - 1, n - 1) 。\n\n请你返回路径和能被 k 整除的路径数目，由于答案可能很大，返回答案对 109 + 7 取余 的结果。\n\n我刚开始觉得应该是回溯，因为是图的路径问题，但是有几个用例总是无法通过\n最后看解析才发现需要使用DP，确实有点难，特别是状态转换方程的推导\nclass Solution &#123;\n    public int numberOfPaths(int[][] grid, int k) &#123;\n        int m = grid.length;\n        int n = grid[0].length;\n        //记忆化搜索\n        int[][][] c = new int[m][n][k];//记录dp值\n        c[0][0][grid[0][0]%k]++;//记录第一个元素dp值\n        for(int i=1; i&lt;m; i++)&#123;//记录第一列元素dp值\n            for(int l = 0; l&lt;k; l++)&#123;\n                c[i][0][(l+grid[i][0])%k] += c[i-1][0][l];\n            &#125;\n        &#125;\n        for(int j=1; j&lt;n; j++)&#123;//记录第一行元素dp值\n            for(int l = 0; l&lt;k; l++)&#123;\n                c[0][j][(l+grid[0][j])%k] += c[0][j-1][l];\n            &#125;\n        &#125;\n        for(int i=1; i&lt;m; i++)&#123;//记录其他元素dp值\n            for(int j=1; j&lt;n; j++)&#123;\n                for(int l = 0; l&lt;k; l++)&#123;\n                    c[i][j][(l+grid[i][j])%k] += c[i-1][j][l];\n                    c[i][j][(l+grid[i][j])%k] += c[i][j-1][l];\n                &#125;\n                for(int l = 0; l&lt;k; l++)&#123;//避免整数溢出\n                    if(c[i][j][l] >= 1000000007) c[i][j][l] -=1000000007 ;\n                &#125;\n            &#125;\n        &#125;\n        return c[m-1][n-1][0];\n    &#125;\n&#125;\n\n","slug":"周赛笔记10-9-2022","date":"2022-10-09T05:25:50.000Z","categories_index":"","tags_index":"LeetCode初见","author_index":"Samuel"},{"id":"bdd0b34d75b797c3e041acb9ccf9384c","title":"位运算技巧","content":"//位运算算法技巧\n//不用临时变量交换两个数\na ^= b;\nb ^= a;\na ^= b;\n//判断是否异号（同号）\nboolean f = ((x ^ y) &lt; 0);\n//利用或操作 | 和空格将英文字符转换为小写\n('A' | ' ') = 'a';\n//利用与操作 &amp; 和下划线将英文字符转换为大写\n('b' &amp; '_') = 'B';\n//利用异或操作 ^ 和空格进行英文字符大小写互换\n('D' ^ ' ') = 'd';\n//去掉最后一位1\nn &amp; (n-1);\n//异或运算的特殊性质,异或运算满足交换律和结合律\na ^ a = 0;\na ^ 0 = a;\n//取反码+与运算\nx &amp; ~x = 0;\nx &amp; ~0 =x;\n\n","slug":"位运算技巧","date":"2022-10-02T04:59:51.000Z","categories_index":"","tags_index":"算法归纳","author_index":"Samuel"},{"id":"8a33ad4dd9e973b50a7c9fd8c1c572f8","title":"划分k个相等子集","content":"输入： nums &#x3D; [4, 3, 2, 3, 5, 2, 1], k &#x3D; 4\n输出： True\n说明： 有可能将其分成 4 个子集（5），（1,4），（2,3），（2,3）等于总和\n\n桶问题：若可以划分为k个子集，则想象有k个桶，容量均为sum&#x2F;k，如果我们刚好将桶装满，则返回true，否则返回false\nclass Solution &#123;\n    int sum =0;\n    public boolean canPartitionKSubsets(int[] nums, int k) &#123;\n        if(!isValid(nums,k)) return false;\n        //对数组排序，从后向前搜索\n        Arrays.sort(nums);\n        if(nums[nums.length-1]>sum/k) return false;\n        sum/=k;\n        int[] arr = new int[k];\n        //建立桶的数据结构\n        Arrays.fill(arr,sum);\n        return(backTrack(nums,k,arr,nums.length-1));\n    &#125;\n    boolean isValid(int[] nums, int k)&#123;\n        for(int val : nums) sum+=val;\n        if(sum%k!=0) return false;\n        return true;\n    &#125;\n    boolean backTrack(int[] nums, int k,int[] arr,int cur)&#123;\n        if(cur&lt;0) return true;// cur走到-1时，说明所有的数全部都放进桶里了。这时一定是true\n        for(int i=0;i&lt;k;i++)&#123;\n            //i遍历每一个桶，判断cur指向的数可以放入哪一个桶\n            if(arr[i]==nums[cur]||arr[i]-nums[cur]>=nums[0])&#123;\n                arr[i]-=nums[cur];\n                if(backTrack(nums,k,arr,cur-1)) return true;\n                arr[i]+=nums[cur];\n            &#125;\n        &#125;\n        return false;\n    &#125;\n&#125;\n\n","slug":"划分k个相等子集","date":"2022-09-27T13:57:25.000Z","categories_index":"","tags_index":"LeetCode初见","author_index":"Samuel"},{"id":"a978a5e93d8e6628e9f4ee713be55be8","title":"Redis","content":"Redis的数据结构字符串int：存储数字\nraw：长度大于39字节，基于SDS\nembstr：长度小于39字节，基于SDS\nSDS结构模型基于C语言，由Redis封装的一种简单高效安全的数据结构\n源码分析SDS的底层实现思路其实十分简单\n\n无符号变量len：记录字符串的长度\n无符号变量free：记录空闲内存的大小\nchar型数组buf：存储字符\n\n其中：buf尾部会自动追加一个空字符，遵循了c语言原生字符串的规范，并且SDS的指针也不是指向起始位置，而是指向buf，使得SDS可以直接使用一部分库函数。\nSDS取消了字节对齐，使得指针移动一位便可以读取到header里的信息。如果没有取消，这个移动的位数是未知的，就无法兼容C语言的库函数了，指针操作也要麻烦很多。\n数据结构优化：如果一个字符串非常短，但是记录信息的头部却占用了更多的空间，这未免有一些浪费，所以SDS会分为五种类型\n\n短字符串：小于32，用一个char类型的flag变量来记录长度，低三位存储类型，高三位存储长度\n短字符串：用一字节的char来记录长度，一字节的flag来记录类型\n长字符串：用2字节的short来记录长度，1字节的flag来记录类型\n长字符串：用4字节的int来记录长度\n超长字符串：用8字节的long来记录字符串\n\nSDS的最大长度：在3.X版本中，因为数据结构中的len属性是由int来修饰的，所以buf的最大长度就是214783647，即512MB\n但是在6.x版本后，长度就更多样了\nSDS相比原生string的优势：\nO(1)时间复杂度获取字符串的长度：因为C语言原生基本数据类型不记录自身长度，当要计算一个字符串的长度必须遍历整个字符串，直到遇到空字符为止，时间复杂度O(n)，而使用SDS则直接获取len属性即可，时间复杂度为O(1)\n二进制安全：在C语言中，用空字符表示字符串的结束，若字符串本身就包含空字符，那么遇到便会截断，即非二进制安全。与其相对的便是二进制安全，SDS使用len属性来判断字符串是否结束，不会受到空字符影响。\n杜绝缓冲区溢出：在C语言中，在对字符串进行拼接操作时，若没有给字符串分配足够的内存，那么就可能产生缓冲区溢出，把其他数据覆盖掉。而SDS的自动扩容机制杜绝了溢出，sdsMakeRoomFor方法：参数：原字符串，待加入的字符串。若空闲空间大于待拼接字符串的长度，则无需扩容；若拼接后的长度小于1M，则直接扩容至新长度的两倍；若拼接后的长度大于1M，则扩容至新长度+1M；扩容后检查类型，若发生变化，则需要为SDS重新分配内存（header的大小也改变了）\n优化的内存分配策略：预分配：扩容后的SDS不会恰好容下新字符串，而是多分配了一些空间，从而减少修改字符串时带来的内存重分配次数；惰性空间释放机制：当缩短字符串时，不会立刻回收空余的空间，而是仅仅更新len属性，空余空间供将来使用，减少内存分配频率，当然Redis也提供了释放未使用空间的方法sdsRemoveFreeSpace\n\nList列表Redis 的列表相当于 Java 语言里面的 LinkedList，这意味着List的插入和删除操作非常块，但是索引定位就比较慢了\nList支持先进先出（lpop）先进后出（rpop）\nList有两种实现方式：压缩列表和双向循环链表\nziplist节点的数据小于64字节，数据个数小于512个\n一般的数组都要求每一格的元素大小相同，但是若要存储不同大小的字符串，就需要以最大长度来作为元素大小，会造成一定程度的浪费。而压缩列表就是将元素紧凑，但是会在每个元素的头部追加一个len属性，这样就能很容易计算出下一个元素的内存地址。\n双向链表和linkedlist很相似，可以处理数据量较大的情况，每个节点包含value和前驱，后继节点的指针\nHash节点的数据小于64字节，数据个数小于512个时由ziplist实现\n其他情况由哈希表实现，和JAVA里的hashmap类似，都是无序的键值对集合。\nhash也有两种实现方式，当数据量小的时候，使用压缩列表，当数据量大的时候，使用散列表。\nhash的底层和hashmap也差不多，都是数组+链表的二维结构，但是hash只能存储字符串，并且rehash的方式也不一样，redis为了保证高性能，采用渐进式的rehash方法，即在不断输入的任务以及hash操作中一步步将旧结构里的内容迁移到新结构中\nSET集合，存储一组不重复的数据\n同样两种实现方法：有序数组inset（只用于处理整数）和散列表。前者是处理较少的数据，后者是处理大量数据。\nZSET节点的数据小于64字节，数据个数小于128个时由ziplist实现\n其他情况由跳表来实现\n跳表skipList跳表是可以实现二分查找的有序链表，常用于redis的有序集合数据结构\n拥有与红黑树相近的查找，删除，插入效率，并且范围查找效率更优越\n原理在于为有序链表建立多级索引，从而实现跳跃查找，\n最底层包含所有元素，第一级索引包含1&#x2F;2的元素，以此类推。\n每个索引包含了一个指针数组，指向了该索引可以到达的所有节点，数组下标即当前指针所在的层数。\n通过生成随机数的方式，来为每一个插入的元素设定索引级数，从而无需重建整个索引，降低了时间复杂度\nRedis的持久化因为redis的数据是在内存里，一旦断电或者宕机，数据便会丢失，所以必须保证数据不会因为故障而丢失\nRDB(redis database)即快照，在指定的时间间隔内将内存中的所有数据集快照写入磁盘\nRedis会单独创建fork一个子进程来进行持久化，依靠操作系统的COW机制（写入时复制，在client没有对数据进行写入时，子进程和主进程通过指针共享一个物理页面，当client对数据进行写入修改时，OS才会为页面创建副本，子进程将副本数据写入RDB，而这个过程仍然不影响主进程对数据的修改），fork进程内部的数据便是整个数据库的一个快照。当子进程完成对新RDB文件的写入时，便会拿其替换原来的RDB文件。\nfork 的作用是复制一个与当前进程一样的进程。新进程的所有数据（变量、环境变量、程序计数器等）数值都和原进程一致，但是是一个全新的进程，并作为原进程的子进程。 子进程读取数据，然后序列化写到磁盘中。\nRDB是对整个内存的数据进行快照，所以只有一个文件，这种方法适合大规模的数据恢复，而且很方便，因为OS只需要fork一个子进程，服务进程无需进行其他的IO操作，最大化保障redis的性能。\n但是RDB也有一些缺点：最后一次快照无法及时写入内存，可能会发生丢失，因为是由fork子进程来完成持久化，相当于克隆了一份内存数据，当数据集较大时，可能会影响整个服务器的性能。\nAOF(Append Only File)以日志的形式来记录写操作，只记录写指令，恢复时只需从前往后执行一遍即可完成数据恢复的工作。\n记录方式：写后日志：即在数据写入内存后再记录日志，让操作系统先执行命令，只有命令执行成功才能被记录，这种方式排除了错误的指令，并且不会阻塞当前的写操作。\n风险：若写入数据后未来得及记录日志便宕机，就会造成数据丢失。虽然避免了当前命令的阻塞，但是会给下一个操作带来阻塞 的风险，因为AOF日志是在主线程中进行的，写入磁盘时，磁盘的写压力大，可能会造成后序操作的阻塞。\n同步写回：每个操作完成后写回，会影响性能，但是可靠性高\n每秒写回：即每秒进行一次写回，性能适中，但是可能会丢失这一秒内的数据\n操作系统控制的写回：每个写完命令执行完，只是先把日志写到AOF文件的内存缓冲区，由操作系统决定何时写回磁盘。性能好，但是宕机时丢失的数据多\nRedis的事务redis是不支持回滚的：由程序员自行纠正编程错误，无回滚的方式保证了内部的简单快速\n以MULTI开始一个事务，将多个命令入队，入队后不会立即执行，而是放置在等待执行的队列里，由EXEC触发事务\n所有命令都会被序列化，顺序执行，执行过程中不会被其他客户端的命令打断\n在提交之前所有命令都不会被执行\n不保证原子性：有一条命令失败，其他的命令仍然会进行，没有回滚\n为什么单线程的redis这么快\n完全基于内存，所以读写效率高\n持久化操作利用fork子进程和linux的页缓存技术来完成，不影响主进程的性能\n单线程避免了上下文切换\n合理高效的数据结构\nIO多路复用机制epoll\n\nredis和memcached的区别memcached全部存储于内存中，断电后会挂掉；redis具有持久化机制\nRedis具有复杂的数据类型\nRedis自己构建了VM机制，一般的系统调用系统函数，会浪费时间去移动和请求\nredis的value值最大可以达到1gb，memcached只有1mb\nRedis的数据过期淘汰策略定期删除策略：启用一个计时器定时监视所有的key，判断key是否过期，过期就删除。这种策略可以保证过期的Key最终都会被删除。缺点：遍历内存中所有的key非常消耗CPU。并且如果key已经过期，但是计时器未被唤起，这段时间内Key仍可以使用\n惰性删除策略：在获取key时，才判断key是否过期，过期即可删除。缺点：若key一直未被使用，那么就算过期了也不会被删除\n定期删除+惰性删除：结合两者的特性，每次选取部分key扫描，减轻了CPU的负担。\n内存淘汰机制：\n\nvolatile-lru：从已设置过期时间的数据集中选取最少使用的数据淘汰\nvolatile-ttl：从已设置过期时间的数据集中选取将要过期的数据淘汰\nvolatile-random：随机选取数据淘汰\nallkeys-lru：当内存不足以容纳新数据时，移除最少使用的Key\nallkeys-random：从数据集中任意选择数据淘汰\nno-eviction：禁止淘汰数据，满了就拒绝写入\n\n","slug":"Redis随想","date":"2022-09-24T05:45:16.000Z","categories_index":"","tags_index":"数据库基础","author_index":"Samuel"},{"id":"e0c4de6a72c616ec823d805c53472b1a","title":"子集排列问题sucks","content":"回溯算法解决所有子集排列问题形式一：元素无重复，且不可复选，即nums中所有元素均唯一，且最多使用一次\n/* 组合/子集问题回溯算法框架 */\n//使用start参数来避免复选\nvoid backtrack(int[] nums, int start) &#123;\n    // 回溯算法标准框架\n    for (int i = start; i &lt; nums.length; i++) &#123;\n        // 做选择\n        track.addLast(nums[i]);\n        // 注意参数\n        backtrack(nums, i + 1);\n        // 撤销选择\n        track.removeLast();\n    &#125;\n&#125;\n/* 排列问题回溯算法框架 */\n//使用used数组来记录已选过的元素，避免复选\nvoid backtrack(int[] nums) &#123;\n    for (int i = 0; i &lt; nums.length; i++) &#123;\n        // 剪枝逻辑\n        if (used[i]) &#123;\n            continue;\n        &#125;\n        // 做选择\n        used[i] = true;\n        track.addLast(nums[i]);\n\n        backtrack(nums);\n        // 撤销选择\n        track.removeLast();\n        used[i] = false;\n    &#125;\n&#125;\n\n形式二：元素有重复，但是不可以复选，即nums中存在重复的元素，但是每个元素只能使用一次\nArrays.sort(nums);\n//为数组排序，使得相同的元素排在一起\n/* 组合/子集问题回溯算法框架 */\nvoid backtrack(int[] nums, int start) &#123;\n    // 回溯算法标准框架\n    for (int i = start; i &lt; nums.length; i++) &#123;\n        // 剪枝逻辑，跳过值相同的相邻树枝\n        if (i > start &amp;&amp; nums[i] == nums[i - 1]) &#123;\n            continue;\n        &#125;\n        // 做选择\n        track.addLast(nums[i]);\n        // 注意参数\n        backtrack(nums, i + 1);\n        // 撤销选择\n        track.removeLast();\n    &#125;\n&#125;\n\n\nArrays.sort(nums);\n/* 排列问题回溯算法框架 */\nvoid backtrack(int[] nums) &#123;\n    for (int i = 0; i &lt; nums.length; i++) &#123;\n        // 剪枝逻辑\n        if (used[i]) &#123;\n            continue;\n        &#125;\n        // 剪枝逻辑，固定相同的元素在排列中的相对位置，若i-1未被选择，那么i也不能选，相当于固定了顺序\n        if (i > 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; !used[i - 1]) &#123;\n            continue;\n        &#125;\n        // 做选择\n        used[i] = true;\n        track.addLast(nums[i]);\n\n        backtrack(nums);\n        // 撤销选择\n        track.removeLast();\n        used[i] = false;\n    &#125;\n&#125;\n\n形式三：元素无重复，但是可以复选\n/* 组合/子集问题回溯算法框架 */\nvoid backtrack(int[] nums, int start) &#123;\n    // 回溯算法标准框架\n    for (int i = start; i &lt; nums.length; i++) &#123;\n        // 做选择\n        track.addLast(nums[i]);\n        // 注意参数\n        backtrack(nums, i);\n        // 撤销选择\n        track.removeLast();\n    &#125;\n&#125;\n\n\n/* 排列问题回溯算法框架 */\nvoid backtrack(int[] nums) &#123;\n    for (int i = 0; i &lt; nums.length; i++) &#123;\n        // 做选择\n        track.addLast(nums[i]);\n        backtrack(nums);\n        // 撤销选择\n        track.removeLast();\n    &#125;\n&#125;\n","slug":"子集排列问题sucks","date":"2022-09-13T05:14:49.000Z","categories_index":"","tags_index":"算法归纳","author_index":"Samuel"},{"id":"d819bd760b595babeef6cadb7a50d452","title":"JVM相关知识","content":"JAVA内存区域讲解运行时数据区域分为两部分：线程共享和线程私有\n线程共享区域：\n堆：是虚拟机内存的最大的一块，此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存，注意是“几乎”，JDK1.7之后，当方法中的对象引用没有被返回或者未被外部使用，就会直接在栈上分配内存。同时，堆也是垃圾收集器管理的主要区域，所以也被称为GC堆。\n\nJDK1.8之前：方法区（运行时常量池）；JDK1.8之后：无，将方法区移至本地内存。方法区是运行时数据区域的一个逻辑区域，在不同虚拟上方法区的实现是不同的，当虚拟机要使用一个类时，它需要读取并解析class文件获取相关信息，再将信息存入到方法区。方法区会存储已被虚拟机加载的类信息，字段信息，方法信息，常量，静态变量，即时编译器编译后的代码缓存。\n方法区有两种具体实现：永久代permanent gen和元空间metaspace。前者拥有一个由本身JVM设置的大小上限，无法调整，而在8版本之后，转而使用元空间，后者使用的是计算机的直接内存，溢出的概率更小。\n方法区包含运行时常量池和字符串常量池，后者是为了减少string类的内存消耗而专门开辟的，可以避免字符串的重复创建。方法区是一个公共且抽象的概念，在不同虚拟机上可以有不同的实现。\n\n\n\n\n\n线程私有区域：\n虚拟机栈：由一个个栈帧组成，栈帧内包含：局部变量表（八大原始类型，对象引用），操作数栈（作为方法调用的中转站，存放中间计算结果，实现CPU的寄存器的功能），动态链接（当一个方法需要调用其他方法时，动态链接就是未来将符号引用转换为调用方法的直接引用），方法返回地址。方法调用的数据通过栈进行传递，每一个方法没调用时都会有一个对应的栈帧被压入，每一个方法调用结束后，都会有一个栈帧被弹出。当函数调用陷入无限循环，或者压栈太多，导致线程请求的栈的深度超过JAVA虚拟机栈的最大深度时，就会抛出,stackoverflow。栈帧的弹出：return语句，异常抛出，随方法的调用而创建，随方法的结束而销毁，所以无论方法是否正常完成还是异常完成，都可以视为方法结束。\n本地方法栈：和虚拟机栈十分相似，但是本地方法是由c++编写的，所以这个栈是为native方法服务的，同样也会创建栈帧，同样也会抛出栈溢出的错误。\n程序计数器PC：一块较小的内存空间，就是一个计数器，可以看作是当前线程执行的字节码的行号指示器，字节码解释器通过改变PC的值来选取下一条要执行的字节码指令，从而实现循环，跳转，异常处理等功能。每个线程都需要一个独立的PC，PC也是唯一一个不会出现outofmemory的内存区域。执行native方法时PC为空。\n\nJAVA堆详解堆分为三部分：新生代，老年代，永久代（JDK8移除，功能由元空间代替实现）\n新生代Young Gen新生代用来存放新生的对象，一般占据1&#x2F;3。新生代中存放着大量刚刚创建的对象，但是大部分对象的存活时间都很短，所以会进行频繁的GC。新生代又分为三个部分Eden，SurvivorFrom，SurvivorTo 。这三个部分默认为8：1：1\n为什么要分配为8：1：1\n因为大部分对象都是朝生夕死，所以Eden区就设置大一些，存活区就设置小一些\nEden区：Java新创建的对象绝大部分会分配在Eden区（如果对象太大，则直接分配到老年代）。当Eden区内存不够的时候，就会触发MinorGC（新生代采用的是复制算法），对新生代进行一次垃圾回收。\nSurvivorFrom区和SurvivorTo区：在GC开始的时候，对象只会存在于Eden区和名为From的Survivor区，To区是空的，一次MinorGc过后，Eden区和SurvivorFrom区存活的对象会移动到SurvivorTo区中，然后会清空Eden区和SurvivorFrom区，并对存活的对象的年龄+1，如果对象的年龄达到15，则直接分配到老年代。MinorGC完成后，SurvivorFrom区和SurvivorTo区的功能进行互换。下一次MinorGC时，会把SurvivorTo区和Eden区存活的对象放入SurvivorFrom区中，并计算对象存活的年龄。\n老年代Old Gen老年代用于存放生命周期较长的内存对象，老年代比较稳定，不会频繁的进行MajorGC。\n而在MaiorGC之前才会先进行一次MinorGc，使得新生的对象进入老年代而导致空间不够才会触发。当无法找到足够大的连续空间分配给新创建的较大对象也会提前触发一次MajorGC进行垃圾回收腾出空间。\n在老年代中，MajorGC采用了标记—清除算法：首先扫描一次所有老年代里的对象，标记出存活的对象，然后回收没有标记的对象。MajorGC的耗时比较长。因为要扫描再回收。MajorGC会产生内存碎片，当老年代也没有内存分配给新来的对象的时候，就会抛出OOM（Out of Memory）异常。\n永久代Permanent Gen（方法区）永久代中包含了虚拟机中可以通过反射获取到的数据，比如Class对象和Method对象。JVM用于描述应用程序中用到的类和方法的元数据，如类的层级信息(包名，父类名，修饰符，接口)，方法的编译信息（参数，返回值，修饰符）及字节码，常量，静态变量就存储在永久代中，如果有类不再需要使用，空间会被释放留给其他类，full GC会进行永久代的回收\n不同的java虚拟机之间可能会进行类共享，因此又分为只读区和读写区\n永久代是有大小上限的，默认为64M，在堆内存中划出一块连续的空间分配给永久代\n元空间Meta SpaceJDK8开始，永久代被彻底删除，替换为元空间，JVM忽略了permsize这个参数，也就是没有outOfMemoryError异常。\n字符串常量池和静态变量也转移到了堆内存，因为字符串在永久代中容易造成性能问题\n元空间使用本地内存来存储类的元数据，所以不再归JVM管理\n为什么要抛弃永久代：\n\n永久代的大小在启动时就会固定好，很难进行调优修改\n元空间使用堆外内存，不由JVM管理，由OS来管理，所以可以不暂停GC的情况下释放类数据\n元空间的每个类加载器都有专门的存储空间\n充分利用了java语言规范的好处：类及相关的元数据的生命周期与类加载器一致\n省略了GC的扫描和压缩的时间\n元空间里面对象的位置是固定的，无需堆内存内GC时将对象不断移动\n元空间只进行线性分配，指针碰撞+OS本地内存&#x3D;大小上限提升，分配内存更迅捷\n\nGC堆内有大量的对象，所以需要GC来不断处理，以保证堆内存空间的合理使用\n并行（Parallel）：多个GC线程并行工作，用户线程等待\n并发（Concurrent）：用户线程和垃圾GC线程同时进行\n如何判断一个对象能否被删除\n被虚拟机栈，本地方法栈，静态变量，字符串常量引用的对象，不能被GC\n若可以被删除：打上标记\n\n标记清理算法：扫描一遍全部对象，删除带标记的对象，容易产生内存碎片\n标记整理算法：扫描一遍全部对象，删除带标记的对象，清理后需要紧凑，不断移动对象，代价比较大\n复制算法：分为1区和2区，无需删除的对象被紧凑复制到2区，然后清空1区，需要两倍的内存\n分代算法：核心是同时发挥“标记整理”和“复制”的优点，让他们分别去处理最适合自己的情况。分代就是为对象设置年龄，在新生代就触发新生代GC也叫minorGC，在老年代就触发老年代GC，也叫major GC，当方法区空间不足时会触发全局GC，也叫full GC\n\n\n\n新生代的GC垃圾回收器：（全部都是复制算法，参考上文）\n\nSerial：最基本，历史最悠久的收集器。单线程，简单，适合于单CPU环境，没有线程交互的开销，所以可以全力进行垃圾回收。需要Stop The World，但是效率不高\nParNew：其实就是多线程版的Serial，适合于多CPU环境，同样需要Stop The World\nParallel Scavenge：吞吐量优先收集器，同样是并行的。PS自带GC自适应调节策略：动态设置Eden和存活区的比例，新生代的大小，晋升老年代的对象年龄。虚拟机会根据运行状态信息来动态调整以获取最优的吞吐量和响应时间。\n\n老年代的GC\nCMS：回收停顿时间优先收集器，基于标记清除算法混合标记整理，并发（Concurrent），低停顿。将整个GC过程拉长，初始标记-&gt;并发标记-&gt;重新标记-&gt;并发清除。并发标记和并发清除是可以和用户线程同时进行的，另外两个阶段需要Stop The World。对碎片有一定容忍度，当碎片过多时会进行整理。对CPU资源敏感，因为需要并发，所以若CPU资源不够，性能会急剧下降\nSerial Old：老年代版本Serial，标记整理\nParallel Old：老年代版本的Parallel，标记整理\n\nG1收集器一款面向服务端应用的垃圾收集器，基于分代算法，基本步骤和CMS差不多，但是解决了CMS存在的问题\n步骤：\n\n初始标记：单线程+Stop The World，只扫描和GC root直接关联的对象\n并发标记：并发，进行GC root tracing，在初始标记的基础上继续向下追溯标记，标记出所有存活对象，用户线程可并发\n重新标记：Stop The World，修正并发标记期间因为用户线程的运行而造成的标记变动\n并发清除：并发进行回收\n\n特点：\n\n并行+并发：G1能充分利用多CPU来缩短停顿时间\n分代收集：G1可以独自管理整个堆\n空间整合：G1不会产生碎片\n可预测的停顿：G1能够建立可预测的停顿时间模型，能让使用者明确指定在一个时间段内，消耗在GC上的时间不超过N毫秒，原理：复制算法优先处理垃圾多的区域，可控\n\nC1和CMS的区别：\n\n管理区域：C1可以管理整个堆，且会将堆分为若干个region来管理，region中可以划分新生代和老年代，且新生代和老年代的大小可以动态调整\nG1收集器可预测垃圾回收的停顿时间（建立可预测的停顿时间模型），这个是G1的优势\n\n三色标记法CMS算法的基础是通过可达性分析找到存活的对象，然后给存活的对象打个标记，最终在清理的时候，如果一个对象没有任何标记，就表示这个对象不可达，需要被清理，标记算法就是使用的三色标记。\n并发标记阶段是从GC Root直接关联的对象开始枚举的过程\nGC Root：\n\n虚拟机栈（栈帧中的局部变量表）中引用的对象\n本地方法栈中 JNI（即一般说的 Native 方法）引用的对象\n方法区中类静态属性引用的对象\n方法区中常量引用的对象\n\n对象的三个状态：\n\n白色：这个对象还没有被访问过，在初始阶段，所有对象都是白色，所有都枚举完仍是白色的对象将会被当做垃圾对象被清理\n灰色：这个对象已经被访问过，但是这个对象所直接引用的对象中，至少还有一个没有被访问到，表示这个对象正在枚举中\n黑色：对象和它所直接引用的所有对象都被访问过。这里只要访问过就行，比如A只引用了B，B引用了C、D，那么只要A和B都被访问过，A就是黑色，即使B所引用的C或D还没有被访问到，此时B就是灰色。\n\n大致流程：\n\n首先我们从GC Roots开始枚举，它们所有的直接引用变为灰色，自己变为黑色。可以想象有一个队列用于存储灰色对象，会把这些灰色对象放到这个队列中\n然后从队列中取出一个灰色对象进行分析：将这个对象所有的直接引用变为灰色，放入队列中，然后这个对象变为黑色；如果取出的这个灰色对象没有直接引用，那么直接变成黑色\n继续从队列中取出一个灰色对象进行分析，分析步骤和第二步相同，一直重复直到灰色队列为空\n分析完成后仍然是白色的对象就是不可达的对象，可以作为垃圾被清理\n最后重置标记状态\n\n可能出现的两种问题\n\n一个本应该是垃圾的对象被视为了非垃圾\n一个本应该不是垃圾的对象被视为了垃圾\n\n解决方式\n\n增量更新：站在新增引用的对象的角度来解决问题，在增加引用前添加一个写屏障，在屏障中记录新的引用。然后将引用关系中的黑色对象重新设置为灰色，在重新标记阶段再扫描一次，CMS\n原始快照：站在减少引用的对象的角度来解决问题，当灰色对象要删除指向白色对象的引用关系时，就将这个要删除的引用记录下来，在并发扫描结束之后，再将这些记录过的引用关系中的灰色对象为根，重新扫描一次。G1使用，效率更高，但是会产生更多的浮动垃圾，只能等待下次GC\n\n这也可以简化理解为，无论引用关系删除与否，都会按照刚刚开始扫描那一刻的对象图快照来进行搜索\n垃圾收集器如何选择呢Client模式下的虚拟机：Serial\n注重高吞吐量以及CPU资源敏感：Parallel Scavenge +Parallel Old\n最小化Stop The World时间：G1或者ParNew+CMS\n类文件结构解析字节码：.class扩展名\n\n魔数：magic number：每个class文件的头4个字节被称为魔数（CAFEBABE）唯一作用便是确定这个文件是否为一个能被虚拟机接收的class文件\nclass文件版本号：小版本号+大版本号。高版本的JVM可以执行低版本的class文件\n常量池：常量池计数器+常量池数据区。计数器从1开始，若有某些指向常量池的索引值需要表达“不引用常量池中的项目”这一含义，则可以将索引值设为0。常量池数据区中主要存储两大常量：字面量：即文本字符串，或者被final修饰的常量等。符号引用：package，接口的全名，方法名称或描述符，字段名称或描述符等等。与c不同的是，java在编译时，不会有连接这一步骤，而是会在虚拟机加载class文件时进行动态连接，虚拟机在进行类加载时，将会从常量池中获得对应的符号引用，在类创建时或运行时解析，并翻译到具体的内存地址中。常量池中的每一项都是一个表。常量池可以看作是class文件里的资源仓库，占用空间最大。\n访问标志：用于识别类或者接口的访问信息，比如class是类还是接口，public还是abstract，是否被final修饰等\n索引集合：当前类，父类，接口索引集合\n字段表集合：描述接口或类中声明的变量，不包括方法内声明的局部变量。字段计数器+字段表数据区\n方法表集合：方法计数器+方法数据区\n\n类加载过程加载加载主要完成下面三件事情\n\n通过全类名获取定义此类的二进制字节流\n将字节流代表的静态数据结构转换为方法区的运行时数据结构\n在内存中生成一个代表该类的class对象，作为方法区数据的访问入口\n\n连接——验证\n文件格式验证：是否符合class文件格式的规范（CAFEBABE），主次版本号是否在虚拟机的处理范围内，常量池中的的常量是否都可以支持\n元数据验证：对字节码的信息进行语义分析，保证描述的信息符合java的语言规范，比如这个类是否有父类，这个类是否继承了不被允许继承的类\n字节码验证：这是最为复杂的一个阶段，通过数据流和控制流的分析，确定程序语义是合法，符合逻辑的，比如确保任意时刻操作数栈都能配合工作\n符号引用验证：确保解析动作能正确执行\n\n连接——准备这个阶段会正式为变量分配内存并设置初始变量，仅包括类变量,static\n连接——解析将常量池里的符号引用替换为直接引用，主要针对，接口，字段，类方法。符号引用就是用一组符号来描述目标，可以是任何字面量；直接引用就是直接指向目标的指针，偏移量\n初始化这是类加载的最后一步，执行初始化方法，在这一步，JVM才真正开始执行类中定义的java程序代码\nJAVA的类加载器\nBootstrap类加载器：即引导类加载器，由C++语言实现，无父类。主要加载的是JVM自身需要的类，是虚拟机自身的一部分，它负责&#x2F;lib路径下的核心类库或-Xbootclasspath参数指定的路径下的jar包加载到内存中，虚拟机按照文件名识别jar包，处于安全考虑，启动类加载器只加载包名为java,javax,sun等开头的jar包，即使将不符合要求的jar包丢入lib目录下也没法被识别。\nExtention类加载器：即扩展类加载器，是指sun公司实现的ExtClassLoader类，由Java语言实现，父类加载器为null，是Launcher中的静态内部类，它负责加载&#x2F;lib&#x2F;ext目录或者由系统变量-Djava.ext.dir指定位路径中的类库，开发者可以直接使用标准扩展类加载器。\nApplication类加载器：即应用程序加载器，是指sun公司实现的appClassLoader，父类加载器为扩展类加载器。它负责加载class-path指定路径下的库类，也就是我们经常用到的classpath，一般情况下该类加载是程序中默认的类加载器。\nCustom自定义类加载器：负责加载用户自定义路径下的类包，父类加载器为应用程序加载器\n\n类加载器的三大特征：\n\n委托性：即双亲委派机制，当类A被加载时，首先会委托给父类加载器。引导类加载器会在lib目录下查找是否存在，找到便加载，未找到便回到扩展类加载器。扩展类加载器会在&#x2F;lib&#x2F;ext目录下查找，找到便加载，未找到便回到应用程序加载器。应用程序加载器会在classPath路径下查找，找到则加载，未找到则抛出ClassNotFoundException异常\n可见性：父类加载器加载的类可以被子类观察到，但是子类加载的类对父类不可见\n一个类只可以被加载一次\n\n双亲委派机制：\n\n\nHOTSPOT虚拟机对象创建的过程类加载检测虚拟机遇到new指令时，首先检查这条指令的参数是否能在常量池中定位到这个类的引用，检查这个符号引用代表的类是否已经被加载过，解析，或初始化。若没有，则先执行相应的类加载过程。\n分配内存为新对象分配内存，所需内存大小在类加载完成后就可以确定，分配内存的任务等同于将一块确定大小的内存从堆中划分出来。\n\n指针碰撞：堆内存规整，将用过的内存和没用过的内存整合到两边，中间有一个分界指针，只需要将指针移动相应大小即可完成分配。\n空闲列表：堆内存不规整，虚拟机会维护一个列表，列表中会记录哪些内存块是可用的，寻找到一块满足大小的内存分配后，更新列表。\n\n初始化零值当内存分配后，需要将分配到的内存空间都初始化为0值，这一步保证了对象的字段在java代码中可以不赋值就能直接被使用，程序能访问这些字段的数据类型对应的0值\n设置对象头这个对象是哪个类的实例，对象的HashCode，如何才能找到类的元数据信息，等信息处理后放入对象头中、\n执行init方法在虚拟机的视角来看，对象的创建已经完成，但是对于java程序来说，对象创建才刚刚开始，在init之前所有的字段都是零值，init之后便会将对象按照程序员的意愿进行初始化，一个真正可用的对象才算真正创建。\nHotSpot的oop-klass模型我们平时写的java类编译成.class文件，JVM加载.class文件，那么加载.class文件之后在JVM中就是oop-klass（C++）模型形式存在的\nJVM内部基于oop-klass模型描述一个java类以及其实例\njava类元信息用klass描述，对象用oop来描述\n\njvm在加载class时，会创建instanceKlass，表示其元数据，包括常量池、字段、方法等，存放在方法区\n在new一个对象时，jvm创建instanceOopDesc，来表示这个对象，存放在堆区\n其引用，存放在栈区；\n在JVM中，Hotspot并没有将Java对象直接映射成C++对象，而是实现了Java的对象模型（oop-klass）\n因为C++的对象里含有虚表，这个虚表实现了C++对象的多态，而JVM不希望每个对象中都包含一份虚函数表\n所以就把对象模型拆成 klass 和 oop，其中 oop 中不含有任何虚函数，而 klass 就含有虚函数表\n四种引用类型强引用一般创建对象时如Object obj&#x3D;new Object()，obj指向堆内的instanceOOP，这个指向就是最常见的强引用\n只要强引用存在，垃圾收集器就不会回收被引用的对象。\n软引用使用SoftReference类包装创建的对象如SoftReference softRef &#x3D; new SoftReference&lt;&gt;(obj)\n此时softRef会以强引用指向堆内的SR对象实例，然后SR会以软引用的方式再指向Object实例\n当要发生内存溢出时，软引用对象会被回收，无论是否被引用。\n对适合作为缓存的对象实例添加软引用，内存够的适合拿来即用，内存不够的时候就被回收，避免OOM\n弱引用和软引用类似，使用weakRefence类来进行包装\n不过必要性再次降低，当GC时，无论内存是否够用，都会被回收\n解决Map或者ThreadLocal的内存泄露问题\n虚引用使用PhantomReference来包装，PhantomReference pr &#x3D; new PhantomReference&lt;&gt;(obj,QUEUE);\n这个队列就是引用队列ReferenceQueue，虚引用必须指定相应的引用队列\n虚引用也称作幽灵引用，虚引用并不会影响对象的生命周期，虚引用的特点就是可以充当信号量：\n即当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到引用队列中，可以通过判断queue里面是不是有对象来判断你的对象是不是要被回收了\n这个特性可以用于管理操作系统的本地内存：\n一些网络编程框架如基于NIO的netty，会使用操作系统的本地内存块作为buffer来接收管道传输的数据，\n通常会在JVM里创建指向这个内存块的指针来进行管理，而GC的范围仅限于JVM\n所以就需要进行通知：当这个指针被回收时-&gt;虚引用进入队列-&gt;检测到队列里有虚引用-&gt;回收指针以及指向的OS内存块\n","slug":"JVM基础","date":"2022-09-12T04:37:43.000Z","categories_index":"","tags_index":"Java基础知识","author_index":"Samuel"},{"id":"b8307bc7cc4dad51e597289f7dfa286e","title":"JAVA的字符串","content":"String&amp;StringBuilderString的底层数据结构是数组char value[]\npublic final class String\nimplements java.io.Serializable, Comparable&lt;String>, CharSequence &#123;\n\t/** The value is used for character storage. */\n\tprivate final char value[];\n\t/** Cache the hash code for the string */\n\tprivate int hash; // Default to 0\n\t/** use serialVersionUID from JDK 1.0.2 for interoperability */\n\tprivate static final long serialVersionUID = -6849794470754667710L;\n&#125;\n\nString的类用于存放字符串的方法都用了final来修饰，也就是创建后均不可以被改变，当我们进行一个字符串相连的操作时，便会创建出新的对象\nString str_1 = new String(\"ab\");\nString str_2 = new String(\"ab\");\nString str_3 = \"ab\";\n\n\nSystem.out.println(str_1 == str_2); //false\nSystem.out.println(str_1 == str_2.intern());//false\nSystem.out.println(str_1.intern() == str_2.intern());//true\nSystem.out.println(str_1 == str_3);//false\nSystem.out.println(str_1.intern() == str_3);//true\n\n结论：\n\n&#x3D;&#x3D; ， 在引用类型中是对比的地址，比如str1和str2，两个new出来的对象置于堆内存中，地址肯定不同；但是如果是基础类型如str3，就是对比值；当然也有equal方法，这是对比的是哈希值\nintern()，这是一个本地方法，底层由c++实现，它的作用是将值推进常量池\nString str_3 = &quot;ab&quot;这种赋值方法JVM做了优化，不会创建对象，直接将值放进常量池\n\nStringBuilder//初始化，同样是数组\nnew StringBuilder(16);\n\npublic StringBuilder() &#123;\n\tsuper(16);\n&#125;\nAbstractStringBuilder(int capacity) &#123;\n\tvalue = new char[capacity];\n&#125;\n\n//添加元素\nstringBuilder.append(\"a\");\n\npublic AbstractStringBuilder append(String str) &#123;\n\tif (str == null)\n\treturn appendNull();\n\tint len = str.length();\n\tensureCapacityInternal(count + len);\n\tstr.getChars(0, len, value, count);\n\tcount += len;\n\treturn this;\n&#125;\n\nprivate void ensureCapacityInternal(int minimumCapacity) &#123;\n\t// overflow-conscious code\n\tif (minimumCapacity - value.length > 0)\n\texpandCapacity(minimumCapacity);\n&#125;\nvoid expandCapacity(int minimumCapacity) &#123;\n\tint newCapacity = value.length * 2 + 2;\n\tif (newCapacity - minimumCapacity &lt; 0) newCapacity = minimumCapacity;\n\tif (newCapacity &lt; 0) &#123;\n\t\tif (minimumCapacity &lt; 0) // overflow\n\t\tthrow new OutOfMemoryError();\n\tnewCapacity = Integer.MAX_VALUE;\n\t&#125;\n\tvalue = Arrays.copyOf(value, newCapacity);\n&#125;\n\n对字符串的各种操作方法字符串类\nString：不可修改\n当使用字符串的相加操作时，不会删掉原字符串，而是在常量池里面新建一个新的String，储存修改后的结果\nequals();\n//boolean比较两个字符串是否相等\ncompareTo();\n//基于每个字符进行Unicode值比较，若完全相等，返回0；小于参数，返回负数；大于参数，返回正数\ncontains();\n//boolean若包含某个字符，返回true\nindexOf();\n//返回字符第一次出现的索引，未找到则返回-1、\nstartsWith(); endsWith();\n//boolean测试字符串是否以参数为前缀开头;是否以参数为后缀结尾\nreplaceAll(String regex,String replacement);\n//将字符串中的所有的regex替换为replacement\nsplit(String regex);\n//每个字符以regex分割并返回一个string型数组\nsubstring();\n//可以接收两个参数，返回这个索引截取的子串\ntrim();\n//删除前置和后置的所有空格\ntoUpperCase();toLowerCase();\n//大小写转换\njoin(\"mark\",\"\");\n//为一系列字符串添加分割符并拼成一个新的字符串\n\nStringBuilder：可以修改，可以在常量池里原地修改字符串\nStringBuffer：可以修改，且线程安全，基本与StringBuilder相同\nappend();\n//字符串连接\ntoString();\n//返回一个与构建器相同的String\nsetCharAt(int i, char c);\n//把某个位置的字符置为C\ninsert(int offset, String str/char c);\n//在指定位置之前插入字符串或字符\ndelete(int startIndex,int endIndex);\n//删除指定范围内的字符串\n\n\ndeleteCharAt (int index);\n//删除某个字符\nreplace(int start,int end,String str);\n//在指定范围内用str替换\n reverse();\n//字符串反转\nsubstring(int start,int end);\n//返回子串\n","slug":"Java的字符串","date":"2022-08-14T04:57:02.000Z","categories_index":"","tags_index":"Java基础知识","author_index":"Samuel"},{"id":"9a0ea7adf62049ce83652b0a7c894a59","title":"Java数据结构","content":"ArrayListArrayList即数组列表，是基于数组实现的，这个数组可以插入任何元素，只不过这个数组是可以按需扩容，可以进行数据拷贝的\nArrayList的构造private static final int DEFAULT_CAPACITY = 10;\n//默认初始化容量\nprivate int size; \n//size指elementData中实际有多少元素\ntransient Object[] elementData;\n//element.length指集合容量\n//transient关键字只能修饰变量，不可修饰方法和类，该变量被序列化后将无法被访问\nprotected transient int modCount = 0;\n//记录对list操作的次数\n\n//无参构造\nprivate static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;\npublic ArrayList() &#123;\n    this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;\n&#125;\n//当使用无参构造时，给elementData数组赋值了一个空数组，这个空数组知道当无参构造时，第一次添加元素后如何扩容。构造时赋予空数组，而当第一次添加元素时，容量便会扩充到10\n\n//有参构造\nprivate static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;\npublic ArrayList(int initialCapacity) &#123;\n    if (initialCapacity > 0) &#123;\n        this.elementData = new Object[initialCapacity];\n        //参数大于零且合法，便初始化一个数组便赋值给elementData\n    &#125; else if (initialCapacity == 0) &#123;\n        //参数为零，便将空数组赋值给elementData\n        this.elementData = EMPTY_ELEMENTDATA;\n    &#125; else &#123;\n        //参数不合法，提示错误\n        throw new IllegalArgumentException(\"Illegal Capacity: \"+\n                                  \t\t\tinitialCapacity);\n    &#125;\n&#125;\n\n//使用指定collection来构造\npublic ArrayList(Collection&lt;? extends E> c) &#123;\n    elementData = c.toArray();\n    //将collection c转化为数组并赋值给elementData\n    if ((size = elementData.length) != 0) &#123;、\n        // c.toArray might (incorrectly) not return Object[] (see 6260652)\n        if (elementData.getClass() != Object[].class)\n            //若elementData的数组类型不是object，就做一次转换\n        elementData = Arrays.copyOf(elementData, size, Object[].class);\n    &#125; else &#123;\n        // replace with empty array.\n        this.elementData = EMPTY_ELEMENTDATA;\n    &#125;\n&#125;\n\nArrayList的相关操作//add 操作\npublic boolean add(E e) &#123;\n    ensureCapacityInternal(size + 1);  // Increments modCount!!\n    //对size进行自增操作，即成功添加新元素\n    elementData[size++] = e;\n    return true;\n&#125;\n\nprivate void ensureCapacityInternal(int minCapacity) &#123;\n    //当使用无参构造时，添加一个元素时会将容量设置为默认10，并进行扩容\n    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123;\n        minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);\n    &#125;\n    ensureExplicitCapacity(minCapacity);\n&#125;\n\nprivate void ensureExplicitCapacity(int minCapacity) &#123;\n    //确认是否需要扩容：即size+1是否会超出容量\n    modCount++;\n    // overflow-conscious code\n    if (minCapacity - elementData.length > 0)\n        //扩容，使用grow方法\n        grow(minCapacity);\n&#125;\n\n//grow操作，当添加元素发现容量不足或无参构造第一次添加元素时，需要扩容\nprivate void grow(int minCapacity) &#123;\n    // overflow-conscious code\n    int oldCapacity = elementData.length;\n    int newCapacity = oldCapacity + (oldCapacity >> 1);\n    //将容量扩充至原大小的1.5倍，但是这个大小可能有大有小，所以需要if语句来进行判断\n    if (newCapacity - minCapacity &lt; 0)\n        newCapacity = minCapacity;\n    //扩容后的容量还是很小，不满足需要的容量，则直接将需要的容量赋值给newCapacity\n    if (newCapacity - MAX_ARRAY_SIZE > 0)\n        //扩容后的容量太大了，就改变扩容方式\n        newCapacity = hugeCapacity(minCapacity);\n    // minCapacity is usually close to size, so this is a win:\n    //将原数组的大小扩充至newCapacity\n    elementData = Arrays.copyOf(elementData, newCapacity);\n&#125;\n\n//当扩大1.5倍后超出了最大范围，那么就干脆将大小设为最大范围\nprivate static int hugeCapacity(int minCapacity) &#123;\n    if (minCapacity &lt; 0) // overflow\n        throw new OutOfMemoryError();\n    return (minCapacity > MAX_ARRAY_SIZE) ?\n        Integer.MAX_VALUE :\n        MAX_ARRAY_SIZE;\n&#125;\n\nprivate static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;\n\n//remove操作\n//输入索引\npublic E remove(int index) &#123;\n    //检测这个元素是否处于数组的最后一个位置\n    rangeCheck(index);\n    modCount++;\n    E oldValue = elementData(index);\n    int numMoved = size - index - 1;\n    if (numMoved > 0)\n        //若index不在最后一位，则将index+1开始向后的所有元素向前移动一位，相当于删除了index位置的元素\n        System.arraycopy(elementData, index+1, elementData, index, numMoved);\n    //将最后一位赋值为null\n    elementData[--size] = null; // clear to let GC do its work\n    return oldValue;\n&#125;\n//参数直接为指定元素\npublic boolean remove(Object o) &#123;\n    if (o == null) &#123;\n        for (int index = 0; index &lt; size; index++)\n            if (elementData[index] == null) &#123;\n                fastRemove(index);\n                return true;\n            &#125;\n    &#125; else &#123;\n        for (int index = 0; index &lt; size; index++)\n            if (o.equals(elementData[index])) &#123;\n                fastRemove(index);\n                return true;\n            &#125;\n    &#125;\n    return false;\n&#125;\n\nprivate void fastRemove(int index) &#123;\n    modCount++;\n    int numMoved = size - index - 1;\n    if (numMoved > 0)\n        System.arraycopy(elementData, index+1, elementData, index,numMoved);\n    elementData[--size] = null; // clear to let GC do its work\n&#125;\n\n//get操作\npublic E get(int index) &#123;\n    rangeCheck(index);\n    return elementData(index);\n&#125;\n//由于arraylist的底层基于数组，获取元素就很简单，直接调用数组访问即可\n\n//迭代器\n//由上述源码可知，在进行remove的时候，size是时刻动态变化的，所以不能对arrayList进行for循环遍历来remove元素，这样容易造成结果不准确甚至数组下标越界\npublic Iterator&lt;E> iterator() &#123;\n    return new Itr();\n&#125;\n//当创建迭代器时 list.iterator();会直接返回一个Itr对象\n\n\n//ArrayList的内部类Itr实现了Iterator接口，该类有三个方法\nprivate class Itr implements Iterator&lt;E> &#123;\n    int cursor = 0 ;       // index of next element to return，下一个要访问的元素\n    int lastRet = -1; // index of last element returned; -1 if no such\n    int expectedModCount = modCount;//代表对ArrayList修改次数的期望值，初始为modCount\n\n    public boolean hasNext() &#123;\n        return cursor != size;\n    &#125;\n\n    @SuppressWarnings(\"unchecked\")\n    public E next() &#123;\n        //判断expectedModCount是否和modCount相等\n        checkForComodification();\n        int i = cursor;\n        //判断是否越界\n        if (i >= size)\n            throw new NoSuchElementException();\n        Object[] elementData = ArrayList.this.elementData;\n        if (i >= elementData.length)\n            throw new ConcurrentModificationException();\n        cursor = i + 1;\n        return (E) elementData[lastRet = i];//lastRet和cursor都自增1，并返回自增后的lastRet\n    &#125;\n\n    public void remove() &#123;\n        //\n        if (lastRet &lt; 0)\n            throw new IllegalStateException();\n        checkForComodification();\n\n        try &#123;\n            ArrayList.this.remove(lastRet);\n            //调用ArrayList的remove方法并将两个游标向前移动一位\n            cursor = lastRet;\n            lastRet = -1;\n            expectedModCount = modCount;\n        &#125; catch (IndexOutOfBoundsException ex) &#123;\n            throw new ConcurrentModificationException();\n        &#125;\n    &#125;\n\n    final void checkForComodification() &#123;\n        if (modCount != expectedModCount)\n            throw new ConcurrentModificationException();\n    &#125;\n&#125;\n//如果要对ArrayList进行遍历操作，就要使用迭代器，且在remove之前必须hasnext和next\n\nLinkedListlinkedlist与arraylist不同，后者基于一个被维护的数组来实现动态调整大小，而前者则是一个双向链表\n链表的优势：当插入和删除比较频繁的时候，链表相较于数组能有更高的效率(通常情况下，也有特殊情况，比如arraylist的中间插入效率就要高一些)，但是查找效率却不高。\n//内部类node的源码\n//一个对象对应一个节点\n    private static class Node&lt;E> &#123;\n       //元素的引用\n       //如果为null,表示没有存储任何元素，如果不为null,表示存储了某种类型的元素\n       E item;\n       //下一个节点的引用\n       //引用代表了对象的十六进制地址值,所以也可以注释为:下一个节点在内存中的地址\n       //如果为null,可能是空链表，也可能是尾节点\n       Node&lt;E> next;\n       Node&lt;E> prev;\n       Node(Node&lt;E> prev, E element, Node&lt;E> next) &#123;\n          //元素的引用初始化\n          this.item = element;\n          //上一个节点的引用初始化\n          this.next = next;\n          //下一个节点的引用初始化\n          this.prev = prev;\n       &#125;\n    &#125;\n\n//变量\ntransient int size = 0;\n//元素数量\ntransient Node&lt;E> last;\n//首节点的固定引用，必须先创建首节点，才能创建下一个节点\ntransient Node&lt;E> first;\n//尾节点的固定引用\n\n\n\n//头插\nprivate void linkFirst(E e) &#123;\n    //再创建一个指针f指向首节点\n\tfinal Node&lt;E> f = first;\n    //前指针为空，后指针指向f\n\tfinal Node&lt;E> newNode = new Node&lt;>(null, e, f);\n    //将first首指针指向newnode，代表newnode成为新的首元素\n\tfirst = newNode;\n    //若f指向的元素为空，证明加入newnode前链表为空，那么newnode既是首元素，也是尾元素\n\tif (f == null) last = newNode;\n    //若不为空，将前指针指向newnode，形成双向链表\n\telse f.prev = newNode;\n\tsize++; modCount++;\n&#125;\n//linkedlist的头插效率非常高，因为arraylist的头插需要进行大量的移位，元素复制的操作，还可能需要进行扩容，而链表只需调整指针的指向即可\n\n//尾插\nvoid linkLast(E e) &#123;\n    //与头插大同小异\n\tfinal Node&lt;E> l = last;\n    //最后一个节点的next为null\n\tfinal Node&lt;E> newNode = new Node&lt;>(l, e, null);\n\tlast = newNode;\n\tif (l == null) first = newNode;\n\telse l.next = newNode;\n\tsize++; modCount++;\n&#125;\n//出乎意料地是，linkedlist的尾插效率却比arraylist要低，因为arraylist无需进行移位拷贝操作，而linkedlist则需要创建对象，后者要耗时许多\n\n//中间插入\npublic void add(int index, E element) &#123;\n    //输入索引和元素，检查索引范围是否合法\n\tcheckPositionIndex(index);\n    //若索引为size则进行尾插\n\tif (index == size) linkLast(element);\n    //不是，则进行中间插入\n\telse inkBefore(element, node(index));\n&#125;\nNode&lt;E> node(int index) &#123;\n\t// assert isElementIndex(index);\n    //size>>1：size的一半，判断元素在左半区间，还是右半区间\n\tif (index &lt; (size >> 1)) &#123;\n        //在左半区间，操纵first指针找到index元素\n\t\tNode&lt;E> x = first;\n\t\tfor (int i = 0; i &lt; index; i++)\n\t\tx = x.next;\n\t\treturn x;&#125; \n    else &#123;\n        //在右半区间，操纵last指针找到index元素\n\t\tNode&lt;E> x = last;\n\t\tfor (int i = size - 1; i > index; i--)\n\t\tx = x.prev;\n\t\treturn x;&#125;\n&#125;\nvoid linkBefore(E e, Node&lt;E> succ) &#123;\n\t// assert succ != null;\n    //在index所指的元素之前插入新元素\n\tfinal Node&lt;E> pred = succ.prev;\n\tfinal Node&lt;E> newNode = new Node&lt;>(pred, e, succ);\n\tsucc.prev = newNode;\n\tif (pred == null) first = newNode;\n\telse pred.next = newNode;\n\tsize++; modCount++;\n&#125;\n//在数据量较大的时候，中间插入相比arrayList仍然会消耗较多的时间，所以CRUD效率不是绝对的可以分高下，需要根据应用场景和数据量等来综合考量\n\n//删除节点\npublic boolean remove(Object o) &#123;\nif (o == null) &#123;\nfor (Node&lt;E> x = first; x != null; x = x.next) &#123;\nif (x.item == null) &#123;\n\tunlink(x);\n\treturn true;\n\t\t&#125;\n\t&#125;\n&#125; else &#123;\n\tfor (Node&lt;E> x = first; x != null; x = x.next) &#123;\n    if (o.equals(x.item)) &#123;\n\tunlink(x);\n\treturn true;\n\t\t&#125;\n\t&#125;\n&#125;\nreturn false;\n&#125;\n//解链操作，即将这个元素从链表中移除\nE unlink(Node&lt;E> x) &#123;\n// assert x != null;\n\tfinal E element = x.item;\n\tfinal Node&lt;E> next = x.next;\n\tfinal Node&lt;E> prev = x.prev;\n    //若上个结点为空，则直接将首指针指向next\n\tif (prev == null) first = next; \n    //断掉x的prev指针\n    else &#123;prev.next = next;x.prev = null;&#125;\n    //若下一个结点为空，则直接将尾结点指向prev\n\tif (next == null) last = prev;\n    //断掉x的next指针\n    else &#123;next.prev = prev;x.next = null;&#125;\n\tx.item = null;\n\tsize--;\n\tmodCount++;\n\treturn element;\n\t&#125;\n","slug":"Java数据结构","date":"2022-08-12T05:41:02.000Z","categories_index":"","tags_index":"Java基础知识","author_index":"Samuel"}]